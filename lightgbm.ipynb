{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_48737/2820391132.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "import lightgbm as lgb\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('./data/clean/diamondsdlfe2xso37.csv',)\n",
    "df_test = pd.read_csv('./data/clean/testdl123fexydatdso3.7x2.csv',)\n",
    "\n",
    "y = df_train['price'].values[1:]\n",
    "X = np.array(df_train.drop(['Unnamed: 0','price'], axis=1))[1:]\n",
    "X_test = np.array(df_test.drop('Unnamed: 0',axis=1))[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'price', 'carat', 'depth', 'table', 'x', 'y', 'z', 'cut',\n",
       "       'color', 'clarity', 'city', 'x/y', 'td', 'ad'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X,y,test_size=0.2,random_state=62)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['0.29', '62.7', '62.0', ..., '0.9905437352245863',\n",
       "        '0.9888357256778308', '0.0061978302977642825'],\n",
       "       ['1.52', '61.2', '60.0', ..., '1.0137174211248285',\n",
       "        '0.9803921568627451', '0.006283842340892668'],\n",
       "       ['0.3', '61.9', '58.0', ..., '1.0070093457943923',\n",
       "        '0.9369951534733442', '0.006113903489343302'],\n",
       "       ...,\n",
       "       ['0.5', '61.8', '59.0', ..., '1.0079522862823063',\n",
       "        '0.9546925566343043', '0.006284047598292306'],\n",
       "       ['1.35', '60.0', '57.0', ..., '1.0055944055944055', '0.95',\n",
       "        '0.006107034602684245'],\n",
       "       ['1.22', '62.0', '54.0', ..., '0.9971014492753623',\n",
       "        '0.8709677419354839', '0.0060185853916895375']], dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_train = lgb.Dataset(X_train, y_train)\n",
    "lgb_eval = lgb.Dataset(X_val, y_val, reference=lgb_train)\n",
    "lgb_X = lgb.Dataset(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_model = lgb.LGBMRegressor(\n",
    "    task = 'predict',\n",
    "    application = 'regression',\n",
    "    objective = 'root_mean_squared_error',\n",
    "    boosting_type=\"gbdt\",\n",
    "    num_iterations = 2500,\n",
    "    learning_rate = 0.05,\n",
    "    num_leaves=15,\n",
    "    tree_learner='feature',\n",
    "    max_depth =10,\n",
    "    min_data_in_leaf=7,\n",
    "    bagging_fraction = 1,\n",
    "    bagging_freq = 100,\n",
    "    reg_sqrt='True',\n",
    "    metric ='rmse',\n",
    "    feature_fraction = 0.6,\n",
    "    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rjcolgut/.local/lib/python3.10/site-packages/lightgbm/sklearn.py:683: UserWarning: Found 'application' in params. Will use it instead of 'objective' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'objective' argument\")\n",
      "/home/rjcolgut/.local/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=7, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7\n",
      "[LightGBM] [Warning] bagging_freq is set=100, subsample_freq=0 will be ignored. Current value: bagging_freq=100\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=7, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7\n",
      "[LightGBM] [Warning] bagging_freq is set=100, subsample_freq=0 will be ignored. Current value: bagging_freq=100\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000325 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1975\n",
      "[LightGBM] [Info] Number of data points in the train set: 32364, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 55.712754\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=7, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7\n",
      "[LightGBM] [Warning] bagging_freq is set=100, subsample_freq=0 will be ignored. Current value: bagging_freq=100\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      " RMSE: 520.319498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rjcolgut/.local/lib/python3.10/site-packages/lightgbm/sklearn.py:683: UserWarning: Found 'application' in params. Will use it instead of 'objective' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'objective' argument\")\n"
     ]
    }
   ],
   "source": [
    "lgb_model.fit(X_train,y_train) \n",
    "\n",
    "\n",
    "preds_lgb_model = lgb_model.predict(X_val)\n",
    "rmse_lgb = root_mean_squared_error(y_val, preds_lgb_model)\n",
    "print(\" RMSE: %f\" % (rmse_lgb ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'LGBMRegressor' object has no attribute 'train'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStarting training...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# train\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m gbm \u001b[38;5;241m=\u001b[39m \u001b[43mlgb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m(\n\u001b[1;32m      4\u001b[0m                 lgb_train,\n\u001b[1;32m      5\u001b[0m                 num_boost_round\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m,\n\u001b[1;32m      6\u001b[0m                 valid_sets\u001b[38;5;241m=\u001b[39mlgb_eval,\n\u001b[1;32m      7\u001b[0m                 callbacks\u001b[38;5;241m=\u001b[39m[lgb\u001b[38;5;241m.\u001b[39mearly_stopping(stopping_rounds\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m15\u001b[39m)])\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'LGBMRegressor' object has no attribute 'train'"
     ]
    }
   ],
   "source": [
    "print('Starting training...')\n",
    "# train\n",
    "gbm = lgb.train(\n",
    "                lgb_train,\n",
    "                num_boost_round=200,\n",
    "                valid_sets=lgb_eval,\n",
    "                callbacks=[lgb.early_stopping(stopping_rounds=15)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridParams_ext = {\n",
    "    'learning_rate': [0.005, 0.01],\n",
    "    'n_estimators': [8,16],\n",
    "    'num_leaves': [6,8], # large num_leaves helps improve accuracy but might lead to over-fitting\n",
    "    'boosting_type' : ['gbdt', 'dart'], # for better accuracy -> try dart\n",
    "    'objective' : ['regression'],\n",
    "    'max_bin':[255], # large max_bin helps improve accuracy but might slow down training progress\n",
    "    'random_state' : [500],\n",
    "    'colsample_bytree' : [0.65],\n",
    "    'subsample' : [0.7,0.75],\n",
    "    'reg_alpha' : [1,1.2],\n",
    "    'reg_lambda' : [1,1.2],\n",
    "    'metric': ['rmse'],\n",
    "    'force_col_wise': [True]}\n",
    "gridParams_quick = {\n",
    "    'task' : ['predict'],\n",
    "    'application' : ['regression'],\n",
    "    'objective' : ['root_mean_squared_error'],\n",
    "    'boosting_type' : [\"gbdt\"],\n",
    "    'num_iterations' : [2500],\n",
    "    'learning_rate' : [0.05],\n",
    "    'num_leaves' : [15],\n",
    "    'tree_learner' : ['feature'],\n",
    "    'max_depth' : [10],\n",
    "    'min_data_in_leaf':[7],\n",
    "    'bagging_fraction' : [1],\n",
    "    'bagging_freq' : [100],\n",
    "    'reg_sqrt' : ['True'],\n",
    "    'metric' : ['rmse'],\n",
    "    'feature_fraction' : [0.6],\n",
    "    'force_col_wise': [True]}\n",
    "gridParams_art={\n",
    "        'num_leaves':[64],\n",
    "          'min_child_samples':[6],\n",
    "          'objective':['regression'],\n",
    "          'learning_rate':[0.01],\n",
    "          'boosting_type':['gbdt'],\n",
    "          'metric':['rmse'],\n",
    "          'max_depth':[6]}\n",
    "gridParams_xgb= {'colsample_bytree': [0.8,0.9], 'learning_rate': [0.005,0.015], 'max_depth': [6,7,8], 'n_estimators': [800,1600], 'subsample': [0.6,0.9],\n",
    "    'force_col_wise': [True]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl = lgb.LGBMRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 48 candidates, totalling 144 fits\n",
      "[CV 2/3; 1/48] START colsample_bytree=0.8, force_col_wise=True, learning_rate=0.005, max_depth=6, n_estimators=800, subsample=0.6\n",
      "[CV 2/3; 4/48] START colsample_bytree=0.8, force_col_wise=True, learning_rate=0.005, max_depth=6, n_estimators=1600, subsample=0.9\n",
      "[CV 3/3; 3/48] START colsample_bytree=0.8, force_col_wise=True, learning_rate=0.005, max_depth=6, n_estimators=1600, subsample=0.6\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[CV 1/3; 1/48] START colsample_bytree=0.8, force_col_wise=True, learning_rate=0.005, max_depth=6, n_estimators=800, subsample=0.6\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[CV 3/3; 2/48] START colsample_bytree=0.8, force_col_wise=True, learning_rate=0.005, max_depth=6, n_estimators=800, subsample=0.9\n",
      "[CV 1/3; 2/48] START colsample_bytree=0.8, force_col_wise=True, learning_rate=0.005, max_depth=6, n_estimators=800, subsample=0.9\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[CV 2/3; 6/48] START colsample_bytree=0.8, force_col_wise=True, learning_rate=0.005, max_depth=7, n_estimators=800, subsample=0.9[CV 3/3; 1/48] START colsample_bytree=0.8, force_col_wise=True, learning_rate=0.005, max_depth=6, n_estimators=800, subsample=0.6\n",
      "[CV 2/3; 3/48] START colsample_bytree=0.8, force_col_wise=True, learning_rate=0.005, max_depth=6, n_estimators=1600, subsample=0.6\n",
      "[CV 1/3; 4/48] START colsample_bytree=0.8, force_col_wise=True, learning_rate=0.005, max_depth=6, n_estimators=1600, subsample=0.9\n",
      "\n",
      "[CV 2/3; 2/48] START colsample_bytree=0.8, force_col_wise=True, learning_rate=0.005, max_depth=6, n_estimators=800, subsample=0.9\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[CV 2/3; 5/48] START colsample_bytree=0.8, force_col_wise=True, learning_rate=0.005, max_depth=7, n_estimators=800, subsample=0.6\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[CV 3/3; 5/48] START colsample_bytree=0.8, force_col_wise=True, learning_rate=0.005, max_depth=7, n_estimators=800, subsample=0.6\n",
      "[CV 3/3; 4/48] START colsample_bytree=0.8, force_col_wise=True, learning_rate=0.005, max_depth=6, n_estimators=1600, subsample=0.9\n",
      "[CV 1/3; 6/48] START colsample_bytree=0.8, force_col_wise=True, learning_rate=0.005, max_depth=7, n_estimators=800, subsample=0.9[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Total Bins 1983\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Total Bins 1984\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Total Bins 1983\n",
      "[CV 3/3; 6/48] START colsample_bytree=0.8, force_col_wise=True, learning_rate=0.005, max_depth=7, n_estimators=800, subsample=0.9\n",
      "[LightGBM] [Info] Number of data points in the train set: 26969, number of used features: 13\n",
      "[LightGBM] [Info] Number of data points in the train set: 26970, number of used features: 13\n",
      "[LightGBM] [Info] Number of data points in the train set: 26969, number of used features: 13\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).[LightGBM] [Info] Total Bins 1981\n",
      "\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Total Bins 1981\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Total Bins 1984\n",
      "[LightGBM] [Info] Number of data points in the train set: 26969, number of used features: 13\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Total Bins 1984\n",
      "[LightGBM] [Info] Start training from score 3933.846898\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Total Bins 1981\n",
      "[LightGBM] [Info] Number of data points in the train set: 26969, number of used features: 13\n",
      "[LightGBM] [Info] Number of data points in the train set: 26970, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 3933.846898\n",
      "[LightGBM] [Info] Start training from score 3925.915721\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Total Bins 1983\n",
      "[CV 1/3; 3/48] START colsample_bytree=0.8, force_col_wise=True, learning_rate=0.005, max_depth=6, n_estimators=1600, subsample=0.6\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Total Bins 1983\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Total Bins 1983\n",
      "[CV 1/3; 7/48] START colsample_bytree=0.8, force_col_wise=True, learning_rate=0.005, max_depth=7, n_estimators=1600, subsample=0.6\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Total Bins 1984\n",
      "[CV 2/3; 7/48] START colsample_bytree=0.8, force_col_wise=True, learning_rate=0.005, max_depth=7, n_estimators=1600, subsample=0.6\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Total Bins 1984\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Total Bins 1981\n",
      "[LightGBM] [Info] Number of data points in the train set: 26969, number of used features: 13\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of data points in the train set: 26970, number of used features: 13\n",
      "[LightGBM] [Info] Number of data points in the train set: 26969, number of used features: 13\n",
      "[LightGBM] [Info] Number of data points in the train set: 26970, number of used features: 13\n",
      "[LightGBM] [Info] Number of data points in the train set: 26969, number of used features: 13\n",
      "[LightGBM] [Info] Number of data points in the train set: 26969, number of used features: 13\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Total Bins 1984\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Total Bins 1983\n",
      "[LightGBM] [Info] Number of data points in the train set: 26969, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 3925.545701\n",
      "[LightGBM] [Info] Number of data points in the train set: 26970, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 3925.915721\n",
      "[LightGBM] [Info] Start training from score 3925.545701\n",
      "[LightGBM] [Info] Number of data points in the train set: 26969, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 3925.915721\n",
      "[LightGBM] [Info] Number of data points in the train set: 26970, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 3925.545701\n",
      "[LightGBM] [Info] Start training from score 3925.545701\n",
      "[LightGBM] [Info] Start training from score 3933.846898\n",
      "[LightGBM] [Info] Start training from score 3933.846898\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Total Bins 1981\n",
      "[LightGBM] [Info] Start training from score 3925.915721\n",
      "[CV 1/3; 5/48] START colsample_bytree=0.8, force_col_wise=True, learning_rate=0.005, max_depth=7, n_estimators=800, subsample=0.6\n",
      "[LightGBM] [Info] Start training from score 3933.846898\n",
      "[LightGBM] [Info] Start training from score 3933.846898\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Start training from score 3925.915721\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Total Bins 1981\n",
      "[LightGBM] [Info] Start training from score 3925.915721\n",
      "[LightGBM] [Info] Number of data points in the train set: 26969, number of used features: 13\n",
      "[LightGBM] [Info] Number of data points in the train set: 26969, number of used features: 13\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Total Bins 1983\n",
      "[LightGBM] [Info] Start training from score 3925.545701\n",
      "[LightGBM] [Info] Start training from score 3925.545701\n",
      "[LightGBM] [Info] Number of data points in the train set: 26969, number of used features: 13\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Total Bins 1981\n",
      "[LightGBM] [Info] Number of data points in the train set: 26969, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 3933.846898\n",
      "[LightGBM] [Info] Start training from score 3925.545701\n"
     ]
    }
   ],
   "source": [
    "grid = GridSearchCV(mdl,gridParams_xgb, verbose=-1, cv=3, n_jobs=-1, scoring='neg_root_mean_squared_error')\n",
    "# Run the grid\n",
    "grid.fit(X, y)\n",
    "\n",
    "best_params = grid.best_params_\n",
    "best_score = grid.best_score_\n",
    "\n",
    "print(\"Best parameters found: \", best_params)\n",
    "print(\"Best score found: \", best_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting predicting...\n",
      "The RMSE of prediction is: 520.4485025239875\n"
     ]
    }
   ],
   "source": [
    "print('Starting predicting...')\n",
    "# predict\n",
    "y_pred = gbm.predict(np.array(X_val))\n",
    "# eval\n",
    "rmse_test = root_mean_squared_error(y_val, y_pred) \n",
    "print(f'The RMSE of prediction is: {rmse_test}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = gbm.predict(np.array(X_test))\n",
    "output = pd.DataFrame({'id': list(range(len(preds))),\n",
    "                       'price': preds.squeeze()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2866.552767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5711.512721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>9709.331458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4027.653518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1567.500332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13480</th>\n",
       "      <td>13480</td>\n",
       "      <td>1674.217339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13481</th>\n",
       "      <td>13481</td>\n",
       "      <td>2437.809262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13482</th>\n",
       "      <td>13482</td>\n",
       "      <td>3044.305921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13483</th>\n",
       "      <td>13483</td>\n",
       "      <td>2068.585185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13484</th>\n",
       "      <td>13484</td>\n",
       "      <td>790.586240</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13485 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id        price\n",
       "0          0  2866.552767\n",
       "1          1  5711.512721\n",
       "2          2  9709.331458\n",
       "3          3  4027.653518\n",
       "4          4  1567.500332\n",
       "...      ...          ...\n",
       "13480  13480  1674.217339\n",
       "13481  13481  2437.809262\n",
       "13482  13482  3044.305921\n",
       "13483  13483  2068.585185\n",
       "13484  13484   790.586240\n",
       "\n",
       "[13485 rows x 2 columns]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.to_csv('./submissions/lgbdefdl123fexydatdso3x2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boosting_type': 'gbdt',\n",
       " 'objective': 'regression',\n",
       " 'metric': 'rmse',\n",
       " 'num_iterations': 200}"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = lgb.Dataset('./data/clean/diamondsdlfe2xso.csv', label='price',feature_name=['price', 'carat', 'depth', 'table', 'x', 'y', 'z', 'cut', 'color',\n",
    "       'clarity', 'city', 'x/y', 'td', 'ad'], categorical_feature= ['cut', 'color','clarity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lightgbm.basic.Dataset at 0x7f99568b7670>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data = train_data.create_valid('testdl123fexydatdso3x2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'metric': 'rmse'}\n",
    "num_round = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Construct bin mappers from text data time 0.02 seconds\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Wrong type(str) for label.\nIt should be list, numpy 1-D array or pandas Series",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m bst \u001b[38;5;241m=\u001b[39m \u001b[43mlgb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_round\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_sets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/lightgbm/engine.py:255\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, feval, init_model, feature_name, categorical_feature, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;66;03m# construct booster\u001b[39;00m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 255\u001b[0m     booster \u001b[38;5;241m=\u001b[39m \u001b[43mBooster\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_set\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_valid_contain_train:\n\u001b[1;32m    257\u001b[0m         booster\u001b[38;5;241m.\u001b[39mset_train_data_name(train_data_name)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/lightgbm/basic.py:3433\u001b[0m, in \u001b[0;36mBooster.__init__\u001b[0;34m(self, params, train_set, model_file, model_str)\u001b[0m\n\u001b[1;32m   3426\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_network(\n\u001b[1;32m   3427\u001b[0m         machines\u001b[38;5;241m=\u001b[39mmachines,\n\u001b[1;32m   3428\u001b[0m         local_listen_port\u001b[38;5;241m=\u001b[39mparams[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlocal_listen_port\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   3429\u001b[0m         listen_time_out\u001b[38;5;241m=\u001b[39mparams\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtime_out\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m120\u001b[39m),\n\u001b[1;32m   3430\u001b[0m         num_machines\u001b[38;5;241m=\u001b[39mparams[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_machines\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   3431\u001b[0m     )\n\u001b[1;32m   3432\u001b[0m \u001b[38;5;66;03m# construct booster object\u001b[39;00m\n\u001b[0;32m-> 3433\u001b[0m \u001b[43mtrain_set\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconstruct\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3434\u001b[0m \u001b[38;5;66;03m# copy the parameters from train_set\u001b[39;00m\n\u001b[1;32m   3435\u001b[0m params\u001b[38;5;241m.\u001b[39mupdate(train_set\u001b[38;5;241m.\u001b[39mget_params())\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/lightgbm/basic.py:2462\u001b[0m, in \u001b[0;36mDataset.construct\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2455\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_init_score_by_predictor(\n\u001b[1;32m   2456\u001b[0m                 predictor\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predictor,\n\u001b[1;32m   2457\u001b[0m                 data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata,\n\u001b[1;32m   2458\u001b[0m                 used_indices\u001b[38;5;241m=\u001b[39mused_indices\n\u001b[1;32m   2459\u001b[0m             )\n\u001b[1;32m   2460\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2461\u001b[0m     \u001b[38;5;66;03m# create train\u001b[39;00m\n\u001b[0;32m-> 2462\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_lazy_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreference\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2463\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2464\u001b[0m \u001b[43m                    \u001b[49m\u001b[43minit_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredictor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predictor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2465\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mfeature_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcategorical_feature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcategorical_feature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2466\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mposition\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mposition\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2467\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfree_raw_data:\n\u001b[1;32m   2468\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/lightgbm/basic.py:2101\u001b[0m, in \u001b[0;36mDataset._lazy_init\u001b[0;34m(self, data, label, reference, weight, group, init_score, predictor, feature_name, categorical_feature, params, position)\u001b[0m\n\u001b[1;32m   2099\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCannot initialize Dataset from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(data)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   2100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m label \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 2101\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_label\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2102\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_label() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2103\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLabel should not be None\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/lightgbm/basic.py:2891\u001b[0m, in \u001b[0;36mDataset.set_label\u001b[0;34m(self, label)\u001b[0m\n\u001b[1;32m   2889\u001b[0m     label_array \u001b[38;5;241m=\u001b[39m label\n\u001b[1;32m   2890\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2891\u001b[0m     label_array \u001b[38;5;241m=\u001b[39m \u001b[43m_list_to_1d_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlabel\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2892\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_field(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m, label_array)\n\u001b[1;32m   2893\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_field(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# original values can be modified at cpp side\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/lightgbm/basic.py:344\u001b[0m, in \u001b[0;36m_list_to_1d_numpy\u001b[0;34m(data, dtype, name)\u001b[0m\n\u001b[1;32m    342\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(data, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)  \u001b[38;5;66;03m# SparseArray should be supported as well\u001b[39;00m\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 344\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWrong type(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(data)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    345\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt should be list, numpy 1-D array or pandas Series\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: Wrong type(str) for label.\nIt should be list, numpy 1-D array or pandas Series"
     ]
    }
   ],
   "source": [
    "bst = lgb.train(param, train_data, num_round, valid_sets=[validation_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
