{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler\n",
    "from sklearn.model_selection import GridSearchCV, cross_validate, train_test_split\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBRegressor, plot_importance\n",
    "import sqlite3 as lite\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = lite.connect('./data/src/diamonds_train.db/diamonds_train.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor = con.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df = pd.read_sql('''SELECT *\n",
    "FROM diamonds_transactional dt JOIN diamonds_dimensions ddi \n",
    "\t\tON dt.index_id = ddi.index_id \n",
    "\tJOIN diamonds_properties dp ON dp.index_id = dt.index_id \n",
    "\tJOIN diamonds_cut dc ON dc.cut_id = dp.cut_id \n",
    "\tJOIN diamonds_color dc2 ON dc2.color_id = dp.color_id \n",
    "\tJOIN diamonds_clarity dc3 ON dc3.clarity_id = dp.clarity_id \n",
    "\tJOIN diamonds_city dc4 ON dc4.city_id = dt.city_id;''', con )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index_id</th>\n",
       "      <th>price</th>\n",
       "      <th>city_id</th>\n",
       "      <th>carat</th>\n",
       "      <th>index_id</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>...</th>\n",
       "      <th>color_id</th>\n",
       "      <th>clarity_id</th>\n",
       "      <th>cut_id</th>\n",
       "      <th>cut</th>\n",
       "      <th>color_id</th>\n",
       "      <th>color</th>\n",
       "      <th>clarity_id</th>\n",
       "      <th>clarity</th>\n",
       "      <th>city_id</th>\n",
       "      <th>city</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91...</td>\n",
       "      <td>4268</td>\n",
       "      <td>6c425048aa7badd9d84615bd8620ca1864efd81cfdb69d...</td>\n",
       "      <td>1.21</td>\n",
       "      <td>5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91...</td>\n",
       "      <td>62.4</td>\n",
       "      <td>58.0</td>\n",
       "      <td>6.83</td>\n",
       "      <td>6.79</td>\n",
       "      <td>4.25</td>\n",
       "      <td>...</td>\n",
       "      <td>6da43b944e494e885e69af021f93c6d9331c78aa228084...</td>\n",
       "      <td>f0b2a1d0db08cc64f85d74f1d15c2191e0e49039f4d8f2...</td>\n",
       "      <td>de88c121a82a06352bf1aaceba20578356408a334ba046...</td>\n",
       "      <td>Premium</td>\n",
       "      <td>6da43b944e494e885e69af021f93c6d9331c78aa228084...</td>\n",
       "      <td>J</td>\n",
       "      <td>f0b2a1d0db08cc64f85d74f1d15c2191e0e49039f4d8f2...</td>\n",
       "      <td>VS2</td>\n",
       "      <td>6c425048aa7badd9d84615bd8620ca1864efd81cfdb69d...</td>\n",
       "      <td>Dubai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d...</td>\n",
       "      <td>505</td>\n",
       "      <td>89c7286890f7347ab235234e74d406596a127ae3679042...</td>\n",
       "      <td>0.32</td>\n",
       "      <td>6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d...</td>\n",
       "      <td>63.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>4.35</td>\n",
       "      <td>4.38</td>\n",
       "      <td>2.75</td>\n",
       "      <td>...</td>\n",
       "      <td>44bd7ae60f478fae1061e11a7739f4b94d1daf917982d3...</td>\n",
       "      <td>f0b2a1d0db08cc64f85d74f1d15c2191e0e49039f4d8f2...</td>\n",
       "      <td>388655e25e91872329272fc10128ef5354b3b19a05d7e8...</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>44bd7ae60f478fae1061e11a7739f4b94d1daf917982d3...</td>\n",
       "      <td>H</td>\n",
       "      <td>f0b2a1d0db08cc64f85d74f1d15c2191e0e49039f4d8f2...</td>\n",
       "      <td>VS2</td>\n",
       "      <td>89c7286890f7347ab235234e74d406596a127ae3679042...</td>\n",
       "      <td>Kimberly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f...</td>\n",
       "      <td>2686</td>\n",
       "      <td>2bd25cd960aba8b706e2b67f2bb38b750ee5384b0e9883...</td>\n",
       "      <td>0.71</td>\n",
       "      <td>d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f...</td>\n",
       "      <td>65.5</td>\n",
       "      <td>55.0</td>\n",
       "      <td>5.62</td>\n",
       "      <td>5.53</td>\n",
       "      <td>3.65</td>\n",
       "      <td>...</td>\n",
       "      <td>333e0a1e27815d0ceee55c473fe3dc93d56c63e3bee2b3...</td>\n",
       "      <td>ef736c1f91cd1900c3d9cde925b1bf4f013adc0211a9ee...</td>\n",
       "      <td>f7b19afcde965ea4942b878d266f89f8ba9a5a833e60f7...</td>\n",
       "      <td>Fair</td>\n",
       "      <td>333e0a1e27815d0ceee55c473fe3dc93d56c63e3bee2b3...</td>\n",
       "      <td>G</td>\n",
       "      <td>ef736c1f91cd1900c3d9cde925b1bf4f013adc0211a9ee...</td>\n",
       "      <td>VS1</td>\n",
       "      <td>2bd25cd960aba8b706e2b67f2bb38b750ee5384b0e9883...</td>\n",
       "      <td>Las Vegas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4e07408562bedb8b60ce05c1decfe3ad16b72230967de0...</td>\n",
       "      <td>738</td>\n",
       "      <td>89c7286890f7347ab235234e74d406596a127ae3679042...</td>\n",
       "      <td>0.41</td>\n",
       "      <td>4e07408562bedb8b60ce05c1decfe3ad16b72230967de0...</td>\n",
       "      <td>63.8</td>\n",
       "      <td>56.0</td>\n",
       "      <td>4.68</td>\n",
       "      <td>4.72</td>\n",
       "      <td>3.00</td>\n",
       "      <td>...</td>\n",
       "      <td>3f39d5c348e5b79d06e842c114e6cc571583bbf44e4b0e...</td>\n",
       "      <td>bd4f4a250da88f87729febc739ae97f439a14f9d38f0e3...</td>\n",
       "      <td>c939327ca16dcf97ca32521d8b834bf1de16573d21deda...</td>\n",
       "      <td>Good</td>\n",
       "      <td>3f39d5c348e5b79d06e842c114e6cc571583bbf44e4b0e...</td>\n",
       "      <td>D</td>\n",
       "      <td>bd4f4a250da88f87729febc739ae97f439a14f9d38f0e3...</td>\n",
       "      <td>SI1</td>\n",
       "      <td>89c7286890f7347ab235234e74d406596a127ae3679042...</td>\n",
       "      <td>Kimberly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4b227777d4dd1fc61c6f884f48641d02b4d121d3fd328c...</td>\n",
       "      <td>4882</td>\n",
       "      <td>6c425048aa7badd9d84615bd8620ca1864efd81cfdb69d...</td>\n",
       "      <td>1.02</td>\n",
       "      <td>4b227777d4dd1fc61c6f884f48641d02b4d121d3fd328c...</td>\n",
       "      <td>60.5</td>\n",
       "      <td>59.0</td>\n",
       "      <td>6.55</td>\n",
       "      <td>6.51</td>\n",
       "      <td>3.95</td>\n",
       "      <td>...</td>\n",
       "      <td>333e0a1e27815d0ceee55c473fe3dc93d56c63e3bee2b3...</td>\n",
       "      <td>bd4f4a250da88f87729febc739ae97f439a14f9d38f0e3...</td>\n",
       "      <td>4e3cfaa334cbafb57a399a98fad8d3812ece460018f457...</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>333e0a1e27815d0ceee55c473fe3dc93d56c63e3bee2b3...</td>\n",
       "      <td>G</td>\n",
       "      <td>bd4f4a250da88f87729febc739ae97f439a14f9d38f0e3...</td>\n",
       "      <td>SI1</td>\n",
       "      <td>6c425048aa7badd9d84615bd8620ca1864efd81cfdb69d...</td>\n",
       "      <td>Dubai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40450</th>\n",
       "      <td>f0bc79169405ebeb24e308055156b946ffd819db9b4f75...</td>\n",
       "      <td>10070</td>\n",
       "      <td>ca3aa21a5b70c3e88cc6336682c8c7da928a0c66a5ead4...</td>\n",
       "      <td>1.34</td>\n",
       "      <td>f0bc79169405ebeb24e308055156b946ffd819db9b4f75...</td>\n",
       "      <td>62.7</td>\n",
       "      <td>57.0</td>\n",
       "      <td>7.10</td>\n",
       "      <td>7.04</td>\n",
       "      <td>4.43</td>\n",
       "      <td>...</td>\n",
       "      <td>333e0a1e27815d0ceee55c473fe3dc93d56c63e3bee2b3...</td>\n",
       "      <td>ef736c1f91cd1900c3d9cde925b1bf4f013adc0211a9ee...</td>\n",
       "      <td>4e3cfaa334cbafb57a399a98fad8d3812ece460018f457...</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>333e0a1e27815d0ceee55c473fe3dc93d56c63e3bee2b3...</td>\n",
       "      <td>G</td>\n",
       "      <td>ef736c1f91cd1900c3d9cde925b1bf4f013adc0211a9ee...</td>\n",
       "      <td>VS1</td>\n",
       "      <td>ca3aa21a5b70c3e88cc6336682c8c7da928a0c66a5ead4...</td>\n",
       "      <td>Antwerp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40451</th>\n",
       "      <td>339916a23bf22b052b54cb2a9b36ee8418c1c68b46acad...</td>\n",
       "      <td>12615</td>\n",
       "      <td>e9c722cbefc2f055ae60b4e2cbe73a2d99537eab0c37f3...</td>\n",
       "      <td>2.02</td>\n",
       "      <td>339916a23bf22b052b54cb2a9b36ee8418c1c68b46acad...</td>\n",
       "      <td>57.1</td>\n",
       "      <td>60.0</td>\n",
       "      <td>8.31</td>\n",
       "      <td>8.25</td>\n",
       "      <td>4.73</td>\n",
       "      <td>...</td>\n",
       "      <td>f67ab10ad4e4c53121b6a5fe4da9c10ddee905b978d378...</td>\n",
       "      <td>03c358cbd92e83278fd523f58dc6a9b4b198d00728af65...</td>\n",
       "      <td>c939327ca16dcf97ca32521d8b834bf1de16573d21deda...</td>\n",
       "      <td>Good</td>\n",
       "      <td>f67ab10ad4e4c53121b6a5fe4da9c10ddee905b978d378...</td>\n",
       "      <td>F</td>\n",
       "      <td>03c358cbd92e83278fd523f58dc6a9b4b198d00728af65...</td>\n",
       "      <td>SI2</td>\n",
       "      <td>e9c722cbefc2f055ae60b4e2cbe73a2d99537eab0c37f3...</td>\n",
       "      <td>Madrid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40452</th>\n",
       "      <td>46957922b99954654c1deb8d854c3f069bf118b2ce9415...</td>\n",
       "      <td>5457</td>\n",
       "      <td>89c7286890f7347ab235234e74d406596a127ae3679042...</td>\n",
       "      <td>1.01</td>\n",
       "      <td>46957922b99954654c1deb8d854c3f069bf118b2ce9415...</td>\n",
       "      <td>62.7</td>\n",
       "      <td>56.0</td>\n",
       "      <td>6.37</td>\n",
       "      <td>6.42</td>\n",
       "      <td>4.01</td>\n",
       "      <td>...</td>\n",
       "      <td>44bd7ae60f478fae1061e11a7739f4b94d1daf917982d3...</td>\n",
       "      <td>bd4f4a250da88f87729febc739ae97f439a14f9d38f0e3...</td>\n",
       "      <td>4e3cfaa334cbafb57a399a98fad8d3812ece460018f457...</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>44bd7ae60f478fae1061e11a7739f4b94d1daf917982d3...</td>\n",
       "      <td>H</td>\n",
       "      <td>bd4f4a250da88f87729febc739ae97f439a14f9d38f0e3...</td>\n",
       "      <td>SI1</td>\n",
       "      <td>89c7286890f7347ab235234e74d406596a127ae3679042...</td>\n",
       "      <td>Kimberly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40453</th>\n",
       "      <td>9d733392d362d5c6f1d9b9659b601c7d4b5a1c1c8df579...</td>\n",
       "      <td>456</td>\n",
       "      <td>89c7286890f7347ab235234e74d406596a127ae3679042...</td>\n",
       "      <td>0.33</td>\n",
       "      <td>9d733392d362d5c6f1d9b9659b601c7d4b5a1c1c8df579...</td>\n",
       "      <td>61.9</td>\n",
       "      <td>54.3</td>\n",
       "      <td>4.45</td>\n",
       "      <td>4.47</td>\n",
       "      <td>2.76</td>\n",
       "      <td>...</td>\n",
       "      <td>6da43b944e494e885e69af021f93c6d9331c78aa228084...</td>\n",
       "      <td>ef736c1f91cd1900c3d9cde925b1bf4f013adc0211a9ee...</td>\n",
       "      <td>4e3cfaa334cbafb57a399a98fad8d3812ece460018f457...</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>6da43b944e494e885e69af021f93c6d9331c78aa228084...</td>\n",
       "      <td>J</td>\n",
       "      <td>ef736c1f91cd1900c3d9cde925b1bf4f013adc0211a9ee...</td>\n",
       "      <td>VS1</td>\n",
       "      <td>89c7286890f7347ab235234e74d406596a127ae3679042...</td>\n",
       "      <td>Kimberly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40454</th>\n",
       "      <td>a02744a70faa594d240b067f21fcc23a8d17cd1098a9fb...</td>\n",
       "      <td>6232</td>\n",
       "      <td>ecc0e7dc084f141b29479058967d0bc07dee25d9690a98...</td>\n",
       "      <td>1.24</td>\n",
       "      <td>a02744a70faa594d240b067f21fcc23a8d17cd1098a9fb...</td>\n",
       "      <td>62.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>6.83</td>\n",
       "      <td>6.88</td>\n",
       "      <td>4.25</td>\n",
       "      <td>...</td>\n",
       "      <td>a83dd0ccbffe39d071cc317ddf6e97f5c6b1c87af91919...</td>\n",
       "      <td>bd4f4a250da88f87729febc739ae97f439a14f9d38f0e3...</td>\n",
       "      <td>4e3cfaa334cbafb57a399a98fad8d3812ece460018f457...</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>a83dd0ccbffe39d071cc317ddf6e97f5c6b1c87af91919...</td>\n",
       "      <td>I</td>\n",
       "      <td>bd4f4a250da88f87729febc739ae97f439a14f9d38f0e3...</td>\n",
       "      <td>SI1</td>\n",
       "      <td>ecc0e7dc084f141b29479058967d0bc07dee25d9690a98...</td>\n",
       "      <td>London</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40455 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                index_id  price  \\\n",
       "0      5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91...   4268   \n",
       "1      6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d...    505   \n",
       "2      d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f...   2686   \n",
       "3      4e07408562bedb8b60ce05c1decfe3ad16b72230967de0...    738   \n",
       "4      4b227777d4dd1fc61c6f884f48641d02b4d121d3fd328c...   4882   \n",
       "...                                                  ...    ...   \n",
       "40450  f0bc79169405ebeb24e308055156b946ffd819db9b4f75...  10070   \n",
       "40451  339916a23bf22b052b54cb2a9b36ee8418c1c68b46acad...  12615   \n",
       "40452  46957922b99954654c1deb8d854c3f069bf118b2ce9415...   5457   \n",
       "40453  9d733392d362d5c6f1d9b9659b601c7d4b5a1c1c8df579...    456   \n",
       "40454  a02744a70faa594d240b067f21fcc23a8d17cd1098a9fb...   6232   \n",
       "\n",
       "                                                 city_id  carat  \\\n",
       "0      6c425048aa7badd9d84615bd8620ca1864efd81cfdb69d...   1.21   \n",
       "1      89c7286890f7347ab235234e74d406596a127ae3679042...   0.32   \n",
       "2      2bd25cd960aba8b706e2b67f2bb38b750ee5384b0e9883...   0.71   \n",
       "3      89c7286890f7347ab235234e74d406596a127ae3679042...   0.41   \n",
       "4      6c425048aa7badd9d84615bd8620ca1864efd81cfdb69d...   1.02   \n",
       "...                                                  ...    ...   \n",
       "40450  ca3aa21a5b70c3e88cc6336682c8c7da928a0c66a5ead4...   1.34   \n",
       "40451  e9c722cbefc2f055ae60b4e2cbe73a2d99537eab0c37f3...   2.02   \n",
       "40452  89c7286890f7347ab235234e74d406596a127ae3679042...   1.01   \n",
       "40453  89c7286890f7347ab235234e74d406596a127ae3679042...   0.33   \n",
       "40454  ecc0e7dc084f141b29479058967d0bc07dee25d9690a98...   1.24   \n",
       "\n",
       "                                                index_id  depth  table     x  \\\n",
       "0      5feceb66ffc86f38d952786c6d696c79c2dbc239dd4e91...   62.4   58.0  6.83   \n",
       "1      6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d...   63.0   57.0  4.35   \n",
       "2      d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f...   65.5   55.0  5.62   \n",
       "3      4e07408562bedb8b60ce05c1decfe3ad16b72230967de0...   63.8   56.0  4.68   \n",
       "4      4b227777d4dd1fc61c6f884f48641d02b4d121d3fd328c...   60.5   59.0  6.55   \n",
       "...                                                  ...    ...    ...   ...   \n",
       "40450  f0bc79169405ebeb24e308055156b946ffd819db9b4f75...   62.7   57.0  7.10   \n",
       "40451  339916a23bf22b052b54cb2a9b36ee8418c1c68b46acad...   57.1   60.0  8.31   \n",
       "40452  46957922b99954654c1deb8d854c3f069bf118b2ce9415...   62.7   56.0  6.37   \n",
       "40453  9d733392d362d5c6f1d9b9659b601c7d4b5a1c1c8df579...   61.9   54.3  4.45   \n",
       "40454  a02744a70faa594d240b067f21fcc23a8d17cd1098a9fb...   62.0   58.0  6.83   \n",
       "\n",
       "          y     z  ...                                           color_id  \\\n",
       "0      6.79  4.25  ...  6da43b944e494e885e69af021f93c6d9331c78aa228084...   \n",
       "1      4.38  2.75  ...  44bd7ae60f478fae1061e11a7739f4b94d1daf917982d3...   \n",
       "2      5.53  3.65  ...  333e0a1e27815d0ceee55c473fe3dc93d56c63e3bee2b3...   \n",
       "3      4.72  3.00  ...  3f39d5c348e5b79d06e842c114e6cc571583bbf44e4b0e...   \n",
       "4      6.51  3.95  ...  333e0a1e27815d0ceee55c473fe3dc93d56c63e3bee2b3...   \n",
       "...     ...   ...  ...                                                ...   \n",
       "40450  7.04  4.43  ...  333e0a1e27815d0ceee55c473fe3dc93d56c63e3bee2b3...   \n",
       "40451  8.25  4.73  ...  f67ab10ad4e4c53121b6a5fe4da9c10ddee905b978d378...   \n",
       "40452  6.42  4.01  ...  44bd7ae60f478fae1061e11a7739f4b94d1daf917982d3...   \n",
       "40453  4.47  2.76  ...  6da43b944e494e885e69af021f93c6d9331c78aa228084...   \n",
       "40454  6.88  4.25  ...  a83dd0ccbffe39d071cc317ddf6e97f5c6b1c87af91919...   \n",
       "\n",
       "                                              clarity_id  \\\n",
       "0      f0b2a1d0db08cc64f85d74f1d15c2191e0e49039f4d8f2...   \n",
       "1      f0b2a1d0db08cc64f85d74f1d15c2191e0e49039f4d8f2...   \n",
       "2      ef736c1f91cd1900c3d9cde925b1bf4f013adc0211a9ee...   \n",
       "3      bd4f4a250da88f87729febc739ae97f439a14f9d38f0e3...   \n",
       "4      bd4f4a250da88f87729febc739ae97f439a14f9d38f0e3...   \n",
       "...                                                  ...   \n",
       "40450  ef736c1f91cd1900c3d9cde925b1bf4f013adc0211a9ee...   \n",
       "40451  03c358cbd92e83278fd523f58dc6a9b4b198d00728af65...   \n",
       "40452  bd4f4a250da88f87729febc739ae97f439a14f9d38f0e3...   \n",
       "40453  ef736c1f91cd1900c3d9cde925b1bf4f013adc0211a9ee...   \n",
       "40454  bd4f4a250da88f87729febc739ae97f439a14f9d38f0e3...   \n",
       "\n",
       "                                                  cut_id        cut  \\\n",
       "0      de88c121a82a06352bf1aaceba20578356408a334ba046...    Premium   \n",
       "1      388655e25e91872329272fc10128ef5354b3b19a05d7e8...  Very Good   \n",
       "2      f7b19afcde965ea4942b878d266f89f8ba9a5a833e60f7...       Fair   \n",
       "3      c939327ca16dcf97ca32521d8b834bf1de16573d21deda...       Good   \n",
       "4      4e3cfaa334cbafb57a399a98fad8d3812ece460018f457...      Ideal   \n",
       "...                                                  ...        ...   \n",
       "40450  4e3cfaa334cbafb57a399a98fad8d3812ece460018f457...      Ideal   \n",
       "40451  c939327ca16dcf97ca32521d8b834bf1de16573d21deda...       Good   \n",
       "40452  4e3cfaa334cbafb57a399a98fad8d3812ece460018f457...      Ideal   \n",
       "40453  4e3cfaa334cbafb57a399a98fad8d3812ece460018f457...      Ideal   \n",
       "40454  4e3cfaa334cbafb57a399a98fad8d3812ece460018f457...      Ideal   \n",
       "\n",
       "                                                color_id color  \\\n",
       "0      6da43b944e494e885e69af021f93c6d9331c78aa228084...     J   \n",
       "1      44bd7ae60f478fae1061e11a7739f4b94d1daf917982d3...     H   \n",
       "2      333e0a1e27815d0ceee55c473fe3dc93d56c63e3bee2b3...     G   \n",
       "3      3f39d5c348e5b79d06e842c114e6cc571583bbf44e4b0e...     D   \n",
       "4      333e0a1e27815d0ceee55c473fe3dc93d56c63e3bee2b3...     G   \n",
       "...                                                  ...   ...   \n",
       "40450  333e0a1e27815d0ceee55c473fe3dc93d56c63e3bee2b3...     G   \n",
       "40451  f67ab10ad4e4c53121b6a5fe4da9c10ddee905b978d378...     F   \n",
       "40452  44bd7ae60f478fae1061e11a7739f4b94d1daf917982d3...     H   \n",
       "40453  6da43b944e494e885e69af021f93c6d9331c78aa228084...     J   \n",
       "40454  a83dd0ccbffe39d071cc317ddf6e97f5c6b1c87af91919...     I   \n",
       "\n",
       "                                              clarity_id clarity  \\\n",
       "0      f0b2a1d0db08cc64f85d74f1d15c2191e0e49039f4d8f2...     VS2   \n",
       "1      f0b2a1d0db08cc64f85d74f1d15c2191e0e49039f4d8f2...     VS2   \n",
       "2      ef736c1f91cd1900c3d9cde925b1bf4f013adc0211a9ee...     VS1   \n",
       "3      bd4f4a250da88f87729febc739ae97f439a14f9d38f0e3...     SI1   \n",
       "4      bd4f4a250da88f87729febc739ae97f439a14f9d38f0e3...     SI1   \n",
       "...                                                  ...     ...   \n",
       "40450  ef736c1f91cd1900c3d9cde925b1bf4f013adc0211a9ee...     VS1   \n",
       "40451  03c358cbd92e83278fd523f58dc6a9b4b198d00728af65...     SI2   \n",
       "40452  bd4f4a250da88f87729febc739ae97f439a14f9d38f0e3...     SI1   \n",
       "40453  ef736c1f91cd1900c3d9cde925b1bf4f013adc0211a9ee...     VS1   \n",
       "40454  bd4f4a250da88f87729febc739ae97f439a14f9d38f0e3...     SI1   \n",
       "\n",
       "                                                 city_id       city  \n",
       "0      6c425048aa7badd9d84615bd8620ca1864efd81cfdb69d...      Dubai  \n",
       "1      89c7286890f7347ab235234e74d406596a127ae3679042...   Kimberly  \n",
       "2      2bd25cd960aba8b706e2b67f2bb38b750ee5384b0e9883...  Las Vegas  \n",
       "3      89c7286890f7347ab235234e74d406596a127ae3679042...   Kimberly  \n",
       "4      6c425048aa7badd9d84615bd8620ca1864efd81cfdb69d...      Dubai  \n",
       "...                                                  ...        ...  \n",
       "40450  ca3aa21a5b70c3e88cc6336682c8c7da928a0c66a5ead4...    Antwerp  \n",
       "40451  e9c722cbefc2f055ae60b4e2cbe73a2d99537eab0c37f3...     Madrid  \n",
       "40452  89c7286890f7347ab235234e74d406596a127ae3679042...   Kimberly  \n",
       "40453  89c7286890f7347ab235234e74d406596a127ae3679042...   Kimberly  \n",
       "40454  ecc0e7dc084f141b29479058967d0bc07dee25d9690a98...     London  \n",
       "\n",
       "[40455 rows x 22 columns]"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>carat</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>40455.000000</td>\n",
       "      <td>40455.000000</td>\n",
       "      <td>40455.000000</td>\n",
       "      <td>40455.000000</td>\n",
       "      <td>40455.000000</td>\n",
       "      <td>40455.000000</td>\n",
       "      <td>40455.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3928.444469</td>\n",
       "      <td>0.797706</td>\n",
       "      <td>61.752841</td>\n",
       "      <td>57.446133</td>\n",
       "      <td>5.729392</td>\n",
       "      <td>5.732819</td>\n",
       "      <td>3.537154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3992.416147</td>\n",
       "      <td>0.475544</td>\n",
       "      <td>1.431725</td>\n",
       "      <td>2.233535</td>\n",
       "      <td>1.124453</td>\n",
       "      <td>1.146650</td>\n",
       "      <td>0.697062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>326.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>945.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>4.710000</td>\n",
       "      <td>4.720000</td>\n",
       "      <td>2.910000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2397.000000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>61.800000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>5.690000</td>\n",
       "      <td>5.710000</td>\n",
       "      <td>3.520000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5331.000000</td>\n",
       "      <td>1.040000</td>\n",
       "      <td>62.500000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>6.540000</td>\n",
       "      <td>6.540000</td>\n",
       "      <td>4.035000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>18823.000000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>10.230000</td>\n",
       "      <td>58.900000</td>\n",
       "      <td>8.060000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              price         carat         depth         table             x  \\\n",
       "count  40455.000000  40455.000000  40455.000000  40455.000000  40455.000000   \n",
       "mean    3928.444469      0.797706     61.752841     57.446133      5.729392   \n",
       "std     3992.416147      0.475544      1.431725      2.233535      1.124453   \n",
       "min      326.000000      0.200000     43.000000     43.000000      0.000000   \n",
       "25%      945.000000      0.400000     61.000000     56.000000      4.710000   \n",
       "50%     2397.000000      0.700000     61.800000     57.000000      5.690000   \n",
       "75%     5331.000000      1.040000     62.500000     59.000000      6.540000   \n",
       "max    18823.000000      4.500000     79.000000     95.000000     10.230000   \n",
       "\n",
       "                  y             z  \n",
       "count  40455.000000  40455.000000  \n",
       "mean       5.732819      3.537154  \n",
       "std        1.146650      0.697062  \n",
       "min        0.000000      0.000000  \n",
       "25%        4.720000      2.910000  \n",
       "50%        5.710000      3.520000  \n",
       "75%        6.540000      4.035000  \n",
       "max       58.900000      8.060000  "
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    13485.000000\n",
       "mean         4.420912\n",
       "std          1.700614\n",
       "min          1.000000\n",
       "25%          3.000000\n",
       "50%          4.000000\n",
       "75%          6.000000\n",
       "max          7.000000\n",
       "Name: color, dtype: float64"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['color'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['index_id', 'price', 'city_id', 'carat', 'index_id', 'depth', 'table',\n",
       "       'x', 'y', 'z', 'index_id', 'cut_id', 'color_id', 'clarity_id', 'cut_id',\n",
       "       'cut', 'color_id', 'color', 'clarity_id', 'clarity', 'city_id', 'city'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = raw_df[ ['price', 'carat',  'depth', 'table','x', 'y', 'z','cut', 'color', 'clarity', 'city']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>carat</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>cut</th>\n",
       "      <th>color</th>\n",
       "      <th>clarity</th>\n",
       "      <th>city</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4268</td>\n",
       "      <td>1.21</td>\n",
       "      <td>62.4</td>\n",
       "      <td>58.0</td>\n",
       "      <td>6.83</td>\n",
       "      <td>6.79</td>\n",
       "      <td>4.25</td>\n",
       "      <td>Premium</td>\n",
       "      <td>J</td>\n",
       "      <td>VS2</td>\n",
       "      <td>Dubai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>505</td>\n",
       "      <td>0.32</td>\n",
       "      <td>63.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>4.35</td>\n",
       "      <td>4.38</td>\n",
       "      <td>2.75</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>H</td>\n",
       "      <td>VS2</td>\n",
       "      <td>Kimberly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2686</td>\n",
       "      <td>0.71</td>\n",
       "      <td>65.5</td>\n",
       "      <td>55.0</td>\n",
       "      <td>5.62</td>\n",
       "      <td>5.53</td>\n",
       "      <td>3.65</td>\n",
       "      <td>Fair</td>\n",
       "      <td>G</td>\n",
       "      <td>VS1</td>\n",
       "      <td>Las Vegas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>738</td>\n",
       "      <td>0.41</td>\n",
       "      <td>63.8</td>\n",
       "      <td>56.0</td>\n",
       "      <td>4.68</td>\n",
       "      <td>4.72</td>\n",
       "      <td>3.00</td>\n",
       "      <td>Good</td>\n",
       "      <td>D</td>\n",
       "      <td>SI1</td>\n",
       "      <td>Kimberly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4882</td>\n",
       "      <td>1.02</td>\n",
       "      <td>60.5</td>\n",
       "      <td>59.0</td>\n",
       "      <td>6.55</td>\n",
       "      <td>6.51</td>\n",
       "      <td>3.95</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>G</td>\n",
       "      <td>SI1</td>\n",
       "      <td>Dubai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40450</th>\n",
       "      <td>10070</td>\n",
       "      <td>1.34</td>\n",
       "      <td>62.7</td>\n",
       "      <td>57.0</td>\n",
       "      <td>7.10</td>\n",
       "      <td>7.04</td>\n",
       "      <td>4.43</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>G</td>\n",
       "      <td>VS1</td>\n",
       "      <td>Antwerp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40451</th>\n",
       "      <td>12615</td>\n",
       "      <td>2.02</td>\n",
       "      <td>57.1</td>\n",
       "      <td>60.0</td>\n",
       "      <td>8.31</td>\n",
       "      <td>8.25</td>\n",
       "      <td>4.73</td>\n",
       "      <td>Good</td>\n",
       "      <td>F</td>\n",
       "      <td>SI2</td>\n",
       "      <td>Madrid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40452</th>\n",
       "      <td>5457</td>\n",
       "      <td>1.01</td>\n",
       "      <td>62.7</td>\n",
       "      <td>56.0</td>\n",
       "      <td>6.37</td>\n",
       "      <td>6.42</td>\n",
       "      <td>4.01</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>H</td>\n",
       "      <td>SI1</td>\n",
       "      <td>Kimberly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40453</th>\n",
       "      <td>456</td>\n",
       "      <td>0.33</td>\n",
       "      <td>61.9</td>\n",
       "      <td>54.3</td>\n",
       "      <td>4.45</td>\n",
       "      <td>4.47</td>\n",
       "      <td>2.76</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>J</td>\n",
       "      <td>VS1</td>\n",
       "      <td>Kimberly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40454</th>\n",
       "      <td>6232</td>\n",
       "      <td>1.24</td>\n",
       "      <td>62.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>6.83</td>\n",
       "      <td>6.88</td>\n",
       "      <td>4.25</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>I</td>\n",
       "      <td>SI1</td>\n",
       "      <td>London</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40455 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       price  carat  depth  table     x     y     z        cut color clarity  \\\n",
       "0       4268   1.21   62.4   58.0  6.83  6.79  4.25    Premium     J     VS2   \n",
       "1        505   0.32   63.0   57.0  4.35  4.38  2.75  Very Good     H     VS2   \n",
       "2       2686   0.71   65.5   55.0  5.62  5.53  3.65       Fair     G     VS1   \n",
       "3        738   0.41   63.8   56.0  4.68  4.72  3.00       Good     D     SI1   \n",
       "4       4882   1.02   60.5   59.0  6.55  6.51  3.95      Ideal     G     SI1   \n",
       "...      ...    ...    ...    ...   ...   ...   ...        ...   ...     ...   \n",
       "40450  10070   1.34   62.7   57.0  7.10  7.04  4.43      Ideal     G     VS1   \n",
       "40451  12615   2.02   57.1   60.0  8.31  8.25  4.73       Good     F     SI2   \n",
       "40452   5457   1.01   62.7   56.0  6.37  6.42  4.01      Ideal     H     SI1   \n",
       "40453    456   0.33   61.9   54.3  4.45  4.47  2.76      Ideal     J     VS1   \n",
       "40454   6232   1.24   62.0   58.0  6.83  6.88  4.25      Ideal     I     SI1   \n",
       "\n",
       "            city  \n",
       "0          Dubai  \n",
       "1       Kimberly  \n",
       "2      Las Vegas  \n",
       "3       Kimberly  \n",
       "4          Dubai  \n",
       "...          ...  \n",
       "40450    Antwerp  \n",
       "40451     Madrid  \n",
       "40452   Kimberly  \n",
       "40453   Kimberly  \n",
       "40454     London  \n",
       "\n",
       "[40455 rows x 11 columns]"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df.to_csv('./data/clean/clean.csv')\n",
    "clean_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_labeling(df, cols):\n",
    "   dic = {}\n",
    "   for col in cols:\n",
    "      group_by = df[[col,'price']].groupby(col).median().sort_values('price')\n",
    "      for key in group_by.index:\n",
    "         dic[key] = sorted(list(group_by['price'])).index(group_by.loc[key,'price']) + 1\n",
    "      print(dic)\n",
    "      for key,value in dic.items():\n",
    "         df.loc[df[col] == key,col] = value\n",
    "      df[col] = df[col].astype(float)\n",
    "   return dic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_labeling_test(df, cols, dic):\n",
    "   for col in cols:\n",
    "      for key,value in dic.items():\n",
    "         df.loc[df[col] == key,col] = value\n",
    "      df[col] = df[col].astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dic = data_labeling(clean_df, ['cut', 'color', 'clarity','city'])\n",
    "#dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic2 = {'Ideal': 5,\n",
    " 'Very Good': 3,\n",
    " 'Good': 2,\n",
    " 'Premium': 4,\n",
    " 'Fair': 1,\n",
    " 'E': 6,\n",
    " 'D': 7,\n",
    " 'G': 4,\n",
    " 'F': 5,\n",
    " 'H': 3,\n",
    " 'I': 2,\n",
    " 'J': 1,\n",
    " 'IF': 8,\n",
    " 'VVS1': 7,\n",
    " 'VVS2': 6,\n",
    " 'VS1': 5,\n",
    " 'VS2': 4,\n",
    " 'SI1': 3,\n",
    " 'I1': 1,\n",
    " 'SI2': 2,\n",
    " 'Paris': 1.0,\n",
    " 'Luxembourg': 1.0017263703064307,\n",
    " 'Tel Aviv': 1.0051791109192922,\n",
    " 'Zurich': 1.0310746655157532,\n",
    " 'London': 1.0332326283987916,\n",
    " 'Antwerp': 1.0358221838584376,\n",
    " 'Madrid': 1.0360379801467414,\n",
    " 'Las Vegas': 1.0388433318946915,\n",
    " 'Surat': 1.0401381096245144,\n",
    " 'New York City': 1.048769961156668,\n",
    " 'Amsterdam': 1.0548122572291756,\n",
    " 'Kimberly': 1.0561070349589987,\n",
    " 'Dubai': 1.0699179974104445}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31332/1822649115.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].astype(float)\n",
      "/tmp/ipykernel_31332/1822649115.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].astype(float)\n",
      "/tmp/ipykernel_31332/1822649115.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].astype(float)\n",
      "/tmp/ipykernel_31332/1822649115.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].astype(float)\n"
     ]
    }
   ],
   "source": [
    "#data_labeling(clean_df, ['cut', 'color', 'clarity','city'])\n",
    "data_labeling_test(clean_df, ['cut', 'color', 'clarity','city'],dic2)\n",
    "#clean_df = pd.concat([clean_df, pd.get_dummies(clean_df[['cut', 'color', 'clarity','city']], drop_first=True)], axis = 1).drop(['cut', 'color', 'clarity','city'],axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>carat</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>cut</th>\n",
       "      <th>color</th>\n",
       "      <th>clarity</th>\n",
       "      <th>city</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>40455.000000</td>\n",
       "      <td>40455.000000</td>\n",
       "      <td>40455.000000</td>\n",
       "      <td>40455.000000</td>\n",
       "      <td>40455.000000</td>\n",
       "      <td>40455.000000</td>\n",
       "      <td>40455.000000</td>\n",
       "      <td>40455.000000</td>\n",
       "      <td>40455.000000</td>\n",
       "      <td>40455.000000</td>\n",
       "      <td>40455.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3928.444469</td>\n",
       "      <td>0.797706</td>\n",
       "      <td>61.752841</td>\n",
       "      <td>57.446133</td>\n",
       "      <td>5.729392</td>\n",
       "      <td>5.732819</td>\n",
       "      <td>3.537154</td>\n",
       "      <td>3.904783</td>\n",
       "      <td>4.400766</td>\n",
       "      <td>4.049388</td>\n",
       "      <td>1.036433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3992.416147</td>\n",
       "      <td>0.475544</td>\n",
       "      <td>1.431725</td>\n",
       "      <td>2.233535</td>\n",
       "      <td>1.124453</td>\n",
       "      <td>1.146650</td>\n",
       "      <td>0.697062</td>\n",
       "      <td>1.117876</td>\n",
       "      <td>1.701260</td>\n",
       "      <td>1.648181</td>\n",
       "      <td>0.019357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>326.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>945.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>4.710000</td>\n",
       "      <td>4.720000</td>\n",
       "      <td>2.910000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.031075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2397.000000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>61.800000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>5.690000</td>\n",
       "      <td>5.710000</td>\n",
       "      <td>3.520000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.038843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5331.000000</td>\n",
       "      <td>1.040000</td>\n",
       "      <td>62.500000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>6.540000</td>\n",
       "      <td>6.540000</td>\n",
       "      <td>4.035000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.048770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>18823.000000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>10.230000</td>\n",
       "      <td>58.900000</td>\n",
       "      <td>8.060000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.069918</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              price         carat         depth         table             x  \\\n",
       "count  40455.000000  40455.000000  40455.000000  40455.000000  40455.000000   \n",
       "mean    3928.444469      0.797706     61.752841     57.446133      5.729392   \n",
       "std     3992.416147      0.475544      1.431725      2.233535      1.124453   \n",
       "min      326.000000      0.200000     43.000000     43.000000      0.000000   \n",
       "25%      945.000000      0.400000     61.000000     56.000000      4.710000   \n",
       "50%     2397.000000      0.700000     61.800000     57.000000      5.690000   \n",
       "75%     5331.000000      1.040000     62.500000     59.000000      6.540000   \n",
       "max    18823.000000      4.500000     79.000000     95.000000     10.230000   \n",
       "\n",
       "                  y             z           cut         color       clarity  \\\n",
       "count  40455.000000  40455.000000  40455.000000  40455.000000  40455.000000   \n",
       "mean       5.732819      3.537154      3.904783      4.400766      4.049388   \n",
       "std        1.146650      0.697062      1.117876      1.701260      1.648181   \n",
       "min        0.000000      0.000000      1.000000      1.000000      1.000000   \n",
       "25%        4.720000      2.910000      3.000000      3.000000      3.000000   \n",
       "50%        5.710000      3.520000      4.000000      4.000000      4.000000   \n",
       "75%        6.540000      4.035000      5.000000      6.000000      5.000000   \n",
       "max       58.900000      8.060000      5.000000      7.000000      8.000000   \n",
       "\n",
       "               city  \n",
       "count  40455.000000  \n",
       "mean       1.036433  \n",
       "std        0.019357  \n",
       "min        1.000000  \n",
       "25%        1.031075  \n",
       "50%        1.038843  \n",
       "75%        1.048770  \n",
       "max        1.069918  "
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sub_outlyers(df,deviations):\n",
    "    df2 = df.copy()\n",
    "    for col in df.columns:\n",
    "        min = df[col].mean() - deviations * df[col].std()\n",
    "        max = df[col].mean() + deviations * df[col].std()\n",
    "        df2.loc[df[col] < min,col] = min    \n",
    "        df2.loc[df[col] > max,col] = max\n",
    "    return df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31332/3379422112.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clean_df[outlier_columns] = sub_outlyers(clean_df[outlier_columns],3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>carat</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>cut</th>\n",
       "      <th>color</th>\n",
       "      <th>clarity</th>\n",
       "      <th>city</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>40455.000000</td>\n",
       "      <td>40455.000000</td>\n",
       "      <td>40455.000000</td>\n",
       "      <td>40455.000000</td>\n",
       "      <td>40455.000000</td>\n",
       "      <td>40455.000000</td>\n",
       "      <td>40455.000000</td>\n",
       "      <td>40455.000000</td>\n",
       "      <td>40455.000000</td>\n",
       "      <td>40455.000000</td>\n",
       "      <td>40455.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3928.444469</td>\n",
       "      <td>0.795712</td>\n",
       "      <td>61.749087</td>\n",
       "      <td>57.433731</td>\n",
       "      <td>5.729428</td>\n",
       "      <td>5.731641</td>\n",
       "      <td>3.537474</td>\n",
       "      <td>3.904783</td>\n",
       "      <td>4.400766</td>\n",
       "      <td>4.049388</td>\n",
       "      <td>1.036433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3992.416147</td>\n",
       "      <td>0.468168</td>\n",
       "      <td>1.361600</td>\n",
       "      <td>2.176820</td>\n",
       "      <td>1.122433</td>\n",
       "      <td>1.114376</td>\n",
       "      <td>0.693746</td>\n",
       "      <td>1.117876</td>\n",
       "      <td>1.701260</td>\n",
       "      <td>1.648181</td>\n",
       "      <td>0.019357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>326.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>57.457665</td>\n",
       "      <td>50.745527</td>\n",
       "      <td>2.356034</td>\n",
       "      <td>2.292869</td>\n",
       "      <td>1.445969</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>945.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>4.710000</td>\n",
       "      <td>4.720000</td>\n",
       "      <td>2.910000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.031075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2397.000000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>61.800000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>5.690000</td>\n",
       "      <td>5.710000</td>\n",
       "      <td>3.520000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.038843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5331.000000</td>\n",
       "      <td>1.040000</td>\n",
       "      <td>62.500000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>6.540000</td>\n",
       "      <td>6.540000</td>\n",
       "      <td>4.035000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.048770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>18823.000000</td>\n",
       "      <td>2.224338</td>\n",
       "      <td>66.048018</td>\n",
       "      <td>64.146739</td>\n",
       "      <td>9.102750</td>\n",
       "      <td>9.172768</td>\n",
       "      <td>5.628338</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.069918</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              price         carat         depth         table             x  \\\n",
       "count  40455.000000  40455.000000  40455.000000  40455.000000  40455.000000   \n",
       "mean    3928.444469      0.795712     61.749087     57.433731      5.729428   \n",
       "std     3992.416147      0.468168      1.361600      2.176820      1.122433   \n",
       "min      326.000000      0.200000     57.457665     50.745527      2.356034   \n",
       "25%      945.000000      0.400000     61.000000     56.000000      4.710000   \n",
       "50%     2397.000000      0.700000     61.800000     57.000000      5.690000   \n",
       "75%     5331.000000      1.040000     62.500000     59.000000      6.540000   \n",
       "max    18823.000000      2.224338     66.048018     64.146739      9.102750   \n",
       "\n",
       "                  y             z           cut         color       clarity  \\\n",
       "count  40455.000000  40455.000000  40455.000000  40455.000000  40455.000000   \n",
       "mean       5.731641      3.537474      3.904783      4.400766      4.049388   \n",
       "std        1.114376      0.693746      1.117876      1.701260      1.648181   \n",
       "min        2.292869      1.445969      1.000000      1.000000      1.000000   \n",
       "25%        4.720000      2.910000      3.000000      3.000000      3.000000   \n",
       "50%        5.710000      3.520000      4.000000      4.000000      4.000000   \n",
       "75%        6.540000      4.035000      5.000000      6.000000      5.000000   \n",
       "max        9.172768      5.628338      5.000000      7.000000      8.000000   \n",
       "\n",
       "               city  \n",
       "count  40455.000000  \n",
       "mean       1.036433  \n",
       "std        0.019357  \n",
       "min        1.000000  \n",
       "25%        1.031075  \n",
       "50%        1.038843  \n",
       "75%        1.048770  \n",
       "max        1.069918  "
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outlier_columns = ['carat','depth','table', 'x', 'y', 'z']\n",
    "clean_df[outlier_columns] = sub_outlyers(clean_df[outlier_columns],3)\n",
    "clean_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_xy(x,y):\n",
    "    try:\n",
    "        return x/y\n",
    "    except:\n",
    "        return 1\n",
    "    \n",
    "def feature_ad(carat,x,y,z,):\n",
    "    try:\n",
    "        return carat/(x*y*z)\n",
    "    except:\n",
    "        return 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31332/2433330840.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clean_df['x/y'] = clean_df.apply(lambda x : feature_xy(x['x'], x['y']), axis=1)\n",
      "/tmp/ipykernel_31332/2433330840.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clean_df['td'] = clean_df.apply(lambda x : feature_xy(x['table'], x['depth']), axis=1)\n",
      "/tmp/ipykernel_31332/2433330840.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clean_df['ad'] = clean_df.apply(lambda x : feature_ad(x['carat'],x['x'], x['y'], x['z']), axis=1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>carat</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>cut</th>\n",
       "      <th>color</th>\n",
       "      <th>clarity</th>\n",
       "      <th>city</th>\n",
       "      <th>x/y</th>\n",
       "      <th>td</th>\n",
       "      <th>ad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>40455.000000</td>\n",
       "      <td>40455.000000</td>\n",
       "      <td>40455.000000</td>\n",
       "      <td>40455.000000</td>\n",
       "      <td>40455.000000</td>\n",
       "      <td>40455.000000</td>\n",
       "      <td>40455.000000</td>\n",
       "      <td>40455.000000</td>\n",
       "      <td>40455.000000</td>\n",
       "      <td>40455.000000</td>\n",
       "      <td>40455.000000</td>\n",
       "      <td>40455.000000</td>\n",
       "      <td>40455.000000</td>\n",
       "      <td>40455.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3928.444469</td>\n",
       "      <td>0.795712</td>\n",
       "      <td>61.749087</td>\n",
       "      <td>57.433731</td>\n",
       "      <td>5.729428</td>\n",
       "      <td>5.731641</td>\n",
       "      <td>3.537474</td>\n",
       "      <td>3.904783</td>\n",
       "      <td>4.400766</td>\n",
       "      <td>4.049388</td>\n",
       "      <td>1.036433</td>\n",
       "      <td>0.999393</td>\n",
       "      <td>0.930813</td>\n",
       "      <td>0.006142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3992.416147</td>\n",
       "      <td>0.468168</td>\n",
       "      <td>1.361600</td>\n",
       "      <td>2.176820</td>\n",
       "      <td>1.122433</td>\n",
       "      <td>1.114376</td>\n",
       "      <td>0.693746</td>\n",
       "      <td>1.117876</td>\n",
       "      <td>1.701260</td>\n",
       "      <td>1.648181</td>\n",
       "      <td>0.019357</td>\n",
       "      <td>0.010858</td>\n",
       "      <td>0.046462</td>\n",
       "      <td>0.001695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>326.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>57.457665</td>\n",
       "      <td>50.745527</td>\n",
       "      <td>2.356034</td>\n",
       "      <td>2.292869</td>\n",
       "      <td>1.445969</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.355896</td>\n",
       "      <td>0.768872</td>\n",
       "      <td>0.002847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>945.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>4.710000</td>\n",
       "      <td>4.720000</td>\n",
       "      <td>2.910000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.031075</td>\n",
       "      <td>0.992593</td>\n",
       "      <td>0.898876</td>\n",
       "      <td>0.006046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2397.000000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>61.800000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>5.690000</td>\n",
       "      <td>5.710000</td>\n",
       "      <td>3.520000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.038843</td>\n",
       "      <td>0.995726</td>\n",
       "      <td>0.923825</td>\n",
       "      <td>0.006115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5331.000000</td>\n",
       "      <td>1.040000</td>\n",
       "      <td>62.500000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>6.540000</td>\n",
       "      <td>6.540000</td>\n",
       "      <td>4.035000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.048770</td>\n",
       "      <td>1.006928</td>\n",
       "      <td>0.955519</td>\n",
       "      <td>0.006189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>18823.000000</td>\n",
       "      <td>2.224338</td>\n",
       "      <td>66.048018</td>\n",
       "      <td>64.146739</td>\n",
       "      <td>9.102750</td>\n",
       "      <td>9.172768</td>\n",
       "      <td>5.628338</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.069918</td>\n",
       "      <td>1.615572</td>\n",
       "      <td>1.116417</td>\n",
       "      <td>0.284761</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              price         carat         depth         table             x  \\\n",
       "count  40455.000000  40455.000000  40455.000000  40455.000000  40455.000000   \n",
       "mean    3928.444469      0.795712     61.749087     57.433731      5.729428   \n",
       "std     3992.416147      0.468168      1.361600      2.176820      1.122433   \n",
       "min      326.000000      0.200000     57.457665     50.745527      2.356034   \n",
       "25%      945.000000      0.400000     61.000000     56.000000      4.710000   \n",
       "50%     2397.000000      0.700000     61.800000     57.000000      5.690000   \n",
       "75%     5331.000000      1.040000     62.500000     59.000000      6.540000   \n",
       "max    18823.000000      2.224338     66.048018     64.146739      9.102750   \n",
       "\n",
       "                  y             z           cut         color       clarity  \\\n",
       "count  40455.000000  40455.000000  40455.000000  40455.000000  40455.000000   \n",
       "mean       5.731641      3.537474      3.904783      4.400766      4.049388   \n",
       "std        1.114376      0.693746      1.117876      1.701260      1.648181   \n",
       "min        2.292869      1.445969      1.000000      1.000000      1.000000   \n",
       "25%        4.720000      2.910000      3.000000      3.000000      3.000000   \n",
       "50%        5.710000      3.520000      4.000000      4.000000      4.000000   \n",
       "75%        6.540000      4.035000      5.000000      6.000000      5.000000   \n",
       "max        9.172768      5.628338      5.000000      7.000000      8.000000   \n",
       "\n",
       "               city           x/y            td            ad  \n",
       "count  40455.000000  40455.000000  40455.000000  40455.000000  \n",
       "mean       1.036433      0.999393      0.930813      0.006142  \n",
       "std        0.019357      0.010858      0.046462      0.001695  \n",
       "min        1.000000      0.355896      0.768872      0.002847  \n",
       "25%        1.031075      0.992593      0.898876      0.006046  \n",
       "50%        1.038843      0.995726      0.923825      0.006115  \n",
       "75%        1.048770      1.006928      0.955519      0.006189  \n",
       "max        1.069918      1.615572      1.116417      0.284761  "
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df['x/y'] = clean_df.apply(lambda x : feature_xy(x['x'], x['y']), axis=1)\n",
    "clean_df['td'] = clean_df.apply(lambda x : feature_xy(x['table'], x['depth']), axis=1)\n",
    "clean_df['ad'] = clean_df.apply(lambda x : feature_ad(x['carat'],x['x'], x['y'], x['z']), axis=1)\n",
    "clean_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31332/3764732256.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clean_df[['x/y', 'td', 'ad']] = sub_outlyers(clean_df[['x/y', 'td', 'ad']],3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>carat</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>cut</th>\n",
       "      <th>color</th>\n",
       "      <th>clarity</th>\n",
       "      <th>city</th>\n",
       "      <th>x/y</th>\n",
       "      <th>td</th>\n",
       "      <th>ad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>40455.000000</td>\n",
       "      <td>40455.000000</td>\n",
       "      <td>40455.000000</td>\n",
       "      <td>40455.000000</td>\n",
       "      <td>40455.000000</td>\n",
       "      <td>40455.000000</td>\n",
       "      <td>40455.000000</td>\n",
       "      <td>40455.000000</td>\n",
       "      <td>40455.000000</td>\n",
       "      <td>40455.000000</td>\n",
       "      <td>40455.000000</td>\n",
       "      <td>40455.000000</td>\n",
       "      <td>40455.000000</td>\n",
       "      <td>40455.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3928.444469</td>\n",
       "      <td>0.795712</td>\n",
       "      <td>61.749087</td>\n",
       "      <td>57.433731</td>\n",
       "      <td>5.729428</td>\n",
       "      <td>5.731641</td>\n",
       "      <td>3.537474</td>\n",
       "      <td>3.904783</td>\n",
       "      <td>4.400766</td>\n",
       "      <td>4.049388</td>\n",
       "      <td>1.036433</td>\n",
       "      <td>0.999352</td>\n",
       "      <td>0.930607</td>\n",
       "      <td>0.006125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3992.416147</td>\n",
       "      <td>0.468168</td>\n",
       "      <td>1.361600</td>\n",
       "      <td>2.176820</td>\n",
       "      <td>1.122433</td>\n",
       "      <td>1.114376</td>\n",
       "      <td>0.693746</td>\n",
       "      <td>1.117876</td>\n",
       "      <td>1.701260</td>\n",
       "      <td>1.648181</td>\n",
       "      <td>0.019357</td>\n",
       "      <td>0.008849</td>\n",
       "      <td>0.045753</td>\n",
       "      <td>0.000181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>326.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>57.457665</td>\n",
       "      <td>50.745527</td>\n",
       "      <td>2.356034</td>\n",
       "      <td>2.292869</td>\n",
       "      <td>1.445969</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.966818</td>\n",
       "      <td>0.791427</td>\n",
       "      <td>0.002847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>945.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>4.710000</td>\n",
       "      <td>4.720000</td>\n",
       "      <td>2.910000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.031075</td>\n",
       "      <td>0.992593</td>\n",
       "      <td>0.898876</td>\n",
       "      <td>0.006046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2397.000000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>61.800000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>5.690000</td>\n",
       "      <td>5.710000</td>\n",
       "      <td>3.520000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.038843</td>\n",
       "      <td>0.995726</td>\n",
       "      <td>0.923825</td>\n",
       "      <td>0.006115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5331.000000</td>\n",
       "      <td>1.040000</td>\n",
       "      <td>62.500000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>6.540000</td>\n",
       "      <td>6.540000</td>\n",
       "      <td>4.035000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.048770</td>\n",
       "      <td>1.006928</td>\n",
       "      <td>0.955519</td>\n",
       "      <td>0.006189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>18823.000000</td>\n",
       "      <td>2.224338</td>\n",
       "      <td>66.048018</td>\n",
       "      <td>64.146739</td>\n",
       "      <td>9.102750</td>\n",
       "      <td>9.172768</td>\n",
       "      <td>5.628338</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.069918</td>\n",
       "      <td>1.031968</td>\n",
       "      <td>1.070199</td>\n",
       "      <td>0.011228</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              price         carat         depth         table             x  \\\n",
       "count  40455.000000  40455.000000  40455.000000  40455.000000  40455.000000   \n",
       "mean    3928.444469      0.795712     61.749087     57.433731      5.729428   \n",
       "std     3992.416147      0.468168      1.361600      2.176820      1.122433   \n",
       "min      326.000000      0.200000     57.457665     50.745527      2.356034   \n",
       "25%      945.000000      0.400000     61.000000     56.000000      4.710000   \n",
       "50%     2397.000000      0.700000     61.800000     57.000000      5.690000   \n",
       "75%     5331.000000      1.040000     62.500000     59.000000      6.540000   \n",
       "max    18823.000000      2.224338     66.048018     64.146739      9.102750   \n",
       "\n",
       "                  y             z           cut         color       clarity  \\\n",
       "count  40455.000000  40455.000000  40455.000000  40455.000000  40455.000000   \n",
       "mean       5.731641      3.537474      3.904783      4.400766      4.049388   \n",
       "std        1.114376      0.693746      1.117876      1.701260      1.648181   \n",
       "min        2.292869      1.445969      1.000000      1.000000      1.000000   \n",
       "25%        4.720000      2.910000      3.000000      3.000000      3.000000   \n",
       "50%        5.710000      3.520000      4.000000      4.000000      4.000000   \n",
       "75%        6.540000      4.035000      5.000000      6.000000      5.000000   \n",
       "max        9.172768      5.628338      5.000000      7.000000      8.000000   \n",
       "\n",
       "               city           x/y            td            ad  \n",
       "count  40455.000000  40455.000000  40455.000000  40455.000000  \n",
       "mean       1.036433      0.999352      0.930607      0.006125  \n",
       "std        0.019357      0.008849      0.045753      0.000181  \n",
       "min        1.000000      0.966818      0.791427      0.002847  \n",
       "25%        1.031075      0.992593      0.898876      0.006046  \n",
       "50%        1.038843      0.995726      0.923825      0.006115  \n",
       "75%        1.048770      1.006928      0.955519      0.006189  \n",
       "max        1.069918      1.031968      1.070199      0.011228  "
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df[['x/y', 'td', 'ad']] = sub_outlyers(clean_df[['x/y', 'td', 'ad']],3)\n",
    "clean_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 40455 entries, 0 to 40454\n",
      "Data columns (total 14 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   price    40455 non-null  int64  \n",
      " 1   carat    40455 non-null  float64\n",
      " 2   depth    40455 non-null  float64\n",
      " 3   table    40455 non-null  float64\n",
      " 4   x        40455 non-null  float64\n",
      " 5   y        40455 non-null  float64\n",
      " 6   z        40455 non-null  float64\n",
      " 7   cut      40455 non-null  float64\n",
      " 8   color    40455 non-null  float64\n",
      " 9   clarity  40455 non-null  float64\n",
      " 10  city     40455 non-null  float64\n",
      " 11  x/y      40455 non-null  float64\n",
      " 12  td       40455 non-null  float64\n",
      " 13  ad       40455 non-null  float64\n",
      "dtypes: float64(13), int64(1)\n",
      "memory usage: 4.3 MB\n"
     ]
    }
   ],
   "source": [
    "clean_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['price', 'carat', 'depth', 'table', 'x', 'y', 'z', 'cut', 'color',\n",
       "       'clarity', 'city', 'x/y', 'td', 'ad'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"selected_features = ['carat', 'depth', 'table', 'x', 'y', 'z', 'cut', 'color',\\n       'clarity', 'city']#,'x/y']#, 'y/z', 'x/z', 'apparent_density']\\ntarget = 'price\""
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''selected_features = ['carat', 'depth', 'table', 'x', 'y', 'z', 'cut', 'color',\n",
    "       'clarity', 'city']#,'x/y']#, 'y/z', 'x/z', 'apparent_density']\n",
    "target = 'price'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"def filter_transform(df,selected_features,target):\\n    data_df = df[selected_features]\\n    to_dummy = ['city']\\n    for feature in to_dummy:\\n        dummies_df = pd.get_dummies(data_df[feature], prefix=feature, drop_first=True)\\n        data_df = pd.concat([data_df, dummies_df],axis=1).drop(feature, axis=1)   \\n    data_df = pd.concat([data_df.select_dtypes(exclude=['object']), df[target]], axis=1).dropna()\\n    return data_df\""
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''def filter_transform(df,selected_features,target):\n",
    "    data_df = df[selected_features]\n",
    "    to_dummy = ['city']\n",
    "    for feature in to_dummy:\n",
    "        dummies_df = pd.get_dummies(data_df[feature], prefix=feature, drop_first=True)\n",
    "        data_df = pd.concat([data_df, dummies_df],axis=1).drop(feature, axis=1)   \n",
    "    data_df = pd.concat([data_df.select_dtypes(exclude=['object']), df[target]], axis=1).dropna()\n",
    "    return data_df'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean_df = pd.concat([clean_df, pd.get_dummies(clean_df[['cut', 'color', 'clarity','city']], drop_first=True)], axis = 1).drop(['cut', 'color', 'clarity','city'],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_df = filter_transform(clean_df,selected_features,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df.to_csv('./data/clean/diamondsdlfe2xso.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = clean_df.drop(['price'], axis=1)\n",
    "y = clean_df['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reducer = UMAP(n_components=10)\n",
    "#scaler = StandardScaler()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nX =X.fillna(0)\\nX = np.nan_to_num(X.astype(np.float32))\\nX = scaler.fit_transform(X)\\nX = reducer.fit_transform(X)\\nX'"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "X =X.fillna(0)\n",
    "X = np.nan_to_num(X.astype(np.float32))\n",
    "X = scaler.fit_transform(X)\n",
    "X = reducer.fit_transform(X)\n",
    "X'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>cut</th>\n",
       "      <th>color</th>\n",
       "      <th>clarity</th>\n",
       "      <th>city</th>\n",
       "      <th>x/y</th>\n",
       "      <th>td</th>\n",
       "      <th>ad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>40455.000000</td>\n",
       "      <td>40455.000000</td>\n",
       "      <td>40455.000000</td>\n",
       "      <td>40455.000000</td>\n",
       "      <td>40455.000000</td>\n",
       "      <td>40455.000000</td>\n",
       "      <td>40455.000000</td>\n",
       "      <td>40455.000000</td>\n",
       "      <td>40455.000000</td>\n",
       "      <td>40455.000000</td>\n",
       "      <td>40455.000000</td>\n",
       "      <td>40455.000000</td>\n",
       "      <td>40455.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.795712</td>\n",
       "      <td>61.749087</td>\n",
       "      <td>57.433731</td>\n",
       "      <td>5.729428</td>\n",
       "      <td>5.731641</td>\n",
       "      <td>3.537474</td>\n",
       "      <td>3.904783</td>\n",
       "      <td>4.400766</td>\n",
       "      <td>4.049388</td>\n",
       "      <td>1.036433</td>\n",
       "      <td>0.999352</td>\n",
       "      <td>0.930607</td>\n",
       "      <td>0.006125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.468168</td>\n",
       "      <td>1.361600</td>\n",
       "      <td>2.176820</td>\n",
       "      <td>1.122433</td>\n",
       "      <td>1.114376</td>\n",
       "      <td>0.693746</td>\n",
       "      <td>1.117876</td>\n",
       "      <td>1.701260</td>\n",
       "      <td>1.648181</td>\n",
       "      <td>0.019357</td>\n",
       "      <td>0.008849</td>\n",
       "      <td>0.045753</td>\n",
       "      <td>0.000181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>57.457665</td>\n",
       "      <td>50.745527</td>\n",
       "      <td>2.356034</td>\n",
       "      <td>2.292869</td>\n",
       "      <td>1.445969</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.966818</td>\n",
       "      <td>0.791427</td>\n",
       "      <td>0.002847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.400000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>4.710000</td>\n",
       "      <td>4.720000</td>\n",
       "      <td>2.910000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.031075</td>\n",
       "      <td>0.992593</td>\n",
       "      <td>0.898876</td>\n",
       "      <td>0.006046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.700000</td>\n",
       "      <td>61.800000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>5.690000</td>\n",
       "      <td>5.710000</td>\n",
       "      <td>3.520000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.038843</td>\n",
       "      <td>0.995726</td>\n",
       "      <td>0.923825</td>\n",
       "      <td>0.006115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.040000</td>\n",
       "      <td>62.500000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>6.540000</td>\n",
       "      <td>6.540000</td>\n",
       "      <td>4.035000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.048770</td>\n",
       "      <td>1.006928</td>\n",
       "      <td>0.955519</td>\n",
       "      <td>0.006189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.224338</td>\n",
       "      <td>66.048018</td>\n",
       "      <td>64.146739</td>\n",
       "      <td>9.102750</td>\n",
       "      <td>9.172768</td>\n",
       "      <td>5.628338</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.069918</td>\n",
       "      <td>1.031968</td>\n",
       "      <td>1.070199</td>\n",
       "      <td>0.011228</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              carat         depth         table             x             y  \\\n",
       "count  40455.000000  40455.000000  40455.000000  40455.000000  40455.000000   \n",
       "mean       0.795712     61.749087     57.433731      5.729428      5.731641   \n",
       "std        0.468168      1.361600      2.176820      1.122433      1.114376   \n",
       "min        0.200000     57.457665     50.745527      2.356034      2.292869   \n",
       "25%        0.400000     61.000000     56.000000      4.710000      4.720000   \n",
       "50%        0.700000     61.800000     57.000000      5.690000      5.710000   \n",
       "75%        1.040000     62.500000     59.000000      6.540000      6.540000   \n",
       "max        2.224338     66.048018     64.146739      9.102750      9.172768   \n",
       "\n",
       "                  z           cut         color       clarity          city  \\\n",
       "count  40455.000000  40455.000000  40455.000000  40455.000000  40455.000000   \n",
       "mean       3.537474      3.904783      4.400766      4.049388      1.036433   \n",
       "std        0.693746      1.117876      1.701260      1.648181      0.019357   \n",
       "min        1.445969      1.000000      1.000000      1.000000      1.000000   \n",
       "25%        2.910000      3.000000      3.000000      3.000000      1.031075   \n",
       "50%        3.520000      4.000000      4.000000      4.000000      1.038843   \n",
       "75%        4.035000      5.000000      6.000000      5.000000      1.048770   \n",
       "max        5.628338      5.000000      7.000000      8.000000      1.069918   \n",
       "\n",
       "                x/y            td            ad  \n",
       "count  40455.000000  40455.000000  40455.000000  \n",
       "mean       0.999352      0.930607      0.006125  \n",
       "std        0.008849      0.045753      0.000181  \n",
       "min        0.966818      0.791427      0.002847  \n",
       "25%        0.992593      0.898876      0.006046  \n",
       "50%        0.995726      0.923825      0.006115  \n",
       "75%        1.006928      0.955519      0.006189  \n",
       "max        1.031968      1.070199      0.011228  "
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Initialize RFE with XGBoost model\\nrfe = RFE(estimator=xgb_model, n_features_to_select=len(X.columns)-1)\\n\\n# Fit RFE to training data\\nrfe.fit(X_train, y_train)\\n\\n# Get selected features\\nselected_features = X_train.columns[rfe.support_]\\nselected_features'"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the XGBoost regressor\n",
    "xgb_model = XGBRegressor( missing= np.inf)\n",
    "\n",
    "# Optimal gridsearch with data labeling\n",
    "param_grid_dl = {\n",
    "    'n_estimators': [225, 230, 235],\n",
    "    'max_depth': [ 5, 6, 7],\n",
    "    'learning_rate': [ 0.075, 0.07, 0.065],\n",
    "    'missing': [np.inf]\n",
    "}\n",
    "\n",
    "param_grid_deep = {\n",
    "        'n_estimators': [ 210, 235, 250],\n",
    "        'min_child_weight': [ 12, 15, 17],\n",
    "        'alpha': [0.3,0.6],\n",
    "        'lambda': [0.3,0.6],\n",
    "        'gamma': [0.02, 0.05, 0.07],\n",
    "        'subsample': [0.8],\n",
    "        'colsample_bytree': [0.7, 0.8, 0.9],\n",
    "        'max_depth': [6],\n",
    "        'learning_rate': [ 0.07],\n",
    "         }\n",
    "\n",
    "param_grid_dart = {\n",
    "    'booster': ['dart'],\n",
    "    'n_estimators': [230],\n",
    "    'max_depth': [  6],\n",
    "    'learning_rate': [ 0.07],\n",
    "    'min_child_weight': [1],\n",
    "              'rate_drop': [0.10],\n",
    "              'skip_drop': [0.5]\n",
    "}\n",
    "\n",
    "param_grid_en = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [ 7, 9, 11],\n",
    "    'learning_rate': [0.01, 0.1,0.2]\n",
    "}\n",
    "\n",
    "param_grid_aiama ={'colsample_bytree': [ 0.8, 0.9, 1],\n",
    "                    'learning_rate': [0.04, 0.05, 0.06],\n",
    "                      'max_depth': [5, 6, 7],\n",
    "                        'n_estimators': [200, 220, 240],\n",
    "                          'subsample': [0.8,0.9,1],\n",
    "                              'missing': [np.inf]} \n",
    "\n",
    "param_grid_art ={'colsample_bytree': [ 0.85, 0.9, 0.95],\n",
    "                    'learning_rate': [0.008, 0.01, 0.012],\n",
    "                      'max_depth': [ 6, 7, 8],\n",
    "                        'n_estimators': [800, 1000, 1200],\n",
    "                          'subsample': [0.8,0.85],\n",
    "                              'missing': [np.inf]} \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "# Initialize XGBoost model\n",
    "'''\n",
    "# Initialize RFE with XGBoost model\n",
    "rfe = RFE(estimator=xgb_model, n_features_to_select=len(X.columns)-1)\n",
    "\n",
    "# Fit RFE to training data\n",
    "rfe.fit(X_train, y_train)\n",
    "\n",
    "# Get selected features\n",
    "selected_features = X_train.columns[rfe.support_]\n",
    "selected_features'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 162 candidates, totalling 810 fits\n",
      "[CV 5/5] END colsample_bytree=0.85, learning_rate=0.008, max_depth=6, missing=inf, n_estimators=800, subsample=0.8;, score=-508.518 total time=   3.8s[CV 2/5] END colsample_bytree=0.85, learning_rate=0.008, max_depth=6, missing=inf, n_estimators=800, subsample=0.8;, score=-512.526 total time=   3.8s\n",
      "\n",
      "[CV 1/5] END colsample_bytree=0.85, learning_rate=0.008, max_depth=6, missing=inf, n_estimators=800, subsample=0.85;, score=-510.545 total time=   3.9s\n",
      "[CV 1/5] END colsample_bytree=0.85, learning_rate=0.008, max_depth=6, missing=inf, n_estimators=800, subsample=0.8;, score=-510.031 total time=   4.0s\n",
      "[CV 3/5] END colsample_bytree=0.85, learning_rate=0.008, max_depth=6, missing=inf, n_estimators=800, subsample=0.8;, score=-517.240 total time=   4.0s\n",
      "[CV 3/5] END colsample_bytree=0.85, learning_rate=0.008, max_depth=6, missing=inf, n_estimators=800, subsample=0.85;, score=-516.380 total time=   4.1s\n",
      "[CV 4/5] END colsample_bytree=0.85, learning_rate=0.008, max_depth=6, missing=inf, n_estimators=800, subsample=0.8;, score=-565.633 total time=   4.4s\n",
      "[CV 2/5] END colsample_bytree=0.85, learning_rate=0.008, max_depth=6, missing=inf, n_estimators=800, subsample=0.85;, score=-511.485 total time=   4.6s\n",
      "[CV 5/5] END colsample_bytree=0.85, learning_rate=0.008, max_depth=6, missing=inf, n_estimators=800, subsample=0.85;, score=-508.166 total time=   4.6s\n",
      "[CV 4/5] END colsample_bytree=0.85, learning_rate=0.008, max_depth=6, missing=inf, n_estimators=1000, subsample=0.8;, score=-560.708 total time=   4.6s\n",
      "[CV 3/5] END colsample_bytree=0.85, learning_rate=0.008, max_depth=6, missing=inf, n_estimators=1000, subsample=0.8;, score=-512.665 total time=   4.6s\n",
      "[CV 1/5] END colsample_bytree=0.85, learning_rate=0.008, max_depth=6, missing=inf, n_estimators=1000, subsample=0.8;, score=-507.008 total time=   4.6s\n",
      "[CV 4/5] END colsample_bytree=0.85, learning_rate=0.008, max_depth=6, missing=inf, n_estimators=800, subsample=0.85;, score=-565.155 total time=   4.7s\n",
      "[CV 2/5] END colsample_bytree=0.85, learning_rate=0.008, max_depth=6, missing=inf, n_estimators=1000, subsample=0.85;, score=-507.944 total time=   4.9s\n",
      "[CV 3/5] END colsample_bytree=0.85, learning_rate=0.008, max_depth=6, missing=inf, n_estimators=1000, subsample=0.85;, score=-511.883 total time=   4.9s\n",
      "[CV 5/5] END colsample_bytree=0.85, learning_rate=0.008, max_depth=6, missing=inf, n_estimators=1000, subsample=0.8;, score=-505.551 total time=   4.9s\n",
      "[CV 4/5] END colsample_bytree=0.85, learning_rate=0.008, max_depth=6, missing=inf, n_estimators=1000, subsample=0.85;, score=-560.941 total time=   4.9s\n",
      "[CV 5/5] END colsample_bytree=0.85, learning_rate=0.008, max_depth=6, missing=inf, n_estimators=1000, subsample=0.85;, score=-504.848 total time=   4.9s\n",
      "[CV 2/5] END colsample_bytree=0.85, learning_rate=0.008, max_depth=6, missing=inf, n_estimators=1000, subsample=0.8;, score=-508.308 total time=   5.3s\n",
      "[CV 1/5] END colsample_bytree=0.85, learning_rate=0.008, max_depth=6, missing=inf, n_estimators=1000, subsample=0.85;, score=-506.899 total time=   5.3s\n",
      "[CV 1/5] END colsample_bytree=0.85, learning_rate=0.008, max_depth=6, missing=inf, n_estimators=1200, subsample=0.8;, score=-505.726 total time=   5.6s\n",
      "[CV 2/5] END colsample_bytree=0.85, learning_rate=0.008, max_depth=6, missing=inf, n_estimators=1200, subsample=0.8;, score=-506.253 total time=   5.7s\n",
      "[CV 3/5] END colsample_bytree=0.85, learning_rate=0.008, max_depth=6, missing=inf, n_estimators=1200, subsample=0.8;, score=-511.035 total time=   5.6s\n",
      "[CV 1/5] END colsample_bytree=0.85, learning_rate=0.008, max_depth=6, missing=inf, n_estimators=1200, subsample=0.85;, score=-505.012 total time=   5.9s\n",
      "[CV 4/5] END colsample_bytree=0.85, learning_rate=0.008, max_depth=6, missing=inf, n_estimators=1200, subsample=0.8;, score=-558.386 total time=   6.1s\n",
      "[CV 5/5] END colsample_bytree=0.85, learning_rate=0.008, max_depth=6, missing=inf, n_estimators=1200, subsample=0.8;, score=-504.773 total time=   6.1s\n",
      "[CV 5/5] END colsample_bytree=0.85, learning_rate=0.008, max_depth=6, missing=inf, n_estimators=1200, subsample=0.85;, score=-503.569 total time=   5.7s\n",
      "[CV 1/5] END colsample_bytree=0.85, learning_rate=0.008, max_depth=7, missing=inf, n_estimators=800, subsample=0.8;, score=-503.988 total time=   5.9s\n",
      "[CV 2/5] END colsample_bytree=0.85, learning_rate=0.008, max_depth=7, missing=inf, n_estimators=800, subsample=0.8;, score=-509.327 total time=   5.9s\n",
      "[CV 2/5] END colsample_bytree=0.85, learning_rate=0.008, max_depth=6, missing=inf, n_estimators=1200, subsample=0.85;, score=-506.387 total time=   6.4s\n",
      "[CV 4/5] END colsample_bytree=0.85, learning_rate=0.008, max_depth=6, missing=inf, n_estimators=1200, subsample=0.85;, score=-558.866 total time=   6.4s\n",
      "[CV 3/5] END colsample_bytree=0.85, learning_rate=0.008, max_depth=6, missing=inf, n_estimators=1200, subsample=0.85;, score=-510.276 total time=   6.6s\n",
      "[CV 5/5] END colsample_bytree=0.85, learning_rate=0.008, max_depth=7, missing=inf, n_estimators=800, subsample=0.8;, score=-504.862 total time=   6.3s\n",
      "[CV 4/5] END colsample_bytree=0.85, learning_rate=0.008, max_depth=7, missing=inf, n_estimators=800, subsample=0.8;, score=-560.402 total time=   6.3s\n",
      "[CV 2/5] END colsample_bytree=0.85, learning_rate=0.008, max_depth=7, missing=inf, n_estimators=800, subsample=0.85;, score=-509.433 total time=   6.3s\n",
      "[CV 1/5] END colsample_bytree=0.85, learning_rate=0.008, max_depth=7, missing=inf, n_estimators=800, subsample=0.85;, score=-505.366 total time=   6.4s\n",
      "[CV 3/5] END colsample_bytree=0.85, learning_rate=0.008, max_depth=7, missing=inf, n_estimators=800, subsample=0.85;, score=-514.970 total time=   6.3s\n",
      "[CV 3/5] END colsample_bytree=0.85, learning_rate=0.008, max_depth=7, missing=inf, n_estimators=800, subsample=0.8;, score=-514.667 total time=   6.7s\n",
      "[CV 5/5] END colsample_bytree=0.85, learning_rate=0.008, max_depth=7, missing=inf, n_estimators=800, subsample=0.85;, score=-505.673 total time=   7.4s\n",
      "[CV 4/5] END colsample_bytree=0.85, learning_rate=0.008, max_depth=7, missing=inf, n_estimators=800, subsample=0.85;, score=-560.430 total time=   7.4s\n",
      "[CV 3/5] END colsample_bytree=0.85, learning_rate=0.008, max_depth=7, missing=inf, n_estimators=1000, subsample=0.8;, score=-512.292 total time=   7.1s\n",
      "[CV 2/5] END colsample_bytree=0.85, learning_rate=0.008, max_depth=7, missing=inf, n_estimators=1000, subsample=0.8;, score=-507.277 total time=   7.3s\n",
      "[CV 1/5] END colsample_bytree=0.85, learning_rate=0.008, max_depth=7, missing=inf, n_estimators=1000, subsample=0.8;, score=-501.921 total time=   7.7s\n",
      "[CV 4/5] END colsample_bytree=0.85, learning_rate=0.008, max_depth=7, missing=inf, n_estimators=1000, subsample=0.8;, score=-557.619 total time=   7.4s\n",
      "[CV 2/5] END colsample_bytree=0.85, learning_rate=0.008, max_depth=7, missing=inf, n_estimators=1000, subsample=0.85;, score=-506.896 total time=   7.2s\n",
      "[CV 4/5] END colsample_bytree=0.85, learning_rate=0.008, max_depth=7, missing=inf, n_estimators=1000, subsample=0.85;, score=-558.086 total time=   7.0s\n",
      "[CV 5/5] END colsample_bytree=0.85, learning_rate=0.008, max_depth=7, missing=inf, n_estimators=1000, subsample=0.8;, score=-504.026 total time=   7.8s\n",
      "[CV 3/5] END colsample_bytree=0.85, learning_rate=0.008, max_depth=7, missing=inf, n_estimators=1000, subsample=0.85;, score=-512.621 total time=   7.3s\n",
      "[CV 1/5] END colsample_bytree=0.85, learning_rate=0.008, max_depth=7, missing=inf, n_estimators=1000, subsample=0.85;, score=-503.135 total time=   7.9s\n",
      "[CV 5/5] END colsample_bytree=0.85, learning_rate=0.008, max_depth=7, missing=inf, n_estimators=1000, subsample=0.85;, score=-503.573 total time=   9.2s\n",
      "[CV 1/5] END colsample_bytree=0.85, learning_rate=0.008, max_depth=7, missing=inf, n_estimators=1200, subsample=0.85;, score=-502.298 total time=   8.7s\n",
      "[CV 4/5] END colsample_bytree=0.85, learning_rate=0.008, max_depth=7, missing=inf, n_estimators=1200, subsample=0.8;, score=-556.605 total time=   9.3s\n",
      "[CV 3/5] END colsample_bytree=0.85, learning_rate=0.008, max_depth=7, missing=inf, n_estimators=1200, subsample=0.8;, score=-511.277 total time=   9.3s\n",
      "[CV 2/5] END colsample_bytree=0.85, learning_rate=0.008, max_depth=7, missing=inf, n_estimators=1200, subsample=0.85;, score=-506.134 total time=   9.3s\n",
      "[CV 5/5] END colsample_bytree=0.85, learning_rate=0.008, max_depth=7, missing=inf, n_estimators=1200, subsample=0.8;, score=-503.241 total time=   9.4s\n",
      "[CV 1/5] END colsample_bytree=0.85, learning_rate=0.008, max_depth=7, missing=inf, n_estimators=1200, subsample=0.8;, score=-501.317 total time=  10.6s\n",
      "[CV 2/5] END colsample_bytree=0.85, learning_rate=0.008, max_depth=7, missing=inf, n_estimators=1200, subsample=0.8;, score=-505.703 total time=  10.5s\n",
      "[CV 3/5] END colsample_bytree=0.85, learning_rate=0.008, max_depth=7, missing=inf, n_estimators=1200, subsample=0.85;, score=-511.602 total time=  10.6s\n",
      "[CV 4/5] END colsample_bytree=0.85, learning_rate=0.008, max_depth=7, missing=inf, n_estimators=1200, subsample=0.85;, score=-556.485 total time=  10.7s\n",
      "[CV 5/5] END colsample_bytree=0.85, learning_rate=0.008, max_depth=7, missing=inf, n_estimators=1200, subsample=0.85;, score=-502.784 total time=  10.8s\n",
      "[CV 1/5] END colsample_bytree=0.85, learning_rate=0.008, max_depth=8, missing=inf, n_estimators=800, subsample=0.8;, score=-503.567 total time=  10.0s\n",
      "[CV 2/5] END colsample_bytree=0.85, learning_rate=0.008, max_depth=8, missing=inf, n_estimators=800, subsample=0.8;, score=-509.906 total time=   9.9s\n",
      "[CV 1/5] END colsample_bytree=0.85, learning_rate=0.008, max_depth=8, missing=inf, n_estimators=800, subsample=0.85;, score=-503.155 total time=   9.7s\n",
      "[CV 5/5] END colsample_bytree=0.85, learning_rate=0.008, max_depth=8, missing=inf, n_estimators=800, subsample=0.8;, score=-506.126 total time=  10.0s\n",
      "[CV 4/5] END colsample_bytree=0.85, learning_rate=0.008, max_depth=8, missing=inf, n_estimators=800, subsample=0.8;, score=-559.507 total time=  10.2s\n",
      "[CV 3/5] END colsample_bytree=0.85, learning_rate=0.008, max_depth=8, missing=inf, n_estimators=800, subsample=0.8;, score=-516.393 total time=  10.7s\n",
      "[CV 3/5] END colsample_bytree=0.85, learning_rate=0.008, max_depth=8, missing=inf, n_estimators=800, subsample=0.85;, score=-517.401 total time=  10.3s\n",
      "[CV 2/5] END colsample_bytree=0.85, learning_rate=0.008, max_depth=8, missing=inf, n_estimators=800, subsample=0.85;, score=-511.477 total time=  10.4s\n",
      "[CV 4/5] END colsample_bytree=0.85, learning_rate=0.008, max_depth=8, missing=inf, n_estimators=800, subsample=0.85;, score=-559.551 total time=  10.6s\n",
      "[CV 1/5] END colsample_bytree=0.85, learning_rate=0.008, max_depth=8, missing=inf, n_estimators=1000, subsample=0.8;, score=-502.795 total time=  12.0s\n",
      "[CV 5/5] END colsample_bytree=0.85, learning_rate=0.008, max_depth=8, missing=inf, n_estimators=800, subsample=0.85;, score=-507.976 total time=  12.6s\n",
      "[CV 4/5] END colsample_bytree=0.85, learning_rate=0.008, max_depth=8, missing=inf, n_estimators=1000, subsample=0.8;, score=-557.624 total time=  12.2s\n",
      "[CV 2/5] END colsample_bytree=0.85, learning_rate=0.008, max_depth=8, missing=inf, n_estimators=1000, subsample=0.8;, score=-508.974 total time=  12.5s\n",
      "[CV 3/5] END colsample_bytree=0.85, learning_rate=0.008, max_depth=8, missing=inf, n_estimators=1000, subsample=0.8;, score=-515.050 total time=  12.6s\n",
      "[CV 5/5] END colsample_bytree=0.85, learning_rate=0.008, max_depth=8, missing=inf, n_estimators=1000, subsample=0.8;, score=-505.510 total time=  13.0s\n",
      "[CV 1/5] END colsample_bytree=0.85, learning_rate=0.008, max_depth=8, missing=inf, n_estimators=1000, subsample=0.85;, score=-501.797 total time=  15.4s\n",
      "[CV 2/5] END colsample_bytree=0.85, learning_rate=0.008, max_depth=8, missing=inf, n_estimators=1000, subsample=0.85;, score=-510.231 total time=  15.4s\n",
      "[CV 3/5] END colsample_bytree=0.85, learning_rate=0.008, max_depth=8, missing=inf, n_estimators=1000, subsample=0.85;, score=-516.314 total time=  15.3s\n",
      "[CV 2/5] END colsample_bytree=0.85, learning_rate=0.01, max_depth=6, missing=inf, n_estimators=800, subsample=0.8;, score=-509.027 total time=   4.6s\n",
      "[CV 1/5] END colsample_bytree=0.85, learning_rate=0.01, max_depth=6, missing=inf, n_estimators=800, subsample=0.8;, score=-506.382 total time=   5.0s\n",
      "[CV 3/5] END colsample_bytree=0.85, learning_rate=0.01, max_depth=6, missing=inf, n_estimators=800, subsample=0.8;, score=-513.937 total time=   4.7s\n",
      "[CV 4/5] END colsample_bytree=0.85, learning_rate=0.01, max_depth=6, missing=inf, n_estimators=800, subsample=0.8;, score=-560.002 total time=   4.6s\n",
      "[CV 5/5] END colsample_bytree=0.85, learning_rate=0.01, max_depth=6, missing=inf, n_estimators=800, subsample=0.8;, score=-506.284 total time=   4.7s\n",
      "[CV 4/5] END colsample_bytree=0.85, learning_rate=0.008, max_depth=8, missing=inf, n_estimators=1000, subsample=0.85;, score=-558.056 total time=  15.2s\n",
      "[CV 5/5] END colsample_bytree=0.85, learning_rate=0.008, max_depth=8, missing=inf, n_estimators=1000, subsample=0.85;, score=-506.859 total time=  15.3s\n",
      "[CV 2/5] END colsample_bytree=0.85, learning_rate=0.008, max_depth=8, missing=inf, n_estimators=1200, subsample=0.8;, score=-508.549 total time=  12.8s\n",
      "[CV 3/5] END colsample_bytree=0.85, learning_rate=0.008, max_depth=8, missing=inf, n_estimators=1200, subsample=0.8;, score=-514.356 total time=  12.7s\n",
      "[CV 1/5] END colsample_bytree=0.85, learning_rate=0.008, max_depth=8, missing=inf, n_estimators=1200, subsample=0.8;, score=-502.951 total time=  13.4s\n",
      "[CV 4/5] END colsample_bytree=0.85, learning_rate=0.008, max_depth=8, missing=inf, n_estimators=1200, subsample=0.8;, score=-557.157 total time=  12.7s\n",
      "[CV 5/5] END colsample_bytree=0.85, learning_rate=0.008, max_depth=8, missing=inf, n_estimators=1200, subsample=0.8;, score=-504.997 total time=  13.0s\n",
      "[CV 2/5] END colsample_bytree=0.85, learning_rate=0.008, max_depth=8, missing=inf, n_estimators=1200, subsample=0.85;, score=-510.053 total time=  12.6s\n",
      "[CV 4/5] END colsample_bytree=0.85, learning_rate=0.01, max_depth=6, missing=inf, n_estimators=800, subsample=0.85;, score=-560.431 total time=   4.1s\n",
      "[CV 1/5] END colsample_bytree=0.85, learning_rate=0.01, max_depth=6, missing=inf, n_estimators=800, subsample=0.85;, score=-506.458 total time=   4.5s\n",
      "[CV 2/5] END colsample_bytree=0.85, learning_rate=0.01, max_depth=6, missing=inf, n_estimators=800, subsample=0.85;, score=-508.416 total time=   4.5s\n",
      "[CV 3/5] END colsample_bytree=0.85, learning_rate=0.01, max_depth=6, missing=inf, n_estimators=800, subsample=0.85;, score=-514.326 total time=   4.4s\n",
      "[CV 5/5] END colsample_bytree=0.85, learning_rate=0.01, max_depth=6, missing=inf, n_estimators=800, subsample=0.85;, score=-506.692 total time=   4.6s\n",
      "[CV 1/5] END colsample_bytree=0.85, learning_rate=0.008, max_depth=8, missing=inf, n_estimators=1200, subsample=0.85;, score=-501.454 total time=  14.6s\n",
      "[CV 3/5] END colsample_bytree=0.85, learning_rate=0.008, max_depth=8, missing=inf, n_estimators=1200, subsample=0.85;, score=-515.711 total time=  14.2s\n",
      "[CV 1/5] END colsample_bytree=0.85, learning_rate=0.01, max_depth=6, missing=inf, n_estimators=1000, subsample=0.8;, score=-504.731 total time=   5.0s\n",
      "[CV 2/5] END colsample_bytree=0.85, learning_rate=0.01, max_depth=6, missing=inf, n_estimators=1000, subsample=0.8;, score=-506.520 total time=   5.0s\n",
      "[CV 4/5] END colsample_bytree=0.85, learning_rate=0.008, max_depth=8, missing=inf, n_estimators=1200, subsample=0.85;, score=-557.457 total time=  14.7s\n",
      "[CV 3/5] END colsample_bytree=0.85, learning_rate=0.01, max_depth=6, missing=inf, n_estimators=1000, subsample=0.8;, score=-510.995 total time=   5.0s\n",
      "[CV 1/5] END colsample_bytree=0.85, learning_rate=0.01, max_depth=6, missing=inf, n_estimators=1000, subsample=0.85;, score=-504.934 total time=   4.5s\n",
      "[CV 5/5] END colsample_bytree=0.85, learning_rate=0.008, max_depth=8, missing=inf, n_estimators=1200, subsample=0.85;, score=-505.818 total time=  12.0s\n",
      "[CV 4/5] END colsample_bytree=0.85, learning_rate=0.01, max_depth=6, missing=inf, n_estimators=1000, subsample=0.8;, score=-557.151 total time=   5.4s\n",
      "[CV 5/5] END colsample_bytree=0.85, learning_rate=0.01, max_depth=6, missing=inf, n_estimators=1000, subsample=0.8;, score=-504.975 total time=   5.4s\n",
      "[CV 3/5] END colsample_bytree=0.85, learning_rate=0.01, max_depth=6, missing=inf, n_estimators=1000, subsample=0.85;, score=-511.042 total time=   4.3s\n",
      "[CV 2/5] END colsample_bytree=0.85, learning_rate=0.01, max_depth=6, missing=inf, n_estimators=1000, subsample=0.85;, score=-506.153 total time=   4.5s\n",
      "[CV 4/5] END colsample_bytree=0.85, learning_rate=0.01, max_depth=6, missing=inf, n_estimators=1000, subsample=0.85;, score=-557.777 total time=   4.3s\n",
      "[CV 5/5] END colsample_bytree=0.85, learning_rate=0.01, max_depth=6, missing=inf, n_estimators=1000, subsample=0.85;, score=-504.928 total time=   4.5s\n",
      "[CV 1/5] END colsample_bytree=0.85, learning_rate=0.01, max_depth=6, missing=inf, n_estimators=1200, subsample=0.8;, score=-504.482 total time=   5.2s\n",
      "[CV 2/5] END colsample_bytree=0.85, learning_rate=0.01, max_depth=6, missing=inf, n_estimators=1200, subsample=0.8;, score=-505.330 total time=   6.0s\n",
      "[CV 5/5] END colsample_bytree=0.85, learning_rate=0.01, max_depth=6, missing=inf, n_estimators=1200, subsample=0.8;, score=-504.227 total time=   6.2s\n",
      "[CV 3/5] END colsample_bytree=0.85, learning_rate=0.01, max_depth=6, missing=inf, n_estimators=1200, subsample=0.8;, score=-509.799 total time=   6.4s\n",
      "[CV 4/5] END colsample_bytree=0.85, learning_rate=0.01, max_depth=6, missing=inf, n_estimators=1200, subsample=0.8;, score=-556.221 total time=   6.5s\n",
      "[CV 2/5] END colsample_bytree=0.85, learning_rate=0.01, max_depth=6, missing=inf, n_estimators=1200, subsample=0.85;, score=-505.062 total time=   5.8s\n",
      "[CV 3/5] END colsample_bytree=0.85, learning_rate=0.01, max_depth=6, missing=inf, n_estimators=1200, subsample=0.85;, score=-510.574 total time=   6.0s\n",
      "[CV 1/5] END colsample_bytree=0.85, learning_rate=0.01, max_depth=6, missing=inf, n_estimators=1200, subsample=0.85;, score=-504.125 total time=   6.4s\n",
      "[CV 4/5] END colsample_bytree=0.85, learning_rate=0.01, max_depth=6, missing=inf, n_estimators=1200, subsample=0.85;, score=-556.327 total time=   5.9s\n",
      "[CV 5/5] END colsample_bytree=0.85, learning_rate=0.01, max_depth=6, missing=inf, n_estimators=1200, subsample=0.85;, score=-504.015 total time=   5.9s\n",
      "[CV 1/5] END colsample_bytree=0.85, learning_rate=0.01, max_depth=7, missing=inf, n_estimators=800, subsample=0.8;, score=-502.899 total time=   6.0s\n",
      "[CV 2/5] END colsample_bytree=0.85, learning_rate=0.01, max_depth=7, missing=inf, n_estimators=800, subsample=0.8;, score=-506.285 total time=   5.9s\n",
      "[CV 4/5] END colsample_bytree=0.85, learning_rate=0.01, max_depth=7, missing=inf, n_estimators=800, subsample=0.8;, score=-558.218 total time=   5.4s\n",
      "[CV 3/5] END colsample_bytree=0.85, learning_rate=0.01, max_depth=7, missing=inf, n_estimators=800, subsample=0.8;, score=-512.374 total time=   5.4s\n",
      "[CV 4/5] END colsample_bytree=0.85, learning_rate=0.01, max_depth=7, missing=inf, n_estimators=800, subsample=0.85;, score=-558.348 total time=   5.3s\n",
      "[CV 3/5] END colsample_bytree=0.85, learning_rate=0.01, max_depth=7, missing=inf, n_estimators=800, subsample=0.85;, score=-513.103 total time=   5.5s\n",
      "[CV 2/5] END colsample_bytree=0.85, learning_rate=0.01, max_depth=7, missing=inf, n_estimators=800, subsample=0.85;, score=-506.343 total time=   5.8s\n",
      "[CV 5/5] END colsample_bytree=0.85, learning_rate=0.01, max_depth=7, missing=inf, n_estimators=800, subsample=0.85;, score=-505.084 total time=   5.6s\n",
      "[CV 5/5] END colsample_bytree=0.85, learning_rate=0.01, max_depth=7, missing=inf, n_estimators=800, subsample=0.8;, score=-503.099 total time=   7.1s\n",
      "[CV 1/5] END colsample_bytree=0.85, learning_rate=0.01, max_depth=7, missing=inf, n_estimators=800, subsample=0.85;, score=-504.616 total time=   7.1s\n",
      "[CV 1/5] END colsample_bytree=0.85, learning_rate=0.01, max_depth=7, missing=inf, n_estimators=1000, subsample=0.8;, score=-501.835 total time=   6.7s\n",
      "[CV 2/5] END colsample_bytree=0.85, learning_rate=0.01, max_depth=7, missing=inf, n_estimators=1000, subsample=0.8;, score=-504.825 total time=   7.9s\n",
      "[CV 1/5] END colsample_bytree=0.85, learning_rate=0.01, max_depth=7, missing=inf, n_estimators=1000, subsample=0.85;, score=-503.770 total time=   8.0s\n",
      "[CV 5/5] END colsample_bytree=0.85, learning_rate=0.01, max_depth=7, missing=inf, n_estimators=1000, subsample=0.85;, score=-504.186 total time=   7.8s\n",
      "[CV 4/5] END colsample_bytree=0.85, learning_rate=0.01, max_depth=7, missing=inf, n_estimators=1000, subsample=0.85;, score=-556.910 total time=   7.9s\n",
      "[CV 2/5] END colsample_bytree=0.85, learning_rate=0.01, max_depth=7, missing=inf, n_estimators=1000, subsample=0.85;, score=-505.625 total time=   8.1s\n",
      "[CV 3/5] END colsample_bytree=0.85, learning_rate=0.01, max_depth=7, missing=inf, n_estimators=1000, subsample=0.8;, score=-511.031 total time=   8.8s\n",
      "[CV 4/5] END colsample_bytree=0.85, learning_rate=0.01, max_depth=7, missing=inf, n_estimators=1000, subsample=0.8;, score=-556.331 total time=   8.9s\n",
      "[CV 3/5] END colsample_bytree=0.85, learning_rate=0.01, max_depth=7, missing=inf, n_estimators=1200, subsample=0.8;, score=-511.046 total time=   7.6s\n",
      "[CV 5/5] END colsample_bytree=0.85, learning_rate=0.01, max_depth=7, missing=inf, n_estimators=1000, subsample=0.8;, score=-502.459 total time=   8.9s\n",
      "[CV 4/5] END colsample_bytree=0.85, learning_rate=0.01, max_depth=7, missing=inf, n_estimators=1200, subsample=0.8;, score=-555.656 total time=   7.7s\n",
      "[CV 3/5] END colsample_bytree=0.85, learning_rate=0.01, max_depth=7, missing=inf, n_estimators=1000, subsample=0.85;, score=-511.557 total time=   8.8s\n",
      "[CV 1/5] END colsample_bytree=0.85, learning_rate=0.01, max_depth=7, missing=inf, n_estimators=1200, subsample=0.85;, score=-503.442 total time=   7.7s\n",
      "[CV 5/5] END colsample_bytree=0.85, learning_rate=0.01, max_depth=7, missing=inf, n_estimators=1200, subsample=0.8;, score=-501.734 total time=   7.8s\n",
      "[CV 2/5] END colsample_bytree=0.85, learning_rate=0.01, max_depth=7, missing=inf, n_estimators=1200, subsample=0.85;, score=-505.139 total time=   8.0s\n",
      "[CV 2/5] END colsample_bytree=0.85, learning_rate=0.01, max_depth=7, missing=inf, n_estimators=1200, subsample=0.8;, score=-504.122 total time=   8.9s\n",
      "[CV 1/5] END colsample_bytree=0.85, learning_rate=0.01, max_depth=7, missing=inf, n_estimators=1200, subsample=0.8;, score=-502.377 total time=   9.0s\n",
      "[CV 3/5] END colsample_bytree=0.85, learning_rate=0.01, max_depth=7, missing=inf, n_estimators=1200, subsample=0.85;, score=-510.839 total time=   7.7s\n",
      "[CV 1/5] END colsample_bytree=0.85, learning_rate=0.01, max_depth=8, missing=inf, n_estimators=800, subsample=0.8;, score=-503.245 total time=   8.7s\n",
      "[CV 4/5] END colsample_bytree=0.85, learning_rate=0.01, max_depth=7, missing=inf, n_estimators=1200, subsample=0.85;, score=-556.264 total time=  10.5s\n",
      "[CV 5/5] END colsample_bytree=0.85, learning_rate=0.01, max_depth=7, missing=inf, n_estimators=1200, subsample=0.85;, score=-503.806 total time=  10.5s\n",
      "[CV 2/5] END colsample_bytree=0.85, learning_rate=0.01, max_depth=8, missing=inf, n_estimators=800, subsample=0.8;, score=-509.306 total time=  10.2s\n",
      "[CV 4/5] END colsample_bytree=0.85, learning_rate=0.01, max_depth=8, missing=inf, n_estimators=800, subsample=0.85;, score=-559.425 total time=   9.4s\n",
      "[CV 3/5] END colsample_bytree=0.85, learning_rate=0.01, max_depth=8, missing=inf, n_estimators=800, subsample=0.8;, score=-514.776 total time=  10.5s\n",
      "[CV 4/5] END colsample_bytree=0.85, learning_rate=0.01, max_depth=8, missing=inf, n_estimators=800, subsample=0.8;, score=-556.735 total time=  10.5s\n",
      "[CV 5/5] END colsample_bytree=0.85, learning_rate=0.01, max_depth=8, missing=inf, n_estimators=800, subsample=0.8;, score=-505.402 total time=  10.6s\n",
      "[CV 1/5] END colsample_bytree=0.85, learning_rate=0.01, max_depth=8, missing=inf, n_estimators=800, subsample=0.85;, score=-503.130 total time=  10.6s\n",
      "[CV 1/5] END colsample_bytree=0.85, learning_rate=0.01, max_depth=8, missing=inf, n_estimators=1000, subsample=0.8;, score=-503.096 total time=  10.9s\n",
      "[CV 3/5] END colsample_bytree=0.85, learning_rate=0.01, max_depth=8, missing=inf, n_estimators=1000, subsample=0.8;, score=-513.992 total time=  10.6s\n",
      "[CV 4/5] END colsample_bytree=0.85, learning_rate=0.01, max_depth=8, missing=inf, n_estimators=1000, subsample=0.8;, score=-555.995 total time=  10.9s\n",
      "[CV 3/5] END colsample_bytree=0.85, learning_rate=0.01, max_depth=8, missing=inf, n_estimators=800, subsample=0.85;, score=-516.681 total time=  12.1s\n",
      "[CV 2/5] END colsample_bytree=0.85, learning_rate=0.01, max_depth=8, missing=inf, n_estimators=800, subsample=0.85;, score=-509.587 total time=  12.2s\n",
      "[CV 3/5] END colsample_bytree=0.85, learning_rate=0.01, max_depth=8, missing=inf, n_estimators=1000, subsample=0.85;, score=-516.413 total time=  11.1s\n",
      "[CV 5/5] END colsample_bytree=0.85, learning_rate=0.01, max_depth=8, missing=inf, n_estimators=800, subsample=0.85;, score=-507.412 total time=  12.5s\n",
      "[CV 5/5] END colsample_bytree=0.85, learning_rate=0.01, max_depth=8, missing=inf, n_estimators=1000, subsample=0.8;, score=-504.789 total time=  11.3s\n",
      "[CV 2/5] END colsample_bytree=0.85, learning_rate=0.01, max_depth=8, missing=inf, n_estimators=1000, subsample=0.85;, score=-509.052 total time=  12.1s\n",
      "[CV 1/5] END colsample_bytree=0.85, learning_rate=0.01, max_depth=8, missing=inf, n_estimators=1000, subsample=0.85;, score=-503.104 total time=  12.4s\n",
      "[CV 2/5] END colsample_bytree=0.85, learning_rate=0.01, max_depth=8, missing=inf, n_estimators=1000, subsample=0.8;, score=-509.361 total time=  14.1s\n",
      "[CV 4/5] END colsample_bytree=0.85, learning_rate=0.01, max_depth=8, missing=inf, n_estimators=1000, subsample=0.85;, score=-558.857 total time=  10.6s\n",
      "[CV 3/5] END colsample_bytree=0.85, learning_rate=0.012, max_depth=6, missing=inf, n_estimators=800, subsample=0.8;, score=-512.138 total time=   3.9s\n",
      "[CV 5/5] END colsample_bytree=0.85, learning_rate=0.012, max_depth=6, missing=inf, n_estimators=800, subsample=0.8;, score=-503.373 total time=   3.9s\n",
      "[CV 1/5] END colsample_bytree=0.85, learning_rate=0.012, max_depth=6, missing=inf, n_estimators=800, subsample=0.8;, score=-505.871 total time=   4.7s\n",
      "[CV 2/5] END colsample_bytree=0.85, learning_rate=0.012, max_depth=6, missing=inf, n_estimators=800, subsample=0.8;, score=-506.893 total time=   4.8s\n",
      "[CV 4/5] END colsample_bytree=0.85, learning_rate=0.012, max_depth=6, missing=inf, n_estimators=800, subsample=0.8;, score=-558.757 total time=   5.0s\n",
      "[CV 1/5] END colsample_bytree=0.85, learning_rate=0.012, max_depth=6, missing=inf, n_estimators=800, subsample=0.85;, score=-505.318 total time=   4.4s\n",
      "[CV 2/5] END colsample_bytree=0.85, learning_rate=0.012, max_depth=6, missing=inf, n_estimators=800, subsample=0.85;, score=-505.968 total time=   4.4s\n",
      "[CV 4/5] END colsample_bytree=0.85, learning_rate=0.012, max_depth=6, missing=inf, n_estimators=800, subsample=0.85;, score=-559.335 total time=   3.8s\n",
      "[CV 5/5] END colsample_bytree=0.85, learning_rate=0.01, max_depth=8, missing=inf, n_estimators=1000, subsample=0.85;, score=-506.355 total time=  14.7s\n",
      "[CV 3/5] END colsample_bytree=0.85, learning_rate=0.012, max_depth=6, missing=inf, n_estimators=800, subsample=0.85;, score=-511.554 total time=   5.0s\n",
      "[CV 5/5] END colsample_bytree=0.85, learning_rate=0.012, max_depth=6, missing=inf, n_estimators=800, subsample=0.85;, score=-504.870 total time=   4.1s\n",
      "[CV 1/5] END colsample_bytree=0.85, learning_rate=0.012, max_depth=6, missing=inf, n_estimators=1000, subsample=0.8;, score=-505.561 total time=   4.9s\n",
      "[CV 3/5] END colsample_bytree=0.85, learning_rate=0.01, max_depth=8, missing=inf, n_estimators=1200, subsample=0.8;, score=-514.079 total time=  12.1s\n",
      "[CV 1/5] END colsample_bytree=0.85, learning_rate=0.01, max_depth=8, missing=inf, n_estimators=1200, subsample=0.8;, score=-503.512 total time=  16.7s\n",
      "[CV 2/5] END colsample_bytree=0.85, learning_rate=0.01, max_depth=8, missing=inf, n_estimators=1200, subsample=0.8;, score=-509.321 total time=  13.5s\n",
      "[CV 2/5] END colsample_bytree=0.85, learning_rate=0.012, max_depth=6, missing=inf, n_estimators=1000, subsample=0.8;, score=-505.114 total time=   5.7s\n",
      "[CV 3/5] END colsample_bytree=0.85, learning_rate=0.012, max_depth=6, missing=inf, n_estimators=1000, subsample=0.8;, score=-510.392 total time=   5.7s\n",
      "[CV 3/5] END colsample_bytree=0.85, learning_rate=0.01, max_depth=8, missing=inf, n_estimators=1200, subsample=0.85;, score=-516.273 total time=  11.8s\n",
      "[CV 5/5] END colsample_bytree=0.85, learning_rate=0.012, max_depth=6, missing=inf, n_estimators=1000, subsample=0.8;, score=-502.930 total time=   4.9s\n",
      "[CV 4/5] END colsample_bytree=0.85, learning_rate=0.01, max_depth=8, missing=inf, n_estimators=1200, subsample=0.8;, score=-555.506 total time=  13.1s\n",
      "[CV 1/5] END colsample_bytree=0.85, learning_rate=0.012, max_depth=6, missing=inf, n_estimators=1000, subsample=0.85;, score=-504.775 total time=   4.8s\n",
      "[CV 4/5] END colsample_bytree=0.85, learning_rate=0.01, max_depth=8, missing=inf, n_estimators=1200, subsample=0.85;, score=-558.718 total time=  11.7s\n",
      "[CV 2/5] END colsample_bytree=0.85, learning_rate=0.012, max_depth=6, missing=inf, n_estimators=1000, subsample=0.85;, score=-504.539 total time=   4.2s\n",
      "[CV 5/5] END colsample_bytree=0.85, learning_rate=0.01, max_depth=8, missing=inf, n_estimators=1200, subsample=0.8;, score=-503.920 total time=  13.1s[CV 4/5] END colsample_bytree=0.85, learning_rate=0.012, max_depth=6, missing=inf, n_estimators=1000, subsample=0.8;, score=-556.860 total time=   5.5s\n",
      "\n",
      "[CV 5/5] END colsample_bytree=0.85, learning_rate=0.01, max_depth=8, missing=inf, n_estimators=1200, subsample=0.85;, score=-506.083 total time=  11.6s\n",
      "[CV 1/5] END colsample_bytree=0.85, learning_rate=0.01, max_depth=8, missing=inf, n_estimators=1200, subsample=0.85;, score=-503.295 total time=  13.1s\n",
      "[CV 2/5] END colsample_bytree=0.85, learning_rate=0.01, max_depth=8, missing=inf, n_estimators=1200, subsample=0.85;, score=-509.494 total time=  13.2s\n",
      "[CV 5/5] END colsample_bytree=0.85, learning_rate=0.012, max_depth=6, missing=inf, n_estimators=1000, subsample=0.85;, score=-504.018 total time=   4.1s\n",
      "[CV 3/5] END colsample_bytree=0.85, learning_rate=0.012, max_depth=6, missing=inf, n_estimators=1000, subsample=0.85;, score=-510.015 total time=   5.3s\n",
      "[CV 4/5] END colsample_bytree=0.85, learning_rate=0.012, max_depth=6, missing=inf, n_estimators=1000, subsample=0.85;, score=-557.593 total time=   5.4s\n",
      "[CV 2/5] END colsample_bytree=0.85, learning_rate=0.012, max_depth=6, missing=inf, n_estimators=1200, subsample=0.8;, score=-504.577 total time=   5.1s\n",
      "[CV 1/5] END colsample_bytree=0.85, learning_rate=0.012, max_depth=6, missing=inf, n_estimators=1200, subsample=0.8;, score=-506.347 total time=   5.2s\n",
      "[CV 4/5] END colsample_bytree=0.85, learning_rate=0.012, max_depth=6, missing=inf, n_estimators=1200, subsample=0.8;, score=-555.796 total time=   5.6s\n",
      "[CV 2/5] END colsample_bytree=0.85, learning_rate=0.012, max_depth=6, missing=inf, n_estimators=1200, subsample=0.85;, score=-504.807 total time=   5.1s\n",
      "[CV 2/5] END colsample_bytree=0.85, learning_rate=0.012, max_depth=7, missing=inf, n_estimators=800, subsample=0.8;, score=-506.726 total time=   5.1s\n",
      "[CV 3/5] END colsample_bytree=0.85, learning_rate=0.012, max_depth=6, missing=inf, n_estimators=1200, subsample=0.8;, score=-509.502 total time=   6.4s\n",
      "[CV 5/5] END colsample_bytree=0.85, learning_rate=0.012, max_depth=7, missing=inf, n_estimators=800, subsample=0.8;, score=-502.526 total time=   5.2s\n",
      "[CV 3/5] END colsample_bytree=0.85, learning_rate=0.012, max_depth=6, missing=inf, n_estimators=1200, subsample=0.85;, score=-509.740 total time=   5.7s\n",
      "[CV 1/5] END colsample_bytree=0.85, learning_rate=0.012, max_depth=7, missing=inf, n_estimators=800, subsample=0.8;, score=-500.896 total time=   5.7s\n",
      "[CV 4/5] END colsample_bytree=0.85, learning_rate=0.012, max_depth=6, missing=inf, n_estimators=1200, subsample=0.85;, score=-556.745 total time=   5.8s\n",
      "[CV 5/5] END colsample_bytree=0.85, learning_rate=0.012, max_depth=6, missing=inf, n_estimators=1200, subsample=0.85;, score=-503.509 total time=   5.9s\n",
      "[CV 3/5] END colsample_bytree=0.85, learning_rate=0.012, max_depth=7, missing=inf, n_estimators=800, subsample=0.8;, score=-512.018 total time=   5.8s\n",
      "[CV 5/5] END colsample_bytree=0.85, learning_rate=0.012, max_depth=6, missing=inf, n_estimators=1200, subsample=0.8;, score=-502.260 total time=   6.4s\n",
      "[CV 1/5] END colsample_bytree=0.85, learning_rate=0.012, max_depth=6, missing=inf, n_estimators=1200, subsample=0.85;, score=-504.054 total time=   6.5s\n",
      "[CV 1/5] END colsample_bytree=0.85, learning_rate=0.012, max_depth=7, missing=inf, n_estimators=800, subsample=0.85;, score=-501.211 total time=   6.1s\n",
      "[CV 2/5] END colsample_bytree=0.85, learning_rate=0.012, max_depth=7, missing=inf, n_estimators=800, subsample=0.85;, score=-506.191 total time=   6.0s\n",
      "[CV 3/5] END colsample_bytree=0.85, learning_rate=0.012, max_depth=7, missing=inf, n_estimators=800, subsample=0.85;, score=-513.598 total time=   5.4s\n",
      "[CV 4/5] END colsample_bytree=0.85, learning_rate=0.012, max_depth=7, missing=inf, n_estimators=800, subsample=0.8;, score=-557.072 total time=   7.0s\n",
      "[CV 4/5] END colsample_bytree=0.85, learning_rate=0.012, max_depth=7, missing=inf, n_estimators=800, subsample=0.85;, score=-557.712 total time=   7.0s\n",
      "[CV 5/5] END colsample_bytree=0.85, learning_rate=0.012, max_depth=7, missing=inf, n_estimators=800, subsample=0.85;, score=-504.052 total time=   6.9s\n",
      "[CV 1/5] END colsample_bytree=0.85, learning_rate=0.012, max_depth=7, missing=inf, n_estimators=1000, subsample=0.8;, score=-501.071 total time=   6.4s\n",
      "[CV 2/5] END colsample_bytree=0.85, learning_rate=0.012, max_depth=7, missing=inf, n_estimators=1000, subsample=0.8;, score=-506.575 total time=   6.8s\n",
      "[CV 4/5] END colsample_bytree=0.85, learning_rate=0.012, max_depth=7, missing=inf, n_estimators=1000, subsample=0.8;, score=-555.607 total time=   6.4s\n",
      "[CV 5/5] END colsample_bytree=0.85, learning_rate=0.012, max_depth=7, missing=inf, n_estimators=1000, subsample=0.8;, score=-501.962 total time=   6.6s\n",
      "[CV 2/5] END colsample_bytree=0.85, learning_rate=0.012, max_depth=7, missing=inf, n_estimators=1000, subsample=0.85;, score=-506.465 total time=   6.5s\n",
      "[CV 3/5] END colsample_bytree=0.85, learning_rate=0.012, max_depth=7, missing=inf, n_estimators=1000, subsample=0.8;, score=-511.123 total time=   7.3s\n",
      "[CV 4/5] END colsample_bytree=0.85, learning_rate=0.012, max_depth=7, missing=inf, n_estimators=1000, subsample=0.85;, score=-556.761 total time=   6.6s\n",
      "[CV 3/5] END colsample_bytree=0.85, learning_rate=0.012, max_depth=7, missing=inf, n_estimators=1000, subsample=0.85;, score=-512.799 total time=   7.6s\n",
      "[CV 5/5] END colsample_bytree=0.85, learning_rate=0.012, max_depth=7, missing=inf, n_estimators=1000, subsample=0.85;, score=-503.440 total time=   7.8s\n",
      "[CV 1/5] END colsample_bytree=0.85, learning_rate=0.012, max_depth=7, missing=inf, n_estimators=1000, subsample=0.85;, score=-501.214 total time=   8.4s\n",
      "[CV 3/5] END colsample_bytree=0.85, learning_rate=0.012, max_depth=7, missing=inf, n_estimators=1200, subsample=0.8;, score=-510.754 total time=   8.7s\n",
      "[CV 1/5] END colsample_bytree=0.85, learning_rate=0.012, max_depth=7, missing=inf, n_estimators=1200, subsample=0.8;, score=-502.134 total time=   8.9s\n",
      "[CV 5/5] END colsample_bytree=0.85, learning_rate=0.012, max_depth=7, missing=inf, n_estimators=1200, subsample=0.8;, score=-501.088 total time=   8.7s\n",
      "[CV 2/5] END colsample_bytree=0.85, learning_rate=0.012, max_depth=7, missing=inf, n_estimators=1200, subsample=0.85;, score=-506.783 total time=   8.3s\n",
      "[CV 1/5] END colsample_bytree=0.85, learning_rate=0.012, max_depth=7, missing=inf, n_estimators=1200, subsample=0.85;, score=-501.176 total time=   8.9s\n",
      "[CV 2/5] END colsample_bytree=0.85, learning_rate=0.012, max_depth=7, missing=inf, n_estimators=1200, subsample=0.8;, score=-506.247 total time=  10.3s\n",
      "[CV 4/5] END colsample_bytree=0.85, learning_rate=0.012, max_depth=7, missing=inf, n_estimators=1200, subsample=0.8;, score=-555.132 total time=  10.2s\n",
      "[CV 3/5] END colsample_bytree=0.85, learning_rate=0.012, max_depth=7, missing=inf, n_estimators=1200, subsample=0.85;, score=-513.374 total time=  10.3s\n",
      "[CV 1/5] END colsample_bytree=0.85, learning_rate=0.012, max_depth=8, missing=inf, n_estimators=800, subsample=0.8;, score=-502.501 total time=   8.5s\n",
      "[CV 2/5] END colsample_bytree=0.85, learning_rate=0.012, max_depth=8, missing=inf, n_estimators=800, subsample=0.8;, score=-509.413 total time=   8.7s\n",
      "[CV 4/5] END colsample_bytree=0.85, learning_rate=0.012, max_depth=7, missing=inf, n_estimators=1200, subsample=0.85;, score=-556.794 total time=  10.3s\n",
      "[CV 5/5] END colsample_bytree=0.85, learning_rate=0.012, max_depth=7, missing=inf, n_estimators=1200, subsample=0.85;, score=-503.025 total time=  10.5s\n",
      "[CV 3/5] END colsample_bytree=0.85, learning_rate=0.012, max_depth=8, missing=inf, n_estimators=800, subsample=0.8;, score=-515.671 total time=   8.4s\n",
      "[CV 4/5] END colsample_bytree=0.85, learning_rate=0.012, max_depth=8, missing=inf, n_estimators=800, subsample=0.8;, score=-558.685 total time=   8.3s\n",
      "[CV 5/5] END colsample_bytree=0.85, learning_rate=0.012, max_depth=8, missing=inf, n_estimators=800, subsample=0.8;, score=-501.812 total time=   8.5s\n",
      "[CV 2/5] END colsample_bytree=0.85, learning_rate=0.012, max_depth=8, missing=inf, n_estimators=800, subsample=0.85;, score=-510.087 total time=   8.3s\n",
      "[CV 1/5] END colsample_bytree=0.85, learning_rate=0.012, max_depth=8, missing=inf, n_estimators=800, subsample=0.85;, score=-502.755 total time=  10.2s\n",
      "[CV 3/5] END colsample_bytree=0.85, learning_rate=0.012, max_depth=8, missing=inf, n_estimators=800, subsample=0.85;, score=-516.670 total time=  10.4s\n",
      "[CV 4/5] END colsample_bytree=0.85, learning_rate=0.012, max_depth=8, missing=inf, n_estimators=800, subsample=0.85;, score=-558.269 total time=  10.4s\n",
      "[CV 5/5] END colsample_bytree=0.85, learning_rate=0.012, max_depth=8, missing=inf, n_estimators=800, subsample=0.85;, score=-505.157 total time=  10.5s\n",
      "[CV 2/5] END colsample_bytree=0.85, learning_rate=0.012, max_depth=8, missing=inf, n_estimators=1000, subsample=0.8;, score=-509.849 total time=  12.6s\n",
      "[CV 1/5] END colsample_bytree=0.85, learning_rate=0.012, max_depth=8, missing=inf, n_estimators=1000, subsample=0.8;, score=-502.313 total time=  12.8s\n",
      "[CV 3/5] END colsample_bytree=0.85, learning_rate=0.012, max_depth=8, missing=inf, n_estimators=1000, subsample=0.8;, score=-515.850 total time=  12.7s\n",
      "[CV 4/5] END colsample_bytree=0.85, learning_rate=0.012, max_depth=8, missing=inf, n_estimators=1000, subsample=0.8;, score=-557.585 total time=  12.8s\n",
      "[CV 4/5] END colsample_bytree=0.85, learning_rate=0.012, max_depth=8, missing=inf, n_estimators=1000, subsample=0.85;, score=-557.113 total time=  10.4s\n",
      "[CV 5/5] END colsample_bytree=0.85, learning_rate=0.012, max_depth=8, missing=inf, n_estimators=1000, subsample=0.8;, score=-501.702 total time=  13.9s\n",
      "[CV 5/5] END colsample_bytree=0.85, learning_rate=0.012, max_depth=8, missing=inf, n_estimators=1000, subsample=0.85;, score=-504.099 total time=  10.5s\n",
      "[CV 1/5] END colsample_bytree=0.85, learning_rate=0.012, max_depth=8, missing=inf, n_estimators=1000, subsample=0.85;, score=-503.118 total time=  14.3s\n",
      "[CV 2/5] END colsample_bytree=0.85, learning_rate=0.012, max_depth=8, missing=inf, n_estimators=1000, subsample=0.85;, score=-509.932 total time=  14.2s\n",
      "[CV 1/5] END colsample_bytree=0.9, learning_rate=0.008, max_depth=6, missing=inf, n_estimators=800, subsample=0.8;, score=-510.031 total time=   4.4s\n",
      "[CV 3/5] END colsample_bytree=0.85, learning_rate=0.012, max_depth=8, missing=inf, n_estimators=1000, subsample=0.85;, score=-516.350 total time=  14.3s\n",
      "[CV 3/5] END colsample_bytree=0.85, learning_rate=0.012, max_depth=8, missing=inf, n_estimators=1200, subsample=0.8;, score=-516.352 total time=  12.2s\n",
      "[CV 2/5] END colsample_bytree=0.9, learning_rate=0.008, max_depth=6, missing=inf, n_estimators=800, subsample=0.8;, score=-512.526 total time=   4.5s\n",
      "[CV 5/5] END colsample_bytree=0.85, learning_rate=0.012, max_depth=8, missing=inf, n_estimators=1200, subsample=0.8;, score=-501.211 total time=  12.0s\n",
      "[CV 3/5] END colsample_bytree=0.9, learning_rate=0.008, max_depth=6, missing=inf, n_estimators=800, subsample=0.8;, score=-517.240 total time=   4.4s\n",
      "[CV 4/5] END colsample_bytree=0.85, learning_rate=0.012, max_depth=8, missing=inf, n_estimators=1200, subsample=0.8;, score=-557.702 total time=  12.4s\n",
      "[CV 1/5] END colsample_bytree=0.85, learning_rate=0.012, max_depth=8, missing=inf, n_estimators=1200, subsample=0.85;, score=-503.881 total time=  12.0s\n",
      "[CV 5/5] END colsample_bytree=0.9, learning_rate=0.008, max_depth=6, missing=inf, n_estimators=800, subsample=0.8;, score=-508.518 total time=   3.7s\n",
      "[CV 4/5] END colsample_bytree=0.9, learning_rate=0.008, max_depth=6, missing=inf, n_estimators=800, subsample=0.8;, score=-565.633 total time=   4.6s\n",
      "[CV 2/5] END colsample_bytree=0.9, learning_rate=0.008, max_depth=6, missing=inf, n_estimators=800, subsample=0.85;, score=-511.485 total time=   3.9s\n",
      "[CV 1/5] END colsample_bytree=0.9, learning_rate=0.008, max_depth=6, missing=inf, n_estimators=800, subsample=0.85;, score=-510.545 total time=   5.0s\n",
      "[CV 3/5] END colsample_bytree=0.9, learning_rate=0.008, max_depth=6, missing=inf, n_estimators=800, subsample=0.85;, score=-516.380 total time=   4.8s\n",
      "[CV 4/5] END colsample_bytree=0.9, learning_rate=0.008, max_depth=6, missing=inf, n_estimators=800, subsample=0.85;, score=-565.155 total time=   4.7s\n",
      "[CV 1/5] END colsample_bytree=0.85, learning_rate=0.012, max_depth=8, missing=inf, n_estimators=1200, subsample=0.8;, score=-502.542 total time=  16.2s\n",
      "[CV 2/5] END colsample_bytree=0.85, learning_rate=0.012, max_depth=8, missing=inf, n_estimators=1200, subsample=0.8;, score=-509.905 total time=  16.0s\n",
      "[CV 5/5] END colsample_bytree=0.85, learning_rate=0.012, max_depth=8, missing=inf, n_estimators=1200, subsample=0.85;, score=-503.338 total time=  11.5s\n",
      "[CV 2/5] END colsample_bytree=0.85, learning_rate=0.012, max_depth=8, missing=inf, n_estimators=1200, subsample=0.85;, score=-510.109 total time=  13.7s\n",
      "[CV 5/5] END colsample_bytree=0.9, learning_rate=0.008, max_depth=6, missing=inf, n_estimators=800, subsample=0.85;, score=-508.166 total time=   4.5s\n",
      "[CV 2/5] END colsample_bytree=0.9, learning_rate=0.008, max_depth=6, missing=inf, n_estimators=1000, subsample=0.8;, score=-508.308 total time=   4.4s\n",
      "[CV 1/5] END colsample_bytree=0.9, learning_rate=0.008, max_depth=6, missing=inf, n_estimators=1000, subsample=0.85;, score=-506.899 total time=   4.4s\n",
      "[CV 3/5] END colsample_bytree=0.85, learning_rate=0.012, max_depth=8, missing=inf, n_estimators=1200, subsample=0.85;, score=-516.533 total time=  13.3s\n",
      "[CV 5/5] END colsample_bytree=0.9, learning_rate=0.008, max_depth=6, missing=inf, n_estimators=1000, subsample=0.8;, score=-505.551 total time=   4.5s\n",
      "[CV 2/5] END colsample_bytree=0.9, learning_rate=0.008, max_depth=6, missing=inf, n_estimators=1000, subsample=0.85;, score=-507.944 total time=   4.4s\n",
      "[CV 3/5] END colsample_bytree=0.9, learning_rate=0.008, max_depth=6, missing=inf, n_estimators=1000, subsample=0.85;, score=-511.883 total time=   4.4s\n",
      "[CV 4/5] END colsample_bytree=0.85, learning_rate=0.012, max_depth=8, missing=inf, n_estimators=1200, subsample=0.85;, score=-557.191 total time=  13.3s\n",
      "[CV 3/5] END colsample_bytree=0.9, learning_rate=0.008, max_depth=6, missing=inf, n_estimators=1000, subsample=0.8;, score=-512.665 total time=   5.2s\n",
      "[CV 1/5] END colsample_bytree=0.9, learning_rate=0.008, max_depth=6, missing=inf, n_estimators=1000, subsample=0.8;, score=-507.008 total time=   5.6s\n",
      "[CV 4/5] END colsample_bytree=0.9, learning_rate=0.008, max_depth=6, missing=inf, n_estimators=1000, subsample=0.8;, score=-560.708 total time=   5.3s\n",
      "[CV 4/5] END colsample_bytree=0.9, learning_rate=0.008, max_depth=6, missing=inf, n_estimators=1000, subsample=0.85;, score=-560.941 total time=   5.0s\n",
      "[CV 5/5] END colsample_bytree=0.9, learning_rate=0.008, max_depth=6, missing=inf, n_estimators=1000, subsample=0.85;, score=-504.848 total time=   4.6s\n",
      "[CV 1/5] END colsample_bytree=0.9, learning_rate=0.008, max_depth=6, missing=inf, n_estimators=1200, subsample=0.8;, score=-505.726 total time=   6.7s\n",
      "[CV 1/5] END colsample_bytree=0.9, learning_rate=0.008, max_depth=6, missing=inf, n_estimators=1200, subsample=0.85;, score=-505.012 total time=   5.5s\n",
      "[CV 4/5] END colsample_bytree=0.9, learning_rate=0.008, max_depth=6, missing=inf, n_estimators=1200, subsample=0.85;, score=-558.866 total time=   5.5s\n",
      "[CV 4/5] END colsample_bytree=0.9, learning_rate=0.008, max_depth=6, missing=inf, n_estimators=1200, subsample=0.8;, score=-558.386 total time=   6.4s\n",
      "[CV 2/5] END colsample_bytree=0.9, learning_rate=0.008, max_depth=6, missing=inf, n_estimators=1200, subsample=0.8;, score=-506.253 total time=   6.6s\n",
      "[CV 2/5] END colsample_bytree=0.9, learning_rate=0.008, max_depth=6, missing=inf, n_estimators=1200, subsample=0.85;, score=-506.387 total time=   6.1s\n",
      "[CV 3/5] END colsample_bytree=0.9, learning_rate=0.008, max_depth=6, missing=inf, n_estimators=1200, subsample=0.8;, score=-511.035 total time=   6.8s\n",
      "[CV 5/5] END colsample_bytree=0.9, learning_rate=0.008, max_depth=6, missing=inf, n_estimators=1200, subsample=0.85;, score=-503.569 total time=   5.4s\n",
      "[CV 5/5] END colsample_bytree=0.9, learning_rate=0.008, max_depth=6, missing=inf, n_estimators=1200, subsample=0.8;, score=-504.773 total time=   6.8s\n",
      "[CV 1/5] END colsample_bytree=0.9, learning_rate=0.008, max_depth=7, missing=inf, n_estimators=800, subsample=0.8;, score=-503.988 total time=   5.7s\n",
      "[CV 3/5] END colsample_bytree=0.9, learning_rate=0.008, max_depth=6, missing=inf, n_estimators=1200, subsample=0.85;, score=-510.276 total time=   6.4s\n",
      "[CV 3/5] END colsample_bytree=0.9, learning_rate=0.008, max_depth=7, missing=inf, n_estimators=800, subsample=0.8;, score=-514.667 total time=   5.9s\n",
      "[CV 4/5] END colsample_bytree=0.9, learning_rate=0.008, max_depth=7, missing=inf, n_estimators=800, subsample=0.8;, score=-560.402 total time=   5.8s\n",
      "[CV 2/5] END colsample_bytree=0.9, learning_rate=0.008, max_depth=7, missing=inf, n_estimators=800, subsample=0.8;, score=-509.327 total time=   6.5s\n",
      "[CV 5/5] END colsample_bytree=0.9, learning_rate=0.008, max_depth=7, missing=inf, n_estimators=800, subsample=0.8;, score=-504.862 total time=   6.6s\n",
      "[CV 1/5] END colsample_bytree=0.9, learning_rate=0.008, max_depth=7, missing=inf, n_estimators=800, subsample=0.85;, score=-505.366 total time=   6.6s\n",
      "[CV 3/5] END colsample_bytree=0.9, learning_rate=0.008, max_depth=7, missing=inf, n_estimators=800, subsample=0.85;, score=-514.970 total time=   6.7s\n",
      "[CV 5/5] END colsample_bytree=0.9, learning_rate=0.008, max_depth=7, missing=inf, n_estimators=800, subsample=0.85;, score=-505.673 total time=   6.1s\n",
      "[CV 4/5] END colsample_bytree=0.9, learning_rate=0.008, max_depth=7, missing=inf, n_estimators=800, subsample=0.85;, score=-560.430 total time=   6.9s\n",
      "[CV 2/5] END colsample_bytree=0.9, learning_rate=0.008, max_depth=7, missing=inf, n_estimators=800, subsample=0.85;, score=-509.433 total time=   7.3s\n",
      "[CV 2/5] END colsample_bytree=0.9, learning_rate=0.008, max_depth=7, missing=inf, n_estimators=1000, subsample=0.8;, score=-507.277 total time=   6.9s\n",
      "[CV 3/5] END colsample_bytree=0.9, learning_rate=0.008, max_depth=7, missing=inf, n_estimators=1000, subsample=0.8;, score=-512.292 total time=   7.1s\n",
      "[CV 3/5] END colsample_bytree=0.9, learning_rate=0.008, max_depth=7, missing=inf, n_estimators=1000, subsample=0.85;, score=-512.621 total time=   7.0s\n",
      "[CV 5/5] END colsample_bytree=0.9, learning_rate=0.008, max_depth=7, missing=inf, n_estimators=1000, subsample=0.85;, score=-503.573 total time=   7.2s\n",
      "[CV 1/5] END colsample_bytree=0.9, learning_rate=0.008, max_depth=7, missing=inf, n_estimators=1000, subsample=0.8;, score=-501.921 total time=   9.3s\n",
      "[CV 1/5] END colsample_bytree=0.9, learning_rate=0.008, max_depth=7, missing=inf, n_estimators=1000, subsample=0.85;, score=-503.135 total time=   8.3s\n",
      "[CV 2/5] END colsample_bytree=0.9, learning_rate=0.008, max_depth=7, missing=inf, n_estimators=1200, subsample=0.8;, score=-505.703 total time=   8.1s\n",
      "[CV 4/5] END colsample_bytree=0.9, learning_rate=0.008, max_depth=7, missing=inf, n_estimators=1000, subsample=0.8;, score=-557.619 total time=   9.2s\n",
      "[CV 5/5] END colsample_bytree=0.9, learning_rate=0.008, max_depth=7, missing=inf, n_estimators=1000, subsample=0.8;, score=-504.026 total time=   9.2s\n",
      "[CV 3/5] END colsample_bytree=0.9, learning_rate=0.008, max_depth=7, missing=inf, n_estimators=1200, subsample=0.8;, score=-511.277 total time=   8.4s\n",
      "[CV 2/5] END colsample_bytree=0.9, learning_rate=0.008, max_depth=7, missing=inf, n_estimators=1000, subsample=0.85;, score=-506.896 total time=   9.2s\n",
      "[CV 4/5] END colsample_bytree=0.9, learning_rate=0.008, max_depth=7, missing=inf, n_estimators=1000, subsample=0.85;, score=-558.086 total time=   9.3s\n",
      "[CV 1/5] END colsample_bytree=0.9, learning_rate=0.008, max_depth=7, missing=inf, n_estimators=1200, subsample=0.8;, score=-501.317 total time=   9.5s\n",
      "[CV 4/5] END colsample_bytree=0.9, learning_rate=0.008, max_depth=7, missing=inf, n_estimators=1200, subsample=0.8;, score=-556.605 total time=   9.5s\n",
      "[CV 5/5] END colsample_bytree=0.9, learning_rate=0.008, max_depth=7, missing=inf, n_estimators=1200, subsample=0.8;, score=-503.241 total time=   9.4s\n",
      "[CV 1/5] END colsample_bytree=0.9, learning_rate=0.008, max_depth=7, missing=inf, n_estimators=1200, subsample=0.85;, score=-502.298 total time=   9.5s\n",
      "[CV 3/5] END colsample_bytree=0.9, learning_rate=0.008, max_depth=7, missing=inf, n_estimators=1200, subsample=0.85;, score=-511.602 total time=   9.0s\n",
      "[CV 2/5] END colsample_bytree=0.9, learning_rate=0.008, max_depth=7, missing=inf, n_estimators=1200, subsample=0.85;, score=-506.134 total time=   9.4s\n",
      "[CV 4/5] END colsample_bytree=0.9, learning_rate=0.008, max_depth=7, missing=inf, n_estimators=1200, subsample=0.85;, score=-556.485 total time=   9.9s\n",
      "[CV 5/5] END colsample_bytree=0.9, learning_rate=0.008, max_depth=7, missing=inf, n_estimators=1200, subsample=0.85;, score=-502.784 total time=  10.9s\n",
      "[CV 1/5] END colsample_bytree=0.9, learning_rate=0.008, max_depth=8, missing=inf, n_estimators=800, subsample=0.8;, score=-503.567 total time=  10.1s\n",
      "[CV 2/5] END colsample_bytree=0.9, learning_rate=0.008, max_depth=8, missing=inf, n_estimators=800, subsample=0.8;, score=-509.906 total time=   9.6s\n",
      "[CV 3/5] END colsample_bytree=0.9, learning_rate=0.008, max_depth=8, missing=inf, n_estimators=800, subsample=0.8;, score=-516.393 total time=   9.4s\n",
      "[CV 4/5] END colsample_bytree=0.9, learning_rate=0.008, max_depth=8, missing=inf, n_estimators=800, subsample=0.8;, score=-559.507 total time=   9.7s\n",
      "[CV 5/5] END colsample_bytree=0.9, learning_rate=0.008, max_depth=8, missing=inf, n_estimators=800, subsample=0.85;, score=-507.976 total time=   9.5s\n",
      "[CV 2/5] END colsample_bytree=0.9, learning_rate=0.008, max_depth=8, missing=inf, n_estimators=800, subsample=0.85;, score=-511.477 total time=   9.9s\n",
      "[CV 1/5] END colsample_bytree=0.9, learning_rate=0.008, max_depth=8, missing=inf, n_estimators=800, subsample=0.85;, score=-503.155 total time=  11.2s\n",
      "[CV 5/5] END colsample_bytree=0.9, learning_rate=0.008, max_depth=8, missing=inf, n_estimators=800, subsample=0.8;, score=-506.126 total time=  12.8s\n",
      "[CV 4/5] END colsample_bytree=0.9, learning_rate=0.008, max_depth=8, missing=inf, n_estimators=800, subsample=0.85;, score=-559.551 total time=  13.1s\n",
      "[CV 3/5] END colsample_bytree=0.9, learning_rate=0.008, max_depth=8, missing=inf, n_estimators=800, subsample=0.85;, score=-517.401 total time=  13.4s\n",
      "[CV 3/5] END colsample_bytree=0.9, learning_rate=0.008, max_depth=8, missing=inf, n_estimators=1000, subsample=0.8;, score=-515.050 total time=  13.3s\n",
      "[CV 4/5] END colsample_bytree=0.9, learning_rate=0.008, max_depth=8, missing=inf, n_estimators=1000, subsample=0.8;, score=-557.624 total time=  12.5s\n",
      "[CV 2/5] END colsample_bytree=0.9, learning_rate=0.008, max_depth=8, missing=inf, n_estimators=1000, subsample=0.85;, score=-510.231 total time=  12.1s\n",
      "[CV 5/5] END colsample_bytree=0.9, learning_rate=0.008, max_depth=8, missing=inf, n_estimators=1000, subsample=0.8;, score=-505.510 total time=  12.8s\n",
      "[CV 1/5] END colsample_bytree=0.9, learning_rate=0.008, max_depth=8, missing=inf, n_estimators=1000, subsample=0.85;, score=-501.797 total time=  13.0s\n",
      "[CV 1/5] END colsample_bytree=0.9, learning_rate=0.008, max_depth=8, missing=inf, n_estimators=1000, subsample=0.8;, score=-502.795 total time=  15.2s\n",
      "[CV 2/5] END colsample_bytree=0.9, learning_rate=0.008, max_depth=8, missing=inf, n_estimators=1000, subsample=0.8;, score=-508.974 total time=  15.0s\n",
      "[CV 3/5] END colsample_bytree=0.9, learning_rate=0.008, max_depth=8, missing=inf, n_estimators=1000, subsample=0.85;, score=-516.314 total time=  13.0s\n",
      "[CV 4/5] END colsample_bytree=0.9, learning_rate=0.008, max_depth=8, missing=inf, n_estimators=1000, subsample=0.85;, score=-558.056 total time=  12.9s\n",
      "[CV 3/5] END colsample_bytree=0.9, learning_rate=0.01, max_depth=6, missing=inf, n_estimators=800, subsample=0.8;, score=-513.937 total time=   4.2s\n",
      "[CV 2/5] END colsample_bytree=0.9, learning_rate=0.01, max_depth=6, missing=inf, n_estimators=800, subsample=0.8;, score=-509.027 total time=   4.4s\n",
      "[CV 1/5] END colsample_bytree=0.9, learning_rate=0.01, max_depth=6, missing=inf, n_estimators=800, subsample=0.8;, score=-506.382 total time=   4.5s\n",
      "[CV 4/5] END colsample_bytree=0.9, learning_rate=0.01, max_depth=6, missing=inf, n_estimators=800, subsample=0.8;, score=-560.002 total time=   4.5s\n",
      "[CV 5/5] END colsample_bytree=0.9, learning_rate=0.008, max_depth=8, missing=inf, n_estimators=1000, subsample=0.85;, score=-506.859 total time=  15.0s\n",
      "[CV 5/5] END colsample_bytree=0.9, learning_rate=0.01, max_depth=6, missing=inf, n_estimators=800, subsample=0.8;, score=-506.284 total time=   4.4s\n",
      "[CV 1/5] END colsample_bytree=0.9, learning_rate=0.008, max_depth=8, missing=inf, n_estimators=1200, subsample=0.8;, score=-502.951 total time=  12.9s\n",
      "[CV 3/5] END colsample_bytree=0.9, learning_rate=0.01, max_depth=6, missing=inf, n_estimators=800, subsample=0.85;, score=-514.326 total time=   4.2s[CV 2/5] END colsample_bytree=0.9, learning_rate=0.008, max_depth=8, missing=inf, n_estimators=1200, subsample=0.8;, score=-508.549 total time=  12.5s\n",
      "\n",
      "[CV 3/5] END colsample_bytree=0.9, learning_rate=0.008, max_depth=8, missing=inf, n_estimators=1200, subsample=0.8;, score=-514.356 total time=  12.7s\n",
      "[CV 2/5] END colsample_bytree=0.9, learning_rate=0.01, max_depth=6, missing=inf, n_estimators=800, subsample=0.85;, score=-508.416 total time=   4.7s\n",
      "[CV 1/5] END colsample_bytree=0.9, learning_rate=0.01, max_depth=6, missing=inf, n_estimators=800, subsample=0.85;, score=-506.458 total time=   4.8s\n",
      "[CV 4/5] END colsample_bytree=0.9, learning_rate=0.01, max_depth=6, missing=inf, n_estimators=800, subsample=0.85;, score=-560.431 total time=   4.3s\n",
      "[CV 4/5] END colsample_bytree=0.9, learning_rate=0.008, max_depth=8, missing=inf, n_estimators=1200, subsample=0.8;, score=-557.157 total time=  12.4s\n",
      "[CV 5/5] END colsample_bytree=0.9, learning_rate=0.008, max_depth=8, missing=inf, n_estimators=1200, subsample=0.8;, score=-504.997 total time=  12.3s\n",
      "[CV 1/5] END colsample_bytree=0.9, learning_rate=0.008, max_depth=8, missing=inf, n_estimators=1200, subsample=0.85;, score=-501.454 total time=  12.2s\n",
      "[CV 5/5] END colsample_bytree=0.9, learning_rate=0.01, max_depth=6, missing=inf, n_estimators=800, subsample=0.85;, score=-506.692 total time=   4.0s\n",
      "[CV 1/5] END colsample_bytree=0.9, learning_rate=0.01, max_depth=6, missing=inf, n_estimators=1000, subsample=0.8;, score=-504.731 total time=   5.1s\n",
      "[CV 2/5] END colsample_bytree=0.9, learning_rate=0.01, max_depth=6, missing=inf, n_estimators=1000, subsample=0.8;, score=-506.520 total time=   5.1s\n",
      "[CV 1/5] END colsample_bytree=0.9, learning_rate=0.01, max_depth=6, missing=inf, n_estimators=1000, subsample=0.85;, score=-504.934 total time=   4.5s\n",
      "[CV 3/5] END colsample_bytree=0.9, learning_rate=0.01, max_depth=6, missing=inf, n_estimators=1000, subsample=0.85;, score=-511.042 total time=   4.5s\n",
      "[CV 4/5] END colsample_bytree=0.9, learning_rate=0.01, max_depth=6, missing=inf, n_estimators=1000, subsample=0.85;, score=-557.777 total time=   4.4s\n",
      "[CV 3/5] END colsample_bytree=0.9, learning_rate=0.01, max_depth=6, missing=inf, n_estimators=1000, subsample=0.8;, score=-510.995 total time=   5.3s\n",
      "[CV 5/5] END colsample_bytree=0.9, learning_rate=0.01, max_depth=6, missing=inf, n_estimators=1000, subsample=0.8;, score=-504.975 total time=   5.2s\n",
      "[CV 2/5] END colsample_bytree=0.9, learning_rate=0.008, max_depth=8, missing=inf, n_estimators=1200, subsample=0.85;, score=-510.053 total time=  14.5s\n",
      "[CV 2/5] END colsample_bytree=0.9, learning_rate=0.01, max_depth=6, missing=inf, n_estimators=1000, subsample=0.85;, score=-506.153 total time=   5.2s\n",
      "[CV 4/5] END colsample_bytree=0.9, learning_rate=0.01, max_depth=6, missing=inf, n_estimators=1000, subsample=0.8;, score=-557.151 total time=   5.7s\n",
      "[CV 3/5] END colsample_bytree=0.9, learning_rate=0.01, max_depth=6, missing=inf, n_estimators=1200, subsample=0.8;, score=-509.799 total time=   5.2s\n",
      "[CV 5/5] END colsample_bytree=0.9, learning_rate=0.01, max_depth=6, missing=inf, n_estimators=1000, subsample=0.85;, score=-504.928 total time=   5.9s\n",
      "[CV 2/5] END colsample_bytree=0.9, learning_rate=0.01, max_depth=6, missing=inf, n_estimators=1200, subsample=0.8;, score=-505.330 total time=   6.1s\n",
      "[CV 4/5] END colsample_bytree=0.9, learning_rate=0.01, max_depth=6, missing=inf, n_estimators=1200, subsample=0.8;, score=-556.221 total time=   5.2s\n",
      "[CV 1/5] END colsample_bytree=0.9, learning_rate=0.01, max_depth=6, missing=inf, n_estimators=1200, subsample=0.8;, score=-504.482 total time=   6.8s[CV 5/5] END colsample_bytree=0.9, learning_rate=0.01, max_depth=6, missing=inf, n_estimators=1200, subsample=0.8;, score=-504.227 total time=   5.2s\n",
      "\n",
      "[CV 1/5] END colsample_bytree=0.9, learning_rate=0.01, max_depth=6, missing=inf, n_estimators=1200, subsample=0.85;, score=-504.125 total time=   5.5s\n",
      "[CV 3/5] END colsample_bytree=0.9, learning_rate=0.008, max_depth=8, missing=inf, n_estimators=1200, subsample=0.85;, score=-515.711 total time=  16.4s\n",
      "[CV 5/5] END colsample_bytree=0.9, learning_rate=0.008, max_depth=8, missing=inf, n_estimators=1200, subsample=0.85;, score=-505.818 total time=  15.9s\n",
      "[CV 4/5] END colsample_bytree=0.9, learning_rate=0.008, max_depth=8, missing=inf, n_estimators=1200, subsample=0.85;, score=-557.457 total time=  16.3s\n",
      "[CV 4/5] END colsample_bytree=0.9, learning_rate=0.01, max_depth=6, missing=inf, n_estimators=1200, subsample=0.85;, score=-556.327 total time=   5.2s\n",
      "[CV 2/5] END colsample_bytree=0.9, learning_rate=0.01, max_depth=6, missing=inf, n_estimators=1200, subsample=0.85;, score=-505.062 total time=   5.9s\n",
      "[CV 5/5] END colsample_bytree=0.9, learning_rate=0.01, max_depth=6, missing=inf, n_estimators=1200, subsample=0.85;, score=-504.015 total time=   5.3s\n",
      "[CV 3/5] END colsample_bytree=0.9, learning_rate=0.01, max_depth=6, missing=inf, n_estimators=1200, subsample=0.85;, score=-510.574 total time=   5.9s\n",
      "[CV 1/5] END colsample_bytree=0.9, learning_rate=0.01, max_depth=7, missing=inf, n_estimators=800, subsample=0.8;, score=-502.899 total time=   5.4s\n",
      "[CV 2/5] END colsample_bytree=0.9, learning_rate=0.01, max_depth=7, missing=inf, n_estimators=800, subsample=0.8;, score=-506.285 total time=   6.1s\n",
      "[CV 3/5] END colsample_bytree=0.9, learning_rate=0.01, max_depth=7, missing=inf, n_estimators=800, subsample=0.8;, score=-512.374 total time=   6.1s\n",
      "[CV 5/5] END colsample_bytree=0.9, learning_rate=0.01, max_depth=7, missing=inf, n_estimators=800, subsample=0.8;, score=-503.099 total time=   6.0s\n",
      "[CV 4/5] END colsample_bytree=0.9, learning_rate=0.01, max_depth=7, missing=inf, n_estimators=800, subsample=0.8;, score=-558.218 total time=   6.2s\n",
      "[CV 2/5] END colsample_bytree=0.9, learning_rate=0.01, max_depth=7, missing=inf, n_estimators=800, subsample=0.85;, score=-506.343 total time=   5.4s\n",
      "[CV 1/5] END colsample_bytree=0.9, learning_rate=0.01, max_depth=7, missing=inf, n_estimators=800, subsample=0.85;, score=-504.616 total time=   7.0s\n",
      "[CV 5/5] END colsample_bytree=0.9, learning_rate=0.01, max_depth=7, missing=inf, n_estimators=800, subsample=0.85;, score=-505.084 total time=   5.4s\n",
      "[CV 4/5] END colsample_bytree=0.9, learning_rate=0.01, max_depth=7, missing=inf, n_estimators=800, subsample=0.85;, score=-558.348 total time=   6.0s\n",
      "[CV 3/5] END colsample_bytree=0.9, learning_rate=0.01, max_depth=7, missing=inf, n_estimators=800, subsample=0.85;, score=-513.103 total time=   7.0s\n",
      "[CV 1/5] END colsample_bytree=0.9, learning_rate=0.01, max_depth=7, missing=inf, n_estimators=1000, subsample=0.8;, score=-501.835 total time=   6.5s\n",
      "[CV 3/5] END colsample_bytree=0.9, learning_rate=0.01, max_depth=7, missing=inf, n_estimators=1000, subsample=0.8;, score=-511.031 total time=   7.0s\n",
      "[CV 2/5] END colsample_bytree=0.9, learning_rate=0.01, max_depth=7, missing=inf, n_estimators=1000, subsample=0.8;, score=-504.825 total time=   8.7s\n",
      "[CV 2/5] END colsample_bytree=0.9, learning_rate=0.01, max_depth=7, missing=inf, n_estimators=1000, subsample=0.85;, score=-505.625 total time=   6.9s\n",
      "[CV 4/5] END colsample_bytree=0.9, learning_rate=0.01, max_depth=7, missing=inf, n_estimators=1000, subsample=0.85;, score=-556.910 total time=   6.7s\n",
      "[CV 4/5] END colsample_bytree=0.9, learning_rate=0.01, max_depth=7, missing=inf, n_estimators=1000, subsample=0.8;, score=-556.331 total time=   8.7s\n",
      "[CV 3/5] END colsample_bytree=0.9, learning_rate=0.01, max_depth=7, missing=inf, n_estimators=1000, subsample=0.85;, score=-511.557 total time=   7.7s\n",
      "[CV 5/5] END colsample_bytree=0.9, learning_rate=0.01, max_depth=7, missing=inf, n_estimators=1000, subsample=0.85;, score=-504.186 total time=   7.7s\n",
      "[CV 1/5] END colsample_bytree=0.9, learning_rate=0.01, max_depth=7, missing=inf, n_estimators=1000, subsample=0.85;, score=-503.770 total time=   8.7s\n",
      "[CV 5/5] END colsample_bytree=0.9, learning_rate=0.01, max_depth=7, missing=inf, n_estimators=1000, subsample=0.8;, score=-502.459 total time=   8.8s\n",
      "[CV 1/5] END colsample_bytree=0.9, learning_rate=0.01, max_depth=7, missing=inf, n_estimators=1200, subsample=0.8;, score=-502.377 total time=   8.3s\n",
      "[CV 1/5] END colsample_bytree=0.9, learning_rate=0.01, max_depth=7, missing=inf, n_estimators=1200, subsample=0.85;, score=-503.442 total time=   8.0s\n",
      "[CV 2/5] END colsample_bytree=0.9, learning_rate=0.01, max_depth=7, missing=inf, n_estimators=1200, subsample=0.8;, score=-504.122 total time=   9.1s\n",
      "[CV 3/5] END colsample_bytree=0.9, learning_rate=0.01, max_depth=7, missing=inf, n_estimators=1200, subsample=0.8;, score=-511.046 total time=   9.2s\n",
      "[CV 5/5] END colsample_bytree=0.9, learning_rate=0.01, max_depth=7, missing=inf, n_estimators=1200, subsample=0.8;, score=-501.734 total time=   9.1s\n",
      "[CV 4/5] END colsample_bytree=0.9, learning_rate=0.01, max_depth=7, missing=inf, n_estimators=1200, subsample=0.8;, score=-555.656 total time=   9.2s\n",
      "[CV 3/5] END colsample_bytree=0.9, learning_rate=0.01, max_depth=7, missing=inf, n_estimators=1200, subsample=0.85;, score=-510.839 total time=   8.1s\n",
      "[CV 4/5] END colsample_bytree=0.9, learning_rate=0.01, max_depth=7, missing=inf, n_estimators=1200, subsample=0.85;, score=-556.264 total time=   9.5s\n",
      "[CV 2/5] END colsample_bytree=0.9, learning_rate=0.01, max_depth=7, missing=inf, n_estimators=1200, subsample=0.85;, score=-505.139 total time=  10.3s\n",
      "[CV 1/5] END colsample_bytree=0.9, learning_rate=0.01, max_depth=8, missing=inf, n_estimators=800, subsample=0.8;, score=-503.245 total time=   8.9s\n",
      "[CV 5/5] END colsample_bytree=0.9, learning_rate=0.01, max_depth=7, missing=inf, n_estimators=1200, subsample=0.85;, score=-503.806 total time=  10.6s\n",
      "[CV 2/5] END colsample_bytree=0.9, learning_rate=0.01, max_depth=8, missing=inf, n_estimators=800, subsample=0.8;, score=-509.306 total time=   9.4s\n",
      "[CV 4/5] END colsample_bytree=0.9, learning_rate=0.01, max_depth=8, missing=inf, n_estimators=800, subsample=0.8;, score=-556.735 total time=   8.9s\n",
      "[CV 5/5] END colsample_bytree=0.9, learning_rate=0.01, max_depth=8, missing=inf, n_estimators=800, subsample=0.8;, score=-505.402 total time=   9.2s\n",
      "[CV 2/5] END colsample_bytree=0.9, learning_rate=0.01, max_depth=8, missing=inf, n_estimators=800, subsample=0.85;, score=-509.587 total time=  10.7s\n",
      "[CV 3/5] END colsample_bytree=0.9, learning_rate=0.01, max_depth=8, missing=inf, n_estimators=800, subsample=0.8;, score=-514.776 total time=  12.4s\n",
      "[CV 3/5] END colsample_bytree=0.9, learning_rate=0.01, max_depth=8, missing=inf, n_estimators=800, subsample=0.85;, score=-516.681 total time=  10.8s\n",
      "[CV 1/5] END colsample_bytree=0.9, learning_rate=0.01, max_depth=8, missing=inf, n_estimators=1000, subsample=0.8;, score=-503.096 total time=  10.8s\n",
      "[CV 1/5] END colsample_bytree=0.9, learning_rate=0.01, max_depth=8, missing=inf, n_estimators=800, subsample=0.85;, score=-503.130 total time=  12.6s\n",
      "[CV 2/5] END colsample_bytree=0.9, learning_rate=0.01, max_depth=8, missing=inf, n_estimators=1000, subsample=0.8;, score=-509.361 total time=  10.7s\n",
      "[CV 4/5] END colsample_bytree=0.9, learning_rate=0.01, max_depth=8, missing=inf, n_estimators=800, subsample=0.85;, score=-559.425 total time=  12.3s\n",
      "[CV 5/5] END colsample_bytree=0.9, learning_rate=0.01, max_depth=8, missing=inf, n_estimators=800, subsample=0.85;, score=-507.412 total time=  12.4s\n",
      "[CV 2/5] END colsample_bytree=0.9, learning_rate=0.01, max_depth=8, missing=inf, n_estimators=1000, subsample=0.85;, score=-509.052 total time=  11.0s\n",
      "[CV 3/5] END colsample_bytree=0.9, learning_rate=0.01, max_depth=8, missing=inf, n_estimators=1000, subsample=0.8;, score=-513.992 total time=  12.8s\n",
      "[CV 4/5] END colsample_bytree=0.9, learning_rate=0.01, max_depth=8, missing=inf, n_estimators=1000, subsample=0.8;, score=-555.995 total time=  12.6s\n",
      "[CV 4/5] END colsample_bytree=0.9, learning_rate=0.01, max_depth=8, missing=inf, n_estimators=1000, subsample=0.85;, score=-558.857 total time=  10.4s\n",
      "[CV 5/5] END colsample_bytree=0.9, learning_rate=0.01, max_depth=8, missing=inf, n_estimators=1000, subsample=0.8;, score=-504.789 total time=  13.0s\n",
      "[CV 1/5] END colsample_bytree=0.9, learning_rate=0.01, max_depth=8, missing=inf, n_estimators=1000, subsample=0.85;, score=-503.104 total time=  13.3s\n",
      "[CV 3/5] END colsample_bytree=0.9, learning_rate=0.01, max_depth=8, missing=inf, n_estimators=1000, subsample=0.85;, score=-516.413 total time=  13.1s\n",
      "[CV 1/5] END colsample_bytree=0.9, learning_rate=0.012, max_depth=6, missing=inf, n_estimators=800, subsample=0.8;, score=-505.871 total time=   4.9s\n",
      "[CV 3/5] END colsample_bytree=0.9, learning_rate=0.012, max_depth=6, missing=inf, n_estimators=800, subsample=0.8;, score=-512.138 total time=   3.8s[CV 2/5] END colsample_bytree=0.9, learning_rate=0.012, max_depth=6, missing=inf, n_estimators=800, subsample=0.8;, score=-506.893 total time=   4.8s\n",
      "\n",
      "[CV 1/5] END colsample_bytree=0.9, learning_rate=0.012, max_depth=6, missing=inf, n_estimators=800, subsample=0.85;, score=-505.318 total time=   3.9s\n",
      "[CV 2/5] END colsample_bytree=0.9, learning_rate=0.01, max_depth=8, missing=inf, n_estimators=1200, subsample=0.8;, score=-509.321 total time=  12.9s\n",
      "[CV 5/5] END colsample_bytree=0.9, learning_rate=0.012, max_depth=6, missing=inf, n_estimators=800, subsample=0.8;, score=-503.373 total time=   4.4s\n",
      "[CV 4/5] END colsample_bytree=0.9, learning_rate=0.012, max_depth=6, missing=inf, n_estimators=800, subsample=0.8;, score=-558.757 total time=   4.6s\n",
      "[CV 3/5] END colsample_bytree=0.9, learning_rate=0.01, max_depth=8, missing=inf, n_estimators=1200, subsample=0.8;, score=-514.079 total time=  12.1s\n",
      "[CV 5/5] END colsample_bytree=0.9, learning_rate=0.01, max_depth=8, missing=inf, n_estimators=1000, subsample=0.85;, score=-506.355 total time=  14.8s\n",
      "[CV 2/5] END colsample_bytree=0.9, learning_rate=0.012, max_depth=6, missing=inf, n_estimators=800, subsample=0.85;, score=-505.968 total time=   4.5s\n",
      "[CV 4/5] END colsample_bytree=0.9, learning_rate=0.01, max_depth=8, missing=inf, n_estimators=1200, subsample=0.8;, score=-555.506 total time=  12.2s\n",
      "[CV 3/5] END colsample_bytree=0.9, learning_rate=0.012, max_depth=6, missing=inf, n_estimators=800, subsample=0.85;, score=-511.554 total time=   4.5s\n",
      "[CV 2/5] END colsample_bytree=0.9, learning_rate=0.012, max_depth=6, missing=inf, n_estimators=1000, subsample=0.8;, score=-505.114 total time=   4.4s\n",
      "[CV 5/5] END colsample_bytree=0.9, learning_rate=0.012, max_depth=6, missing=inf, n_estimators=800, subsample=0.85;, score=-504.870 total time=   4.7s\n",
      "[CV 4/5] END colsample_bytree=0.9, learning_rate=0.012, max_depth=6, missing=inf, n_estimators=800, subsample=0.85;, score=-559.335 total time=   4.8s\n",
      "[CV 1/5] END colsample_bytree=0.9, learning_rate=0.01, max_depth=8, missing=inf, n_estimators=1200, subsample=0.8;, score=-503.512 total time=  16.9s\n",
      "[CV 3/5] END colsample_bytree=0.9, learning_rate=0.01, max_depth=8, missing=inf, n_estimators=1200, subsample=0.85;, score=-516.273 total time=  11.9s\n",
      "[CV 1/5] END colsample_bytree=0.9, learning_rate=0.012, max_depth=6, missing=inf, n_estimators=1000, subsample=0.8;, score=-505.561 total time=   5.8s\n",
      "[CV 3/5] END colsample_bytree=0.9, learning_rate=0.012, max_depth=6, missing=inf, n_estimators=1000, subsample=0.8;, score=-510.392 total time=   4.7s\n",
      "[CV 1/5] END colsample_bytree=0.9, learning_rate=0.012, max_depth=6, missing=inf, n_estimators=1000, subsample=0.85;, score=-504.775 total time=   4.5s\n",
      "[CV 5/5] END colsample_bytree=0.9, learning_rate=0.01, max_depth=8, missing=inf, n_estimators=1200, subsample=0.85;, score=-506.083 total time=  11.9s\n",
      "[CV 5/5] END colsample_bytree=0.9, learning_rate=0.012, max_depth=6, missing=inf, n_estimators=1000, subsample=0.8;, score=-502.930 total time=   4.6s\n",
      "[CV 5/5] END colsample_bytree=0.9, learning_rate=0.012, max_depth=6, missing=inf, n_estimators=1000, subsample=0.85;, score=-504.018 total time=   4.5s\n",
      "[CV 5/5] END colsample_bytree=0.9, learning_rate=0.01, max_depth=8, missing=inf, n_estimators=1200, subsample=0.8;, score=-503.920 total time=  14.3s\n",
      "[CV 2/5] END colsample_bytree=0.9, learning_rate=0.01, max_depth=8, missing=inf, n_estimators=1200, subsample=0.85;, score=-509.494 total time=  14.5s\n",
      "[CV 2/5] END colsample_bytree=0.9, learning_rate=0.012, max_depth=6, missing=inf, n_estimators=1000, subsample=0.85;, score=-504.539 total time=   5.8s\n",
      "[CV 4/5] END colsample_bytree=0.9, learning_rate=0.012, max_depth=6, missing=inf, n_estimators=1000, subsample=0.8;, score=-556.860 total time=   5.9s\n",
      "[CV 3/5] END colsample_bytree=0.9, learning_rate=0.012, max_depth=6, missing=inf, n_estimators=1000, subsample=0.85;, score=-510.015 total time=   5.7s\n",
      "[CV 4/5] END colsample_bytree=0.9, learning_rate=0.012, max_depth=6, missing=inf, n_estimators=1000, subsample=0.85;, score=-557.593 total time=   6.0s\n",
      "[CV 1/5] END colsample_bytree=0.9, learning_rate=0.01, max_depth=8, missing=inf, n_estimators=1200, subsample=0.85;, score=-503.295 total time=  16.5s\n",
      "[CV 1/5] END colsample_bytree=0.9, learning_rate=0.012, max_depth=6, missing=inf, n_estimators=1200, subsample=0.8;, score=-506.347 total time=   6.6s\n",
      "[CV 2/5] END colsample_bytree=0.9, learning_rate=0.012, max_depth=6, missing=inf, n_estimators=1200, subsample=0.8;, score=-504.577 total time=   5.1s\n",
      "[CV 4/5] END colsample_bytree=0.9, learning_rate=0.01, max_depth=8, missing=inf, n_estimators=1200, subsample=0.85;, score=-558.718 total time=  16.1s\n",
      "[CV 1/5] END colsample_bytree=0.9, learning_rate=0.012, max_depth=6, missing=inf, n_estimators=1200, subsample=0.85;, score=-504.054 total time=   5.3s\n",
      "[CV 4/5] END colsample_bytree=0.9, learning_rate=0.012, max_depth=6, missing=inf, n_estimators=1200, subsample=0.8;, score=-555.796 total time=   6.4s\n",
      "[CV 3/5] END colsample_bytree=0.9, learning_rate=0.012, max_depth=6, missing=inf, n_estimators=1200, subsample=0.8;, score=-509.502 total time=   6.5s\n",
      "[CV 3/5] END colsample_bytree=0.9, learning_rate=0.012, max_depth=6, missing=inf, n_estimators=1200, subsample=0.85;, score=-509.740 total time=   5.2s\n",
      "[CV 4/5] END colsample_bytree=0.9, learning_rate=0.012, max_depth=6, missing=inf, n_estimators=1200, subsample=0.85;, score=-556.745 total time=   5.2s\n",
      "[CV 5/5] END colsample_bytree=0.9, learning_rate=0.012, max_depth=6, missing=inf, n_estimators=1200, subsample=0.85;, score=-503.509 total time=   5.4s\n",
      "[CV 5/5] END colsample_bytree=0.9, learning_rate=0.012, max_depth=6, missing=inf, n_estimators=1200, subsample=0.8;, score=-502.260 total time=   6.5s\n",
      "[CV 1/5] END colsample_bytree=0.9, learning_rate=0.012, max_depth=7, missing=inf, n_estimators=800, subsample=0.8;, score=-500.896 total time=   5.4s\n",
      "[CV 2/5] END colsample_bytree=0.9, learning_rate=0.012, max_depth=6, missing=inf, n_estimators=1200, subsample=0.85;, score=-504.807 total time=   6.4s\n",
      "[CV 2/5] END colsample_bytree=0.9, learning_rate=0.012, max_depth=7, missing=inf, n_estimators=800, subsample=0.8;, score=-506.726 total time=   5.5s\n",
      "[CV 3/5] END colsample_bytree=0.9, learning_rate=0.012, max_depth=7, missing=inf, n_estimators=800, subsample=0.8;, score=-512.018 total time=   6.3s\n",
      "[CV 5/5] END colsample_bytree=0.9, learning_rate=0.012, max_depth=7, missing=inf, n_estimators=800, subsample=0.8;, score=-502.526 total time=   6.0s\n",
      "[CV 4/5] END colsample_bytree=0.9, learning_rate=0.012, max_depth=7, missing=inf, n_estimators=800, subsample=0.8;, score=-557.072 total time=   6.5s\n",
      "[CV 1/5] END colsample_bytree=0.9, learning_rate=0.012, max_depth=7, missing=inf, n_estimators=800, subsample=0.85;, score=-501.211 total time=   6.3s\n",
      "[CV 2/5] END colsample_bytree=0.9, learning_rate=0.012, max_depth=7, missing=inf, n_estimators=800, subsample=0.85;, score=-506.191 total time=   6.9s\n",
      "[CV 3/5] END colsample_bytree=0.9, learning_rate=0.012, max_depth=7, missing=inf, n_estimators=800, subsample=0.85;, score=-513.598 total time=   6.3s\n",
      "[CV 5/5] END colsample_bytree=0.9, learning_rate=0.012, max_depth=7, missing=inf, n_estimators=800, subsample=0.85;, score=-504.052 total time=   6.5s\n",
      "[CV 1/5] END colsample_bytree=0.9, learning_rate=0.012, max_depth=7, missing=inf, n_estimators=1000, subsample=0.8;, score=-501.071 total time=   6.5s\n",
      "[CV 4/5] END colsample_bytree=0.9, learning_rate=0.012, max_depth=7, missing=inf, n_estimators=800, subsample=0.85;, score=-557.712 total time=   6.9s\n",
      "[CV 3/5] END colsample_bytree=0.9, learning_rate=0.012, max_depth=7, missing=inf, n_estimators=1000, subsample=0.8;, score=-511.123 total time=   6.5s\n",
      "[CV 1/5] END colsample_bytree=0.9, learning_rate=0.012, max_depth=7, missing=inf, n_estimators=1000, subsample=0.85;, score=-501.214 total time=   6.6s\n",
      "[CV 2/5] END colsample_bytree=0.9, learning_rate=0.012, max_depth=7, missing=inf, n_estimators=1000, subsample=0.85;, score=-506.465 total time=   6.6s\n",
      "[CV 3/5] END colsample_bytree=0.9, learning_rate=0.012, max_depth=7, missing=inf, n_estimators=1000, subsample=0.85;, score=-512.799 total time=   6.8s\n",
      "[CV 5/5] END colsample_bytree=0.9, learning_rate=0.012, max_depth=7, missing=inf, n_estimators=1000, subsample=0.8;, score=-501.962 total time=   7.6s\n",
      "[CV 5/5] END colsample_bytree=0.9, learning_rate=0.012, max_depth=7, missing=inf, n_estimators=1000, subsample=0.85;, score=-503.440 total time=   6.9s\n",
      "[CV 2/5] END colsample_bytree=0.9, learning_rate=0.012, max_depth=7, missing=inf, n_estimators=1000, subsample=0.8;, score=-506.575 total time=   8.5s\n",
      "[CV 4/5] END colsample_bytree=0.9, learning_rate=0.012, max_depth=7, missing=inf, n_estimators=1000, subsample=0.8;, score=-555.607 total time=   8.6s\n",
      "[CV 2/5] END colsample_bytree=0.9, learning_rate=0.012, max_depth=7, missing=inf, n_estimators=1200, subsample=0.8;, score=-506.247 total time=   7.7s\n",
      "[CV 4/5] END colsample_bytree=0.9, learning_rate=0.012, max_depth=7, missing=inf, n_estimators=1000, subsample=0.85;, score=-556.761 total time=   8.8s\n",
      "[CV 3/5] END colsample_bytree=0.9, learning_rate=0.012, max_depth=7, missing=inf, n_estimators=1200, subsample=0.8;, score=-510.754 total time=   8.8s\n",
      "[CV 1/5] END colsample_bytree=0.9, learning_rate=0.012, max_depth=7, missing=inf, n_estimators=1200, subsample=0.8;, score=-502.134 total time=  10.0s\n",
      "[CV 4/5] END colsample_bytree=0.9, learning_rate=0.012, max_depth=7, missing=inf, n_estimators=1200, subsample=0.8;, score=-555.132 total time=   8.9s\n",
      "[CV 1/5] END colsample_bytree=0.9, learning_rate=0.012, max_depth=7, missing=inf, n_estimators=1200, subsample=0.85;, score=-501.176 total time=   8.9s\n",
      "[CV 5/5] END colsample_bytree=0.9, learning_rate=0.012, max_depth=7, missing=inf, n_estimators=1200, subsample=0.8;, score=-501.088 total time=   8.9s\n",
      "[CV 3/5] END colsample_bytree=0.9, learning_rate=0.012, max_depth=7, missing=inf, n_estimators=1200, subsample=0.85;, score=-513.374 total time=   9.1s\n",
      "[CV 5/5] END colsample_bytree=0.9, learning_rate=0.012, max_depth=7, missing=inf, n_estimators=1200, subsample=0.85;, score=-503.025 total time=   8.6s\n",
      "[CV 2/5] END colsample_bytree=0.9, learning_rate=0.012, max_depth=7, missing=inf, n_estimators=1200, subsample=0.85;, score=-506.783 total time=  10.2s\n",
      "[CV 4/5] END colsample_bytree=0.9, learning_rate=0.012, max_depth=7, missing=inf, n_estimators=1200, subsample=0.85;, score=-556.794 total time=   9.1s\n",
      "[CV 2/5] END colsample_bytree=0.9, learning_rate=0.012, max_depth=8, missing=inf, n_estimators=800, subsample=0.8;, score=-509.413 total time=   8.8s\n",
      "[CV 3/5] END colsample_bytree=0.9, learning_rate=0.012, max_depth=8, missing=inf, n_estimators=800, subsample=0.8;, score=-515.671 total time=   8.6s\n",
      "[CV 4/5] END colsample_bytree=0.9, learning_rate=0.012, max_depth=8, missing=inf, n_estimators=800, subsample=0.8;, score=-558.685 total time=   8.6s\n",
      "[CV 5/5] END colsample_bytree=0.9, learning_rate=0.012, max_depth=8, missing=inf, n_estimators=800, subsample=0.8;, score=-501.812 total time=   8.7s\n",
      "[CV 1/5] END colsample_bytree=0.9, learning_rate=0.012, max_depth=8, missing=inf, n_estimators=800, subsample=0.8;, score=-502.501 total time=  11.6s\n",
      "[CV 1/5] END colsample_bytree=0.9, learning_rate=0.012, max_depth=8, missing=inf, n_estimators=800, subsample=0.85;, score=-502.755 total time=   9.7s\n",
      "[CV 2/5] END colsample_bytree=0.9, learning_rate=0.012, max_depth=8, missing=inf, n_estimators=800, subsample=0.85;, score=-510.087 total time=   9.5s\n",
      "[CV 5/5] END colsample_bytree=0.9, learning_rate=0.012, max_depth=8, missing=inf, n_estimators=800, subsample=0.85;, score=-505.157 total time=   9.3s\n",
      "[CV 3/5] END colsample_bytree=0.9, learning_rate=0.012, max_depth=8, missing=inf, n_estimators=800, subsample=0.85;, score=-516.670 total time=  11.9s\n",
      "[CV 4/5] END colsample_bytree=0.9, learning_rate=0.012, max_depth=8, missing=inf, n_estimators=800, subsample=0.85;, score=-558.269 total time=  11.9s\n",
      "[CV 2/5] END colsample_bytree=0.9, learning_rate=0.012, max_depth=8, missing=inf, n_estimators=1000, subsample=0.8;, score=-509.849 total time=  11.8s\n",
      "[CV 4/5] END colsample_bytree=0.9, learning_rate=0.012, max_depth=8, missing=inf, n_estimators=1000, subsample=0.8;, score=-557.585 total time=  11.6s\n",
      "[CV 1/5] END colsample_bytree=0.9, learning_rate=0.012, max_depth=8, missing=inf, n_estimators=1000, subsample=0.85;, score=-503.118 total time=  11.6s\n",
      "[CV 5/5] END colsample_bytree=0.9, learning_rate=0.012, max_depth=8, missing=inf, n_estimators=1000, subsample=0.8;, score=-501.702 total time=  11.7s\n",
      "[CV 1/5] END colsample_bytree=0.9, learning_rate=0.012, max_depth=8, missing=inf, n_estimators=1000, subsample=0.8;, score=-502.313 total time=  14.2s\n",
      "[CV 2/5] END colsample_bytree=0.9, learning_rate=0.012, max_depth=8, missing=inf, n_estimators=1000, subsample=0.85;, score=-509.932 total time=  11.6s\n",
      "[CV 3/5] END colsample_bytree=0.9, learning_rate=0.012, max_depth=8, missing=inf, n_estimators=1000, subsample=0.8;, score=-515.850 total time=  13.6s\n",
      "[CV 3/5] END colsample_bytree=0.9, learning_rate=0.012, max_depth=8, missing=inf, n_estimators=1000, subsample=0.85;, score=-516.350 total time=  11.2s\n",
      "[CV 5/5] END colsample_bytree=0.9, learning_rate=0.012, max_depth=8, missing=inf, n_estimators=1000, subsample=0.85;, score=-504.099 total time=  11.6s\n",
      "[CV 1/5] END colsample_bytree=0.95, learning_rate=0.008, max_depth=6, missing=inf, n_estimators=800, subsample=0.8;, score=-508.823 total time=   4.3s\n",
      "[CV 4/5] END colsample_bytree=0.9, learning_rate=0.012, max_depth=8, missing=inf, n_estimators=1000, subsample=0.85;, score=-557.113 total time=  13.6s\n",
      "[CV 2/5] END colsample_bytree=0.95, learning_rate=0.008, max_depth=6, missing=inf, n_estimators=800, subsample=0.8;, score=-512.160 total time=   4.2s\n",
      "[CV 3/5] END colsample_bytree=0.95, learning_rate=0.008, max_depth=6, missing=inf, n_estimators=800, subsample=0.8;, score=-516.837 total time=   4.2s\n",
      "[CV 4/5] END colsample_bytree=0.95, learning_rate=0.008, max_depth=6, missing=inf, n_estimators=800, subsample=0.8;, score=-565.648 total time=   4.2s\n",
      "[CV 1/5] END colsample_bytree=0.9, learning_rate=0.012, max_depth=8, missing=inf, n_estimators=1200, subsample=0.8;, score=-502.542 total time=  12.9s\n",
      "[CV 2/5] END colsample_bytree=0.9, learning_rate=0.012, max_depth=8, missing=inf, n_estimators=1200, subsample=0.8;, score=-509.905 total time=  12.5s\n",
      "[CV 3/5] END colsample_bytree=0.9, learning_rate=0.012, max_depth=8, missing=inf, n_estimators=1200, subsample=0.8;, score=-516.352 total time=  12.4s\n",
      "[CV 1/5] END colsample_bytree=0.95, learning_rate=0.008, max_depth=6, missing=inf, n_estimators=800, subsample=0.85;, score=-508.978 total time=   4.3s\n",
      "[CV 4/5] END colsample_bytree=0.9, learning_rate=0.012, max_depth=8, missing=inf, n_estimators=1200, subsample=0.8;, score=-557.702 total time=  12.3s\n",
      "[CV 2/5] END colsample_bytree=0.95, learning_rate=0.008, max_depth=6, missing=inf, n_estimators=800, subsample=0.85;, score=-512.080 total time=   4.0s\n",
      "[CV 5/5] END colsample_bytree=0.95, learning_rate=0.008, max_depth=6, missing=inf, n_estimators=800, subsample=0.8;, score=-509.414 total time=   5.0s\n",
      "[CV 3/5] END colsample_bytree=0.95, learning_rate=0.008, max_depth=6, missing=inf, n_estimators=800, subsample=0.85;, score=-516.648 total time=   4.7s\n",
      "[CV 4/5] END colsample_bytree=0.95, learning_rate=0.008, max_depth=6, missing=inf, n_estimators=800, subsample=0.85;, score=-564.539 total time=   4.2s\n",
      "[CV 2/5] END colsample_bytree=0.9, learning_rate=0.012, max_depth=8, missing=inf, n_estimators=1200, subsample=0.85;, score=-510.109 total time=  12.8s\n",
      "[CV 1/5] END colsample_bytree=0.9, learning_rate=0.012, max_depth=8, missing=inf, n_estimators=1200, subsample=0.85;, score=-503.881 total time=  12.9s\n",
      "[CV 3/5] END colsample_bytree=0.9, learning_rate=0.012, max_depth=8, missing=inf, n_estimators=1200, subsample=0.85;, score=-516.533 total time=  12.3s\n",
      "[CV 5/5] END colsample_bytree=0.95, learning_rate=0.008, max_depth=6, missing=inf, n_estimators=800, subsample=0.85;, score=-508.577 total time=   4.0s\n",
      "[CV 5/5] END colsample_bytree=0.9, learning_rate=0.012, max_depth=8, missing=inf, n_estimators=1200, subsample=0.8;, score=-501.211 total time=  14.8s\n",
      "[CV 2/5] END colsample_bytree=0.95, learning_rate=0.008, max_depth=6, missing=inf, n_estimators=1000, subsample=0.8;, score=-508.469 total time=   5.0s\n",
      "[CV 5/5] END colsample_bytree=0.95, learning_rate=0.008, max_depth=6, missing=inf, n_estimators=1000, subsample=0.8;, score=-506.520 total time=   4.7s\n",
      "[CV 3/5] END colsample_bytree=0.95, learning_rate=0.008, max_depth=6, missing=inf, n_estimators=1000, subsample=0.8;, score=-512.296 total time=   4.9s\n",
      "[CV 4/5] END colsample_bytree=0.95, learning_rate=0.008, max_depth=6, missing=inf, n_estimators=1000, subsample=0.8;, score=-560.967 total time=   4.9s\n",
      "[CV 1/5] END colsample_bytree=0.95, learning_rate=0.008, max_depth=6, missing=inf, n_estimators=1000, subsample=0.85;, score=-506.064 total time=   4.7s\n",
      "[CV 1/5] END colsample_bytree=0.95, learning_rate=0.008, max_depth=6, missing=inf, n_estimators=1000, subsample=0.8;, score=-506.266 total time=   5.5s\n",
      "[CV 2/5] END colsample_bytree=0.95, learning_rate=0.008, max_depth=6, missing=inf, n_estimators=1000, subsample=0.85;, score=-508.511 total time=   4.8s\n",
      "[CV 3/5] END colsample_bytree=0.95, learning_rate=0.008, max_depth=6, missing=inf, n_estimators=1000, subsample=0.85;, score=-512.547 total time=   4.9s\n",
      "[CV 4/5] END colsample_bytree=0.95, learning_rate=0.008, max_depth=6, missing=inf, n_estimators=1000, subsample=0.85;, score=-560.328 total time=   4.9s\n",
      "[CV 5/5] END colsample_bytree=0.95, learning_rate=0.008, max_depth=6, missing=inf, n_estimators=1000, subsample=0.85;, score=-505.763 total time=   4.8s\n",
      "[CV 4/5] END colsample_bytree=0.9, learning_rate=0.012, max_depth=8, missing=inf, n_estimators=1200, subsample=0.85;, score=-557.191 total time=  14.6s\n",
      "[CV 5/5] END colsample_bytree=0.9, learning_rate=0.012, max_depth=8, missing=inf, n_estimators=1200, subsample=0.85;, score=-503.338 total time=  14.2s\n",
      "[CV 1/5] END colsample_bytree=0.95, learning_rate=0.008, max_depth=6, missing=inf, n_estimators=1200, subsample=0.8;, score=-505.466 total time=   6.4s\n",
      "[CV 3/5] END colsample_bytree=0.95, learning_rate=0.008, max_depth=6, missing=inf, n_estimators=1200, subsample=0.8;, score=-510.710 total time=   5.7s\n",
      "[CV 2/5] END colsample_bytree=0.95, learning_rate=0.008, max_depth=6, missing=inf, n_estimators=1200, subsample=0.8;, score=-506.437 total time=   6.3s\n",
      "[CV 4/5] END colsample_bytree=0.95, learning_rate=0.008, max_depth=6, missing=inf, n_estimators=1200, subsample=0.8;, score=-559.148 total time=   5.6s\n",
      "[CV 5/5] END colsample_bytree=0.95, learning_rate=0.008, max_depth=6, missing=inf, n_estimators=1200, subsample=0.8;, score=-505.231 total time=   5.7s\n",
      "[CV 1/5] END colsample_bytree=0.95, learning_rate=0.008, max_depth=6, missing=inf, n_estimators=1200, subsample=0.85;, score=-504.432 total time=   5.6s\n",
      "[CV 2/5] END colsample_bytree=0.95, learning_rate=0.008, max_depth=6, missing=inf, n_estimators=1200, subsample=0.85;, score=-507.433 total time=   5.6s\n",
      "[CV 3/5] END colsample_bytree=0.95, learning_rate=0.008, max_depth=6, missing=inf, n_estimators=1200, subsample=0.85;, score=-510.756 total time=   6.6s\n",
      "[CV 5/5] END colsample_bytree=0.95, learning_rate=0.008, max_depth=6, missing=inf, n_estimators=1200, subsample=0.85;, score=-504.596 total time=   5.8s\n",
      "[CV 4/5] END colsample_bytree=0.95, learning_rate=0.008, max_depth=6, missing=inf, n_estimators=1200, subsample=0.85;, score=-558.429 total time=   6.1s\n",
      "[CV 2/5] END colsample_bytree=0.95, learning_rate=0.008, max_depth=7, missing=inf, n_estimators=800, subsample=0.8;, score=-509.422 total time=   6.0s\n",
      "[CV 1/5] END colsample_bytree=0.95, learning_rate=0.008, max_depth=7, missing=inf, n_estimators=800, subsample=0.8;, score=-504.013 total time=   6.2s\n",
      "[CV 5/5] END colsample_bytree=0.95, learning_rate=0.008, max_depth=7, missing=inf, n_estimators=800, subsample=0.8;, score=-505.672 total time=   5.9s\n",
      "[CV 3/5] END colsample_bytree=0.95, learning_rate=0.008, max_depth=7, missing=inf, n_estimators=800, subsample=0.8;, score=-512.399 total time=   6.1s\n",
      "[CV 2/5] END colsample_bytree=0.95, learning_rate=0.008, max_depth=7, missing=inf, n_estimators=800, subsample=0.85;, score=-508.985 total time=   6.1s\n",
      "[CV 1/5] END colsample_bytree=0.95, learning_rate=0.008, max_depth=7, missing=inf, n_estimators=800, subsample=0.85;, score=-504.708 total time=   6.2s\n",
      "[CV 3/5] END colsample_bytree=0.95, learning_rate=0.008, max_depth=7, missing=inf, n_estimators=800, subsample=0.85;, score=-514.510 total time=   6.2s\n",
      "[CV 4/5] END colsample_bytree=0.95, learning_rate=0.008, max_depth=7, missing=inf, n_estimators=800, subsample=0.8;, score=-559.540 total time=   7.1s\n",
      "[CV 4/5] END colsample_bytree=0.95, learning_rate=0.008, max_depth=7, missing=inf, n_estimators=800, subsample=0.85;, score=-559.510 total time=   7.2s\n",
      "[CV 5/5] END colsample_bytree=0.95, learning_rate=0.008, max_depth=7, missing=inf, n_estimators=800, subsample=0.85;, score=-506.044 total time=   7.5s\n",
      "[CV 2/5] END colsample_bytree=0.95, learning_rate=0.008, max_depth=7, missing=inf, n_estimators=1000, subsample=0.8;, score=-507.236 total time=   7.6s\n",
      "[CV 4/5] END colsample_bytree=0.95, learning_rate=0.008, max_depth=7, missing=inf, n_estimators=1000, subsample=0.8;, score=-556.323 total time=   7.5s\n",
      "[CV 1/5] END colsample_bytree=0.95, learning_rate=0.008, max_depth=7, missing=inf, n_estimators=1000, subsample=0.85;, score=-502.484 total time=   7.2s\n",
      "[CV 5/5] END colsample_bytree=0.95, learning_rate=0.008, max_depth=7, missing=inf, n_estimators=1000, subsample=0.8;, score=-504.164 total time=   7.5s\n",
      "[CV 1/5] END colsample_bytree=0.95, learning_rate=0.008, max_depth=7, missing=inf, n_estimators=1000, subsample=0.8;, score=-502.251 total time=   8.8s\n",
      "[CV 2/5] END colsample_bytree=0.95, learning_rate=0.008, max_depth=7, missing=inf, n_estimators=1000, subsample=0.85;, score=-507.618 total time=   7.5s\n",
      "[CV 3/5] END colsample_bytree=0.95, learning_rate=0.008, max_depth=7, missing=inf, n_estimators=1000, subsample=0.8;, score=-510.107 total time=   8.7s\n",
      "[CV 4/5] END colsample_bytree=0.95, learning_rate=0.008, max_depth=7, missing=inf, n_estimators=1000, subsample=0.85;, score=-556.934 total time=   7.5s\n",
      "[CV 5/5] END colsample_bytree=0.95, learning_rate=0.008, max_depth=7, missing=inf, n_estimators=1000, subsample=0.85;, score=-504.532 total time=   7.6s\n",
      "[CV 3/5] END colsample_bytree=0.95, learning_rate=0.008, max_depth=7, missing=inf, n_estimators=1000, subsample=0.85;, score=-512.180 total time=   8.8s\n",
      "[CV 3/5] END colsample_bytree=0.95, learning_rate=0.008, max_depth=7, missing=inf, n_estimators=1200, subsample=0.8;, score=-509.512 total time=   8.6s\n",
      "[CV 1/5] END colsample_bytree=0.95, learning_rate=0.008, max_depth=7, missing=inf, n_estimators=1200, subsample=0.8;, score=-501.741 total time=   8.8s\n",
      "[CV 4/5] END colsample_bytree=0.95, learning_rate=0.008, max_depth=7, missing=inf, n_estimators=1200, subsample=0.8;, score=-555.730 total time=   8.6s\n",
      "[CV 2/5] END colsample_bytree=0.95, learning_rate=0.008, max_depth=7, missing=inf, n_estimators=1200, subsample=0.8;, score=-505.730 total time=   8.9s\n",
      "[CV 5/5] END colsample_bytree=0.95, learning_rate=0.008, max_depth=7, missing=inf, n_estimators=1200, subsample=0.8;, score=-503.283 total time=   8.9s\n",
      "[CV 1/5] END colsample_bytree=0.95, learning_rate=0.008, max_depth=7, missing=inf, n_estimators=1200, subsample=0.85;, score=-502.090 total time=   8.9s\n",
      "[CV 2/5] END colsample_bytree=0.95, learning_rate=0.008, max_depth=7, missing=inf, n_estimators=1200, subsample=0.85;, score=-506.474 total time=   9.1s\n",
      "[CV 3/5] END colsample_bytree=0.95, learning_rate=0.008, max_depth=7, missing=inf, n_estimators=1200, subsample=0.85;, score=-511.425 total time=  10.2s\n",
      "[CV 4/5] END colsample_bytree=0.95, learning_rate=0.008, max_depth=7, missing=inf, n_estimators=1200, subsample=0.85;, score=-555.359 total time=  10.6s\n",
      "[CV 5/5] END colsample_bytree=0.95, learning_rate=0.008, max_depth=7, missing=inf, n_estimators=1200, subsample=0.85;, score=-503.928 total time=  10.5s\n",
      "[CV 1/5] END colsample_bytree=0.95, learning_rate=0.008, max_depth=8, missing=inf, n_estimators=800, subsample=0.8;, score=-503.555 total time=  10.4s\n",
      "[CV 2/5] END colsample_bytree=0.95, learning_rate=0.008, max_depth=8, missing=inf, n_estimators=800, subsample=0.8;, score=-509.961 total time=  10.1s\n",
      "[CV 3/5] END colsample_bytree=0.95, learning_rate=0.008, max_depth=8, missing=inf, n_estimators=800, subsample=0.8;, score=-514.749 total time=  10.1s\n",
      "[CV 4/5] END colsample_bytree=0.95, learning_rate=0.008, max_depth=8, missing=inf, n_estimators=800, subsample=0.8;, score=-559.550 total time=  10.6s\n",
      "[CV 1/5] END colsample_bytree=0.95, learning_rate=0.008, max_depth=8, missing=inf, n_estimators=800, subsample=0.85;, score=-503.044 total time=  10.3s\n",
      "[CV 5/5] END colsample_bytree=0.95, learning_rate=0.008, max_depth=8, missing=inf, n_estimators=800, subsample=0.8;, score=-506.592 total time=  12.0s\n",
      "[CV 3/5] END colsample_bytree=0.95, learning_rate=0.008, max_depth=8, missing=inf, n_estimators=800, subsample=0.85;, score=-516.440 total time=  10.3s\n",
      "[CV 4/5] END colsample_bytree=0.95, learning_rate=0.008, max_depth=8, missing=inf, n_estimators=800, subsample=0.85;, score=-560.552 total time=  10.5s\n",
      "[CV 2/5] END colsample_bytree=0.95, learning_rate=0.008, max_depth=8, missing=inf, n_estimators=800, subsample=0.85;, score=-510.070 total time=  12.2s\n",
      "[CV 5/5] END colsample_bytree=0.95, learning_rate=0.008, max_depth=8, missing=inf, n_estimators=800, subsample=0.85;, score=-507.998 total time=  12.2s\n",
      "[CV 3/5] END colsample_bytree=0.95, learning_rate=0.008, max_depth=8, missing=inf, n_estimators=1000, subsample=0.8;, score=-514.161 total time=  11.9s\n",
      "[CV 1/5] END colsample_bytree=0.95, learning_rate=0.008, max_depth=8, missing=inf, n_estimators=1000, subsample=0.8;, score=-502.914 total time=  12.2s[CV 2/5] END colsample_bytree=0.95, learning_rate=0.008, max_depth=8, missing=inf, n_estimators=1000, subsample=0.8;, score=-509.323 total time=  12.1s\n",
      "\n",
      "[CV 4/5] END colsample_bytree=0.95, learning_rate=0.008, max_depth=8, missing=inf, n_estimators=1000, subsample=0.8;, score=-557.939 total time=  12.3s\n",
      "[CV 5/5] END colsample_bytree=0.95, learning_rate=0.008, max_depth=8, missing=inf, n_estimators=1000, subsample=0.8;, score=-505.771 total time=  11.9s\n",
      "[CV 1/5] END colsample_bytree=0.95, learning_rate=0.008, max_depth=8, missing=inf, n_estimators=1000, subsample=0.85;, score=-502.527 total time=  11.9s\n",
      "[CV 2/5] END colsample_bytree=0.95, learning_rate=0.008, max_depth=8, missing=inf, n_estimators=1000, subsample=0.85;, score=-509.067 total time=  12.6s\n",
      "[CV 1/5] END colsample_bytree=0.95, learning_rate=0.01, max_depth=6, missing=inf, n_estimators=800, subsample=0.8;, score=-505.733 total time=   4.1s\n",
      "[CV 2/5] END colsample_bytree=0.95, learning_rate=0.01, max_depth=6, missing=inf, n_estimators=800, subsample=0.8;, score=-508.568 total time=   4.1s\n",
      "[CV 3/5] END colsample_bytree=0.95, learning_rate=0.01, max_depth=6, missing=inf, n_estimators=800, subsample=0.8;, score=-513.036 total time=   4.2s\n",
      "[CV 3/5] END colsample_bytree=0.95, learning_rate=0.008, max_depth=8, missing=inf, n_estimators=1000, subsample=0.85;, score=-515.361 total time=  14.0s\n",
      "[CV 4/5] END colsample_bytree=0.95, learning_rate=0.01, max_depth=6, missing=inf, n_estimators=800, subsample=0.8;, score=-560.438 total time=   4.3s\n",
      "[CV 5/5] END colsample_bytree=0.95, learning_rate=0.01, max_depth=6, missing=inf, n_estimators=800, subsample=0.8;, score=-507.017 total time=   4.3s\n",
      "[CV 1/5] END colsample_bytree=0.95, learning_rate=0.01, max_depth=6, missing=inf, n_estimators=800, subsample=0.85;, score=-506.124 total time=   4.3s\n",
      "[CV 2/5] END colsample_bytree=0.95, learning_rate=0.01, max_depth=6, missing=inf, n_estimators=800, subsample=0.85;, score=-508.548 total time=   4.1s\n",
      "[CV 2/5] END colsample_bytree=0.95, learning_rate=0.008, max_depth=8, missing=inf, n_estimators=1200, subsample=0.8;, score=-509.111 total time=  13.3s\n",
      "[CV 4/5] END colsample_bytree=0.95, learning_rate=0.008, max_depth=8, missing=inf, n_estimators=1000, subsample=0.85;, score=-559.119 total time=  14.6s\n",
      "[CV 5/5] END colsample_bytree=0.95, learning_rate=0.008, max_depth=8, missing=inf, n_estimators=1000, subsample=0.85;, score=-507.097 total time=  14.1s\n",
      "[CV 1/5] END colsample_bytree=0.95, learning_rate=0.008, max_depth=8, missing=inf, n_estimators=1200, subsample=0.8;, score=-503.387 total time=  13.5s\n",
      "[CV 3/5] END colsample_bytree=0.95, learning_rate=0.008, max_depth=8, missing=inf, n_estimators=1200, subsample=0.8;, score=-513.518 total time=  13.8s\n",
      "[CV 3/5] END colsample_bytree=0.95, learning_rate=0.01, max_depth=6, missing=inf, n_estimators=800, subsample=0.85;, score=-512.962 total time=   3.9s\n",
      "[CV 4/5] END colsample_bytree=0.95, learning_rate=0.01, max_depth=6, missing=inf, n_estimators=800, subsample=0.85;, score=-560.976 total time=   4.1s\n",
      "[CV 5/5] END colsample_bytree=0.95, learning_rate=0.01, max_depth=6, missing=inf, n_estimators=800, subsample=0.85;, score=-508.080 total time=   4.0s\n",
      "[CV 4/5] END colsample_bytree=0.95, learning_rate=0.008, max_depth=8, missing=inf, n_estimators=1200, subsample=0.8;, score=-557.550 total time=  13.8s\n",
      "[CV 5/5] END colsample_bytree=0.95, learning_rate=0.008, max_depth=8, missing=inf, n_estimators=1200, subsample=0.8;, score=-505.432 total time=  13.4s\n",
      "[CV 1/5] END colsample_bytree=0.95, learning_rate=0.01, max_depth=6, missing=inf, n_estimators=1000, subsample=0.8;, score=-504.209 total time=   4.9s\n",
      "[CV 4/5] END colsample_bytree=0.95, learning_rate=0.01, max_depth=6, missing=inf, n_estimators=1000, subsample=0.8;, score=-557.465 total time=   4.7s\n",
      "[CV 2/5] END colsample_bytree=0.95, learning_rate=0.008, max_depth=8, missing=inf, n_estimators=1200, subsample=0.85;, score=-508.828 total time=  13.4s\n",
      "[CV 3/5] END colsample_bytree=0.95, learning_rate=0.01, max_depth=6, missing=inf, n_estimators=1000, subsample=0.8;, score=-510.909 total time=   4.8s\n",
      "[CV 2/5] END colsample_bytree=0.95, learning_rate=0.01, max_depth=6, missing=inf, n_estimators=1000, subsample=0.8;, score=-506.204 total time=   5.4s\n",
      "[CV 3/5] END colsample_bytree=0.95, learning_rate=0.008, max_depth=8, missing=inf, n_estimators=1200, subsample=0.85;, score=-514.705 total time=  13.5s\n",
      "[CV 5/5] END colsample_bytree=0.95, learning_rate=0.01, max_depth=6, missing=inf, n_estimators=1000, subsample=0.8;, score=-505.460 total time=   4.6s\n",
      "[CV 1/5] END colsample_bytree=0.95, learning_rate=0.01, max_depth=6, missing=inf, n_estimators=1000, subsample=0.85;, score=-505.251 total time=   4.8s\n",
      "[CV 4/5] END colsample_bytree=0.95, learning_rate=0.01, max_depth=6, missing=inf, n_estimators=1000, subsample=0.85;, score=-557.601 total time=   4.9s\n",
      "[CV 5/5] END colsample_bytree=0.95, learning_rate=0.01, max_depth=6, missing=inf, n_estimators=1000, subsample=0.85;, score=-506.609 total time=   4.7s\n",
      "[CV 1/5] END colsample_bytree=0.95, learning_rate=0.008, max_depth=8, missing=inf, n_estimators=1200, subsample=0.85;, score=-502.549 total time=  15.9s\n",
      "[CV 2/5] END colsample_bytree=0.95, learning_rate=0.01, max_depth=6, missing=inf, n_estimators=1000, subsample=0.85;, score=-507.185 total time=   5.3s\n",
      "[CV 3/5] END colsample_bytree=0.95, learning_rate=0.01, max_depth=6, missing=inf, n_estimators=1000, subsample=0.85;, score=-510.105 total time=   5.3s\n",
      "[CV 4/5] END colsample_bytree=0.95, learning_rate=0.008, max_depth=8, missing=inf, n_estimators=1200, subsample=0.85;, score=-558.351 total time=  16.1s\n",
      "[CV 1/5] END colsample_bytree=0.95, learning_rate=0.01, max_depth=6, missing=inf, n_estimators=1200, subsample=0.8;, score=-504.342 total time=   5.5s\n",
      "[CV 3/5] END colsample_bytree=0.95, learning_rate=0.01, max_depth=6, missing=inf, n_estimators=1200, subsample=0.8;, score=-510.005 total time=   5.5s\n",
      "[CV 2/5] END colsample_bytree=0.95, learning_rate=0.01, max_depth=6, missing=inf, n_estimators=1200, subsample=0.8;, score=-505.308 total time=   5.6s\n",
      "[CV 5/5] END colsample_bytree=0.95, learning_rate=0.01, max_depth=6, missing=inf, n_estimators=1200, subsample=0.8;, score=-504.852 total time=   5.5s\n",
      "[CV 4/5] END colsample_bytree=0.95, learning_rate=0.01, max_depth=6, missing=inf, n_estimators=1200, subsample=0.8;, score=-556.345 total time=   5.7s\n",
      "[CV 1/5] END colsample_bytree=0.95, learning_rate=0.01, max_depth=6, missing=inf, n_estimators=1200, subsample=0.85;, score=-504.904 total time=   5.6s\n",
      "[CV 2/5] END colsample_bytree=0.95, learning_rate=0.01, max_depth=6, missing=inf, n_estimators=1200, subsample=0.85;, score=-505.890 total time=   5.4s\n",
      "[CV 5/5] END colsample_bytree=0.95, learning_rate=0.008, max_depth=8, missing=inf, n_estimators=1200, subsample=0.85;, score=-506.668 total time=  15.8s\n",
      "[CV 4/5] END colsample_bytree=0.95, learning_rate=0.01, max_depth=6, missing=inf, n_estimators=1200, subsample=0.85;, score=-555.859 total time=   5.5s\n",
      "[CV 3/5] END colsample_bytree=0.95, learning_rate=0.01, max_depth=6, missing=inf, n_estimators=1200, subsample=0.85;, score=-509.476 total time=   5.7s\n",
      "[CV 5/5] END colsample_bytree=0.95, learning_rate=0.01, max_depth=6, missing=inf, n_estimators=1200, subsample=0.85;, score=-506.259 total time=   6.2s\n",
      "[CV 2/5] END colsample_bytree=0.95, learning_rate=0.01, max_depth=7, missing=inf, n_estimators=800, subsample=0.8;, score=-506.995 total time=   5.6s\n",
      "[CV 1/5] END colsample_bytree=0.95, learning_rate=0.01, max_depth=7, missing=inf, n_estimators=800, subsample=0.8;, score=-502.377 total time=   6.0s\n",
      "[CV 3/5] END colsample_bytree=0.95, learning_rate=0.01, max_depth=7, missing=inf, n_estimators=800, subsample=0.8;, score=-512.670 total time=   6.0s\n",
      "[CV 5/5] END colsample_bytree=0.95, learning_rate=0.01, max_depth=7, missing=inf, n_estimators=800, subsample=0.8;, score=-503.080 total time=   5.8s\n",
      "[CV 4/5] END colsample_bytree=0.95, learning_rate=0.01, max_depth=7, missing=inf, n_estimators=800, subsample=0.8;, score=-557.409 total time=   6.0s\n",
      "[CV 5/5] END colsample_bytree=0.95, learning_rate=0.01, max_depth=7, missing=inf, n_estimators=800, subsample=0.85;, score=-504.270 total time=   6.1s[CV 1/5] END colsample_bytree=0.95, learning_rate=0.01, max_depth=7, missing=inf, n_estimators=800, subsample=0.85;, score=-503.233 total time=   7.0s\n",
      "\n",
      "[CV 3/5] END colsample_bytree=0.95, learning_rate=0.01, max_depth=7, missing=inf, n_estimators=800, subsample=0.85;, score=-512.846 total time=   7.0s\n",
      "[CV 2/5] END colsample_bytree=0.95, learning_rate=0.01, max_depth=7, missing=inf, n_estimators=800, subsample=0.85;, score=-506.472 total time=   7.0s\n",
      "[CV 4/5] END colsample_bytree=0.95, learning_rate=0.01, max_depth=7, missing=inf, n_estimators=800, subsample=0.85;, score=-557.447 total time=   7.2s\n",
      "[CV 2/5] END colsample_bytree=0.95, learning_rate=0.01, max_depth=7, missing=inf, n_estimators=1000, subsample=0.8;, score=-506.041 total time=   7.0s\n",
      "[CV 3/5] END colsample_bytree=0.95, learning_rate=0.01, max_depth=7, missing=inf, n_estimators=1000, subsample=0.8;, score=-511.525 total time=   7.1s\n",
      "[CV 1/5] END colsample_bytree=0.95, learning_rate=0.01, max_depth=7, missing=inf, n_estimators=1000, subsample=0.8;, score=-501.320 total time=   7.3s\n",
      "[CV 4/5] END colsample_bytree=0.95, learning_rate=0.01, max_depth=7, missing=inf, n_estimators=1000, subsample=0.8;, score=-555.771 total time=   7.3s\n",
      "[CV 1/5] END colsample_bytree=0.95, learning_rate=0.01, max_depth=7, missing=inf, n_estimators=1000, subsample=0.85;, score=-503.004 total time=   7.2s\n",
      "[CV 5/5] END colsample_bytree=0.95, learning_rate=0.01, max_depth=7, missing=inf, n_estimators=1000, subsample=0.8;, score=-502.717 total time=   7.5s\n",
      "[CV 3/5] END colsample_bytree=0.95, learning_rate=0.01, max_depth=7, missing=inf, n_estimators=1000, subsample=0.85;, score=-510.747 total time=   7.5s\n",
      "[CV 4/5] END colsample_bytree=0.95, learning_rate=0.01, max_depth=7, missing=inf, n_estimators=1000, subsample=0.85;, score=-555.986 total time=   7.4s\n",
      "[CV 5/5] END colsample_bytree=0.95, learning_rate=0.01, max_depth=7, missing=inf, n_estimators=1000, subsample=0.85;, score=-503.555 total time=   7.2s\n",
      "[CV 2/5] END colsample_bytree=0.95, learning_rate=0.01, max_depth=7, missing=inf, n_estimators=1000, subsample=0.85;, score=-505.969 total time=   8.8s\n",
      "[CV 2/5] END colsample_bytree=0.95, learning_rate=0.01, max_depth=7, missing=inf, n_estimators=1200, subsample=0.8;, score=-505.663 total time=   8.7s\n",
      "[CV 1/5] END colsample_bytree=0.95, learning_rate=0.01, max_depth=7, missing=inf, n_estimators=1200, subsample=0.8;, score=-501.479 total time=  10.0s\n",
      "[CV 3/5] END colsample_bytree=0.95, learning_rate=0.01, max_depth=7, missing=inf, n_estimators=1200, subsample=0.8;, score=-511.239 total time=   8.7s\n",
      "[CV 4/5] END colsample_bytree=0.95, learning_rate=0.01, max_depth=7, missing=inf, n_estimators=1200, subsample=0.8;, score=-555.371 total time=   8.6s\n",
      "[CV 5/5] END colsample_bytree=0.95, learning_rate=0.01, max_depth=7, missing=inf, n_estimators=1200, subsample=0.8;, score=-501.902 total time=   8.7s\n",
      "[CV 1/5] END colsample_bytree=0.95, learning_rate=0.01, max_depth=7, missing=inf, n_estimators=1200, subsample=0.85;, score=-503.090 total time=   9.0s\n",
      "[CV 3/5] END colsample_bytree=0.95, learning_rate=0.01, max_depth=7, missing=inf, n_estimators=1200, subsample=0.85;, score=-509.938 total time=  10.0s\n",
      "[CV 4/5] END colsample_bytree=0.95, learning_rate=0.01, max_depth=7, missing=inf, n_estimators=1200, subsample=0.85;, score=-555.058 total time=  10.3s\n",
      "[CV 2/5] END colsample_bytree=0.95, learning_rate=0.01, max_depth=7, missing=inf, n_estimators=1200, subsample=0.85;, score=-505.755 total time=  10.4s\n",
      "[CV 1/5] END colsample_bytree=0.95, learning_rate=0.01, max_depth=8, missing=inf, n_estimators=800, subsample=0.8;, score=-502.369 total time=   9.6s\n",
      "[CV 2/5] END colsample_bytree=0.95, learning_rate=0.01, max_depth=8, missing=inf, n_estimators=800, subsample=0.8;, score=-508.773 total time=   9.6s\n",
      "[CV 3/5] END colsample_bytree=0.95, learning_rate=0.01, max_depth=8, missing=inf, n_estimators=800, subsample=0.8;, score=-513.273 total time=   9.6s\n",
      "[CV 4/5] END colsample_bytree=0.95, learning_rate=0.01, max_depth=8, missing=inf, n_estimators=800, subsample=0.8;, score=-557.539 total time=   9.7s\n",
      "[CV 5/5] END colsample_bytree=0.95, learning_rate=0.01, max_depth=7, missing=inf, n_estimators=1200, subsample=0.85;, score=-503.289 total time=  10.6s\n",
      "[CV 5/5] END colsample_bytree=0.95, learning_rate=0.01, max_depth=8, missing=inf, n_estimators=800, subsample=0.8;, score=-506.672 total time=   9.3s\n",
      "[CV 1/5] END colsample_bytree=0.95, learning_rate=0.01, max_depth=8, missing=inf, n_estimators=800, subsample=0.85;, score=-503.081 total time=   9.7s\n",
      "[CV 2/5] END colsample_bytree=0.95, learning_rate=0.01, max_depth=8, missing=inf, n_estimators=800, subsample=0.85;, score=-509.145 total time=   9.5s\n",
      "[CV 3/5] END colsample_bytree=0.95, learning_rate=0.01, max_depth=8, missing=inf, n_estimators=800, subsample=0.85;, score=-516.130 total time=   9.4s\n",
      "[CV 4/5] END colsample_bytree=0.95, learning_rate=0.01, max_depth=8, missing=inf, n_estimators=800, subsample=0.85;, score=-560.595 total time=   9.5s\n",
      "[CV 5/5] END colsample_bytree=0.95, learning_rate=0.01, max_depth=8, missing=inf, n_estimators=800, subsample=0.85;, score=-505.612 total time=  11.8s\n",
      "[CV 1/5] END colsample_bytree=0.95, learning_rate=0.01, max_depth=8, missing=inf, n_estimators=1000, subsample=0.8;, score=-501.998 total time=  12.0s\n",
      "[CV 3/5] END colsample_bytree=0.95, learning_rate=0.01, max_depth=8, missing=inf, n_estimators=1000, subsample=0.8;, score=-512.685 total time=  11.9s\n",
      "[CV 5/5] END colsample_bytree=0.95, learning_rate=0.01, max_depth=8, missing=inf, n_estimators=1000, subsample=0.8;, score=-506.042 total time=  11.6s\n",
      "[CV 4/5] END colsample_bytree=0.95, learning_rate=0.01, max_depth=8, missing=inf, n_estimators=1000, subsample=0.8;, score=-556.575 total time=  11.8s\n",
      "[CV 1/5] END colsample_bytree=0.95, learning_rate=0.01, max_depth=8, missing=inf, n_estimators=1000, subsample=0.85;, score=-502.866 total time=  11.9s\n",
      "[CV 2/5] END colsample_bytree=0.95, learning_rate=0.01, max_depth=8, missing=inf, n_estimators=1000, subsample=0.8;, score=-509.286 total time=  14.2s\n",
      "[CV 1/5] END colsample_bytree=0.95, learning_rate=0.012, max_depth=6, missing=inf, n_estimators=800, subsample=0.8;, score=-505.924 total time=   4.4s\n",
      "[CV 5/5] END colsample_bytree=0.95, learning_rate=0.01, max_depth=8, missing=inf, n_estimators=1000, subsample=0.85;, score=-504.984 total time=  11.8s\n",
      "[CV 3/5] END colsample_bytree=0.95, learning_rate=0.012, max_depth=6, missing=inf, n_estimators=800, subsample=0.8;, score=-511.723 total time=   4.1s\n",
      "[CV 2/5] END colsample_bytree=0.95, learning_rate=0.012, max_depth=6, missing=inf, n_estimators=800, subsample=0.8;, score=-507.076 total time=   4.1s\n",
      "[CV 4/5] END colsample_bytree=0.95, learning_rate=0.012, max_depth=6, missing=inf, n_estimators=800, subsample=0.8;, score=-558.014 total time=   4.2s\n",
      "[CV 2/5] END colsample_bytree=0.95, learning_rate=0.01, max_depth=8, missing=inf, n_estimators=1000, subsample=0.85;, score=-508.632 total time=  13.5s\n",
      "[CV 4/5] END colsample_bytree=0.95, learning_rate=0.01, max_depth=8, missing=inf, n_estimators=1000, subsample=0.85;, score=-559.667 total time=  13.7s\n",
      "[CV 3/5] END colsample_bytree=0.95, learning_rate=0.01, max_depth=8, missing=inf, n_estimators=1000, subsample=0.85;, score=-515.626 total time=  13.8s\n",
      "[CV 1/5] END colsample_bytree=0.95, learning_rate=0.01, max_depth=8, missing=inf, n_estimators=1200, subsample=0.8;, score=-502.517 total time=  13.3s\n",
      "[CV 5/5] END colsample_bytree=0.95, learning_rate=0.012, max_depth=6, missing=inf, n_estimators=800, subsample=0.8;, score=-504.986 total time=   4.0s\n",
      "[CV 3/5] END colsample_bytree=0.95, learning_rate=0.01, max_depth=8, missing=inf, n_estimators=1200, subsample=0.8;, score=-512.659 total time=  13.4s\n",
      "[CV 2/5] END colsample_bytree=0.95, learning_rate=0.01, max_depth=8, missing=inf, n_estimators=1200, subsample=0.8;, score=-508.964 total time=  14.0s\n",
      "[CV 5/5] END colsample_bytree=0.95, learning_rate=0.01, max_depth=8, missing=inf, n_estimators=1200, subsample=0.8;, score=-505.477 total time=  12.9s\n",
      "[CV 1/5] END colsample_bytree=0.95, learning_rate=0.012, max_depth=6, missing=inf, n_estimators=800, subsample=0.85;, score=-504.996 total time=   4.4s\n",
      "[CV 2/5] END colsample_bytree=0.95, learning_rate=0.012, max_depth=6, missing=inf, n_estimators=800, subsample=0.85;, score=-506.253 total time=   3.8s\n",
      "[CV 2/5] END colsample_bytree=0.95, learning_rate=0.01, max_depth=8, missing=inf, n_estimators=1200, subsample=0.85;, score=-508.936 total time=  12.9s\n",
      "[CV 3/5] END colsample_bytree=0.95, learning_rate=0.012, max_depth=6, missing=inf, n_estimators=800, subsample=0.85;, score=-510.748 total time=   3.8s\n",
      "[CV 4/5] END colsample_bytree=0.95, learning_rate=0.01, max_depth=8, missing=inf, n_estimators=1200, subsample=0.85;, score=-559.216 total time=  13.2s\n",
      "[CV 3/5] END colsample_bytree=0.95, learning_rate=0.01, max_depth=8, missing=inf, n_estimators=1200, subsample=0.85;, score=-515.231 total time=  13.6s\n",
      "[CV 1/5] END colsample_bytree=0.95, learning_rate=0.01, max_depth=8, missing=inf, n_estimators=1200, subsample=0.85;, score=-503.363 total time=  13.7s\n",
      "[CV 5/5] END colsample_bytree=0.95, learning_rate=0.012, max_depth=6, missing=inf, n_estimators=800, subsample=0.85;, score=-505.570 total time=   3.7s\n",
      "[CV 4/5] END colsample_bytree=0.95, learning_rate=0.012, max_depth=6, missing=inf, n_estimators=800, subsample=0.85;, score=-558.528 total time=   3.9s\n",
      "[CV 4/5] END colsample_bytree=0.95, learning_rate=0.01, max_depth=8, missing=inf, n_estimators=1200, subsample=0.8;, score=-555.796 total time=  16.0s\n",
      "[CV 1/5] END colsample_bytree=0.95, learning_rate=0.012, max_depth=6, missing=inf, n_estimators=1000, subsample=0.8;, score=-505.582 total time=   4.5s\n",
      "[CV 2/5] END colsample_bytree=0.95, learning_rate=0.012, max_depth=6, missing=inf, n_estimators=1000, subsample=0.8;, score=-505.798 total time=   5.1s\n",
      "[CV 5/5] END colsample_bytree=0.95, learning_rate=0.012, max_depth=6, missing=inf, n_estimators=1000, subsample=0.8;, score=-504.323 total time=   4.6s\n",
      "[CV 3/5] END colsample_bytree=0.95, learning_rate=0.012, max_depth=6, missing=inf, n_estimators=1000, subsample=0.8;, score=-510.669 total time=   5.0s\n",
      "[CV 4/5] END colsample_bytree=0.95, learning_rate=0.012, max_depth=6, missing=inf, n_estimators=1000, subsample=0.8;, score=-556.094 total time=   5.1s\n",
      "[CV 1/5] END colsample_bytree=0.95, learning_rate=0.012, max_depth=6, missing=inf, n_estimators=1000, subsample=0.85;, score=-504.854 total time=   4.5s\n",
      "[CV 3/5] END colsample_bytree=0.95, learning_rate=0.012, max_depth=6, missing=inf, n_estimators=1000, subsample=0.85;, score=-509.075 total time=   4.5s\n",
      "[CV 2/5] END colsample_bytree=0.95, learning_rate=0.012, max_depth=6, missing=inf, n_estimators=1000, subsample=0.85;, score=-504.795 total time=   4.8s\n",
      "[CV 4/5] END colsample_bytree=0.95, learning_rate=0.012, max_depth=6, missing=inf, n_estimators=1000, subsample=0.85;, score=-557.053 total time=   4.4s\n",
      "[CV 5/5] END colsample_bytree=0.95, learning_rate=0.012, max_depth=6, missing=inf, n_estimators=1000, subsample=0.85;, score=-504.402 total time=   4.9s\n",
      "[CV 1/5] END colsample_bytree=0.95, learning_rate=0.012, max_depth=6, missing=inf, n_estimators=1200, subsample=0.8;, score=-506.601 total time=   5.5s\n",
      "[CV 2/5] END colsample_bytree=0.95, learning_rate=0.012, max_depth=6, missing=inf, n_estimators=1200, subsample=0.8;, score=-505.063 total time=   5.5s\n",
      "[CV 5/5] END colsample_bytree=0.95, learning_rate=0.01, max_depth=8, missing=inf, n_estimators=1200, subsample=0.85;, score=-504.734 total time=  15.0s\n",
      "[CV 3/5] END colsample_bytree=0.95, learning_rate=0.012, max_depth=6, missing=inf, n_estimators=1200, subsample=0.8;, score=-510.176 total time=   5.4s\n",
      "[CV 5/5] END colsample_bytree=0.95, learning_rate=0.012, max_depth=6, missing=inf, n_estimators=1200, subsample=0.8;, score=-503.452 total time=   5.3s\n",
      "[CV 1/5] END colsample_bytree=0.95, learning_rate=0.012, max_depth=6, missing=inf, n_estimators=1200, subsample=0.85;, score=-504.911 total time=   5.3s\n",
      "[CV 4/5] END colsample_bytree=0.95, learning_rate=0.012, max_depth=6, missing=inf, n_estimators=1200, subsample=0.8;, score=-555.122 total time=   5.4s\n",
      "[CV 3/5] END colsample_bytree=0.95, learning_rate=0.012, max_depth=6, missing=inf, n_estimators=1200, subsample=0.85;, score=-508.789 total time=   5.3s\n",
      "[CV 2/5] END colsample_bytree=0.95, learning_rate=0.012, max_depth=6, missing=inf, n_estimators=1200, subsample=0.85;, score=-504.829 total time=   5.6s\n",
      "[CV 5/5] END colsample_bytree=0.95, learning_rate=0.012, max_depth=6, missing=inf, n_estimators=1200, subsample=0.85;, score=-503.414 total time=   5.6s\n",
      "[CV 4/5] END colsample_bytree=0.95, learning_rate=0.012, max_depth=6, missing=inf, n_estimators=1200, subsample=0.85;, score=-556.298 total time=   6.4s\n",
      "[CV 2/5] END colsample_bytree=0.95, learning_rate=0.012, max_depth=7, missing=inf, n_estimators=800, subsample=0.8;, score=-506.040 total time=   5.6s\n",
      "[CV 5/5] END colsample_bytree=0.95, learning_rate=0.012, max_depth=7, missing=inf, n_estimators=800, subsample=0.8;, score=-502.541 total time=   5.7s\n",
      "[CV 1/5] END colsample_bytree=0.95, learning_rate=0.012, max_depth=7, missing=inf, n_estimators=800, subsample=0.8;, score=-500.847 total time=   6.6s\n",
      "[CV 1/5] END colsample_bytree=0.95, learning_rate=0.012, max_depth=7, missing=inf, n_estimators=800, subsample=0.85;, score=-500.754 total time=   5.8s\n",
      "[CV 2/5] END colsample_bytree=0.95, learning_rate=0.012, max_depth=7, missing=inf, n_estimators=800, subsample=0.85;, score=-506.337 total time=   5.8s\n",
      "[CV 3/5] END colsample_bytree=0.95, learning_rate=0.012, max_depth=7, missing=inf, n_estimators=800, subsample=0.8;, score=-508.651 total time=   6.7s\n",
      "[CV 4/5] END colsample_bytree=0.95, learning_rate=0.012, max_depth=7, missing=inf, n_estimators=800, subsample=0.8;, score=-554.619 total time=   6.5s\n",
      "[CV 3/5] END colsample_bytree=0.95, learning_rate=0.012, max_depth=7, missing=inf, n_estimators=800, subsample=0.85;, score=-511.456 total time=   6.0s\n",
      "[CV 4/5] END colsample_bytree=0.95, learning_rate=0.012, max_depth=7, missing=inf, n_estimators=800, subsample=0.85;, score=-558.773 total time=   6.3s\n",
      "[CV 5/5] END colsample_bytree=0.95, learning_rate=0.012, max_depth=7, missing=inf, n_estimators=800, subsample=0.85;, score=-504.827 total time=   6.0s\n",
      "[CV 1/5] END colsample_bytree=0.95, learning_rate=0.012, max_depth=7, missing=inf, n_estimators=1000, subsample=0.8;, score=-500.935 total time=   6.9s\n",
      "[CV 4/5] END colsample_bytree=0.95, learning_rate=0.012, max_depth=7, missing=inf, n_estimators=1000, subsample=0.8;, score=-553.519 total time=   7.0s\n",
      "[CV 5/5] END colsample_bytree=0.95, learning_rate=0.012, max_depth=7, missing=inf, n_estimators=1000, subsample=0.8;, score=-502.519 total time=   7.0s\n",
      "[CV 3/5] END colsample_bytree=0.95, learning_rate=0.012, max_depth=7, missing=inf, n_estimators=1000, subsample=0.8;, score=-508.344 total time=   7.1s\n",
      "[CV 2/5] END colsample_bytree=0.95, learning_rate=0.012, max_depth=7, missing=inf, n_estimators=1000, subsample=0.85;, score=-506.103 total time=   6.9s\n",
      "[CV 1/5] END colsample_bytree=0.95, learning_rate=0.012, max_depth=7, missing=inf, n_estimators=1000, subsample=0.85;, score=-500.720 total time=   7.2s\n",
      "[CV 3/5] END colsample_bytree=0.95, learning_rate=0.012, max_depth=7, missing=inf, n_estimators=1000, subsample=0.85;, score=-511.196 total time=   7.0s\n",
      "[CV 2/5] END colsample_bytree=0.95, learning_rate=0.012, max_depth=7, missing=inf, n_estimators=1000, subsample=0.8;, score=-506.187 total time=   8.1s\n",
      "[CV 4/5] END colsample_bytree=0.95, learning_rate=0.012, max_depth=7, missing=inf, n_estimators=1000, subsample=0.85;, score=-558.441 total time=   7.2s\n",
      "[CV 5/5] END colsample_bytree=0.95, learning_rate=0.012, max_depth=7, missing=inf, n_estimators=1000, subsample=0.85;, score=-503.999 total time=   8.7s\n",
      "[CV 1/5] END colsample_bytree=0.95, learning_rate=0.012, max_depth=7, missing=inf, n_estimators=1200, subsample=0.8;, score=-501.861 total time=   8.6s\n",
      "[CV 2/5] END colsample_bytree=0.95, learning_rate=0.012, max_depth=7, missing=inf, n_estimators=1200, subsample=0.8;, score=-506.041 total time=   8.2s\n",
      "[CV 4/5] END colsample_bytree=0.95, learning_rate=0.012, max_depth=7, missing=inf, n_estimators=1200, subsample=0.8;, score=-553.040 total time=   8.4s\n",
      "[CV 5/5] END colsample_bytree=0.95, learning_rate=0.012, max_depth=7, missing=inf, n_estimators=1200, subsample=0.8;, score=-502.126 total time=   8.4s\n",
      "[CV 3/5] END colsample_bytree=0.95, learning_rate=0.012, max_depth=7, missing=inf, n_estimators=1200, subsample=0.85;, score=-511.301 total time=   8.8s\n",
      "[CV 3/5] END colsample_bytree=0.95, learning_rate=0.012, max_depth=7, missing=inf, n_estimators=1200, subsample=0.8;, score=-508.392 total time=  10.2s\n",
      "[CV 1/5] END colsample_bytree=0.95, learning_rate=0.012, max_depth=7, missing=inf, n_estimators=1200, subsample=0.85;, score=-501.187 total time=   9.9s\n",
      "[CV 2/5] END colsample_bytree=0.95, learning_rate=0.012, max_depth=7, missing=inf, n_estimators=1200, subsample=0.85;, score=-506.781 total time=  10.1s\n",
      "[CV 5/5] END colsample_bytree=0.95, learning_rate=0.012, max_depth=7, missing=inf, n_estimators=1200, subsample=0.85;, score=-503.698 total time=   8.7s\n",
      "[CV 4/5] END colsample_bytree=0.95, learning_rate=0.012, max_depth=7, missing=inf, n_estimators=1200, subsample=0.85;, score=-558.180 total time=  10.2s\n",
      "[CV 2/5] END colsample_bytree=0.95, learning_rate=0.012, max_depth=8, missing=inf, n_estimators=800, subsample=0.8;, score=-508.903 total time=   9.0s\n",
      "[CV 1/5] END colsample_bytree=0.95, learning_rate=0.012, max_depth=8, missing=inf, n_estimators=800, subsample=0.8;, score=-502.810 total time=   9.7s\n",
      "[CV 3/5] END colsample_bytree=0.95, learning_rate=0.012, max_depth=8, missing=inf, n_estimators=800, subsample=0.8;, score=-512.823 total time=   9.1s\n",
      "[CV 5/5] END colsample_bytree=0.95, learning_rate=0.012, max_depth=8, missing=inf, n_estimators=800, subsample=0.8;, score=-503.491 total time=   9.1s\n",
      "[CV 4/5] END colsample_bytree=0.95, learning_rate=0.012, max_depth=8, missing=inf, n_estimators=800, subsample=0.8;, score=-558.324 total time=   9.6s\n",
      "[CV 1/5] END colsample_bytree=0.95, learning_rate=0.012, max_depth=8, missing=inf, n_estimators=800, subsample=0.85;, score=-501.664 total time=   9.4s\n",
      "[CV 2/5] END colsample_bytree=0.95, learning_rate=0.012, max_depth=8, missing=inf, n_estimators=800, subsample=0.85;, score=-510.659 total time=   9.4s\n",
      "[CV 4/5] END colsample_bytree=0.95, learning_rate=0.012, max_depth=8, missing=inf, n_estimators=800, subsample=0.85;, score=-559.746 total time=   9.1s\n",
      "[CV 3/5] END colsample_bytree=0.95, learning_rate=0.012, max_depth=8, missing=inf, n_estimators=800, subsample=0.85;, score=-515.493 total time=  11.8s\n",
      "[CV 5/5] END colsample_bytree=0.95, learning_rate=0.012, max_depth=8, missing=inf, n_estimators=800, subsample=0.85;, score=-505.501 total time=  11.4s\n",
      "[CV 2/5] END colsample_bytree=0.95, learning_rate=0.012, max_depth=8, missing=inf, n_estimators=1000, subsample=0.8;, score=-509.230 total time=  11.1s\n",
      "[CV 1/5] END colsample_bytree=0.95, learning_rate=0.012, max_depth=8, missing=inf, n_estimators=1000, subsample=0.8;, score=-502.764 total time=  11.5s\n",
      "[CV 4/5] END colsample_bytree=0.95, learning_rate=0.012, max_depth=8, missing=inf, n_estimators=1000, subsample=0.8;, score=-557.122 total time=  11.1s\n",
      "[CV 3/5] END colsample_bytree=0.95, learning_rate=0.012, max_depth=8, missing=inf, n_estimators=1000, subsample=0.8;, score=-512.556 total time=  11.7s\n",
      "[CV 5/5] END colsample_bytree=0.95, learning_rate=0.012, max_depth=8, missing=inf, n_estimators=1000, subsample=0.8;, score=-503.114 total time=  11.6s\n",
      "[CV 4/5] END colsample_bytree=0.95, learning_rate=0.012, max_depth=8, missing=inf, n_estimators=1000, subsample=0.85;, score=-559.062 total time=  11.0s\n",
      "[CV 1/5] END colsample_bytree=0.95, learning_rate=0.012, max_depth=8, missing=inf, n_estimators=1000, subsample=0.85;, score=-501.775 total time=  12.4s\n",
      "[CV 2/5] END colsample_bytree=0.95, learning_rate=0.012, max_depth=8, missing=inf, n_estimators=1000, subsample=0.85;, score=-510.727 total time=  12.4s\n",
      "[CV 3/5] END colsample_bytree=0.95, learning_rate=0.012, max_depth=8, missing=inf, n_estimators=1000, subsample=0.85;, score=-515.404 total time=  12.3s\n",
      "[CV 5/5] END colsample_bytree=0.95, learning_rate=0.012, max_depth=8, missing=inf, n_estimators=1000, subsample=0.85;, score=-505.385 total time=  11.6s\n",
      "[CV 2/5] END colsample_bytree=0.95, learning_rate=0.012, max_depth=8, missing=inf, n_estimators=1200, subsample=0.8;, score=-508.899 total time=  11.2s\n",
      "[CV 1/5] END colsample_bytree=0.95, learning_rate=0.012, max_depth=8, missing=inf, n_estimators=1200, subsample=0.8;, score=-503.582 total time=  11.4s\n",
      "[CV 3/5] END colsample_bytree=0.95, learning_rate=0.012, max_depth=8, missing=inf, n_estimators=1200, subsample=0.8;, score=-513.195 total time=  11.2s\n",
      "[CV 4/5] END colsample_bytree=0.95, learning_rate=0.012, max_depth=8, missing=inf, n_estimators=1200, subsample=0.8;, score=-556.763 total time=  11.2s\n",
      "[CV 1/5] END colsample_bytree=0.95, learning_rate=0.012, max_depth=8, missing=inf, n_estimators=1200, subsample=0.85;, score=-502.275 total time=  10.9s\n",
      "[CV 2/5] END colsample_bytree=0.95, learning_rate=0.012, max_depth=8, missing=inf, n_estimators=1200, subsample=0.85;, score=-511.183 total time=  10.8s\n",
      "[CV 5/5] END colsample_bytree=0.95, learning_rate=0.012, max_depth=8, missing=inf, n_estimators=1200, subsample=0.8;, score=-502.815 total time=  11.0s\n",
      "[CV 3/5] END colsample_bytree=0.95, learning_rate=0.012, max_depth=8, missing=inf, n_estimators=1200, subsample=0.85;, score=-515.424 total time=  10.2s\n",
      "[CV 4/5] END colsample_bytree=0.95, learning_rate=0.012, max_depth=8, missing=inf, n_estimators=1200, subsample=0.85;, score=-559.295 total time=   9.0s\n",
      "[CV 5/5] END colsample_bytree=0.95, learning_rate=0.012, max_depth=8, missing=inf, n_estimators=1200, subsample=0.85;, score=-504.879 total time=   7.2s\n",
      "Best parameters found:  {'colsample_bytree': 0.95, 'learning_rate': 0.012, 'max_depth': 7, 'missing': inf, 'n_estimators': 1200, 'subsample': 0.8}\n",
      "Best score found:  -514.2922399050833\n",
      "Test score with best parameters:  0.9932780728080274\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid_art, cv=5, n_jobs=-1, verbose=3, scoring='neg_root_mean_squared_error')\n",
    "\n",
    "# Fit the GridSearchCV instance to the training data\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "# Get the best parameters and the best score\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "print(\"Best parameters found: \", best_params)\n",
    "print(\"Best score found: \", best_score)\n",
    "\n",
    "# Evaluate the model on the test set using the best parameters\n",
    "best_model = grid_search.best_estimator_\n",
    "test_score = best_model.score(X_test, y_test)\n",
    "print(\"Test score with best parameters: \", test_score)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlkAAAHHCAYAAACMfE3pAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAACWmUlEQVR4nOzdeVhUZfvA8e8My7CJCIqIIuCuuZZpKqUlCkGmaalFKu5rZeaaG6jlmrtpWbmkZpZKpWiSS70lr6KpuVKaWwK5g4oOA/P8/vDl/BwBdZQRxPtzXVxwnvOc59znZmDuOeeZMzqllEIIIYQQQuQrfUEHIIQQQghRFEmRJYQQQghhA1JkCSGEEELYgBRZQgghhBA2IEWWEEIIIYQNSJElhBBCCGEDUmQJIYQQQtiAFFlCCCGEEDYgRZYQQgghhA1IkSWEeOwsXrwYnU7HiRMnCjoUIUQRJkWWEI+B7KIit6/hw4fbZJ/bt28nKiqKy5cv22T8x1l6ejpRUVFs27atoEMRQtyBfUEHIIR4eMaNG0dgYKBFW82aNW2yr+3btxMdHU1kZCQeHh422cf96tSpEx07dsRgMBR0KPclPT2d6OhoAJo1a1awwQgh8iRFlhCPkRdffJH69esXdBgP5Nq1a7i6uj7QGHZ2dtjZ2eVTRA+P2WwmIyOjoMMQQtwjuVwohNBs2LCBZ599FldXV4oVK0Z4eDgHDx606PPHH38QGRlJhQoVcHJywsfHh27dunHhwgWtT1RUFEOGDAEgMDBQuzR54sQJTpw4gU6nY/HixTn2r9PpiIqKshhHp9Nx6NAh3njjDUqUKEFQUJC2ftmyZTz11FM4Ozvj6elJx44dOX369F2PM7c5WQEBAbz00kts27aN+vXr4+zsTK1atbRLcmvWrKFWrVo4OTnx1FNPsWfPHosxIyMjcXNz4++//yYkJARXV1d8fX0ZN24cSimLvteuXeO9997Dz88Pg8FA1apVmTZtWo5+Op2OAQMGsHz5cp544gkMBgMLFiygVKlSAERHR2u5zc7bvfx+bs3t0aNHtbONxYsXp2vXrqSnp+fI2bJly2jQoAEuLi6UKFGC5557jk2bNln0uZfHjxCPEzmTJcRjJDU1lfPnz1u0lSxZEoAvv/ySLl26EBISwuTJk0lPT2f+/PkEBQWxZ88eAgICAIiLi+Pvv/+ma9eu+Pj4cPDgQT799FMOHjzIf//7X3Q6HW3btuXPP//kq6++YsaMGdo+SpUqxblz56yO+7XXXqNy5cp8+OGHWiHywQcfMHr0aNq3b0+PHj04d+4cc+bM4bnnnmPPnj33dYny6NGjvPHGG/Tu3Zs333yTadOm0apVKxYsWMD7779Pv379AJg4cSLt27cnMTERvf7/X6tmZWURGhrKM888w5QpU9i4cSNjx44lMzOTcePGAaCU4uWXX2br1q10796dunXr8uOPPzJkyBDOnDnDjBkzLGLasmULq1atYsCAAZQsWZI6deowf/58+vbtyyuvvELbtm0BqF27NnBvv59btW/fnsDAQCZOnMjvv//OZ599hre3N5MnT9b6REdHExUVRePGjRk3bhyOjo7s2LGDLVu20LJlS+DeHz9CPFaUEKLIW7RokQJy/VJKqStXrigPDw/Vs2dPi+1SUlJU8eLFLdrT09NzjP/VV18pQP3yyy9a29SpUxWgjh8/btH3+PHjClCLFi3KMQ6gxo4dqy2PHTtWAer111+36HfixAllZ2enPvjgA4v2/fv3K3t7+xzteeXj1tj8/f0VoLZv3661/fjjjwpQzs7O6uTJk1r7J598ogC1detWra1Lly4KUG+99ZbWZjabVXh4uHJ0dFTnzp1TSikVExOjADVhwgSLmF599VWl0+nU0aNHLfKh1+vVwYMHLfqeO3cuR66y3evvJzu33bp1s+j7yiuvKC8vL235r7/+Unq9Xr3yyisqKyvLoq/ZbFZKWff4EeJxIpcLhXiMzJs3j7i4OIsvuHn24/Lly7z++uucP39e+7Kzs6Nhw4Zs3bpVG8PZ2Vn7+caNG5w/f55nnnkGgN9//90mcffp08diec2aNZjNZtq3b28Rr4+PD5UrV7aI1xo1atSgUaNG2nLDhg0BeOGFFyhfvnyO9r///jvHGAMGDNB+zr7cl5GRwU8//QRAbGwsdnZ2vP322xbbvffeeyil2LBhg0V706ZNqVGjxj0fg7W/n9tz++yzz3LhwgXS0tIAiImJwWw2M2bMGIuzdtnHB9Y9foR4nMjlQiEeIw0aNMh14vtff/0F3CwmcuPu7q79fPHiRaKjo1m5ciVnz5616JeampqP0f6/298R+ddff6GUonLlyrn2d3BwuK/93FpIARQvXhwAPz+/XNsvXbpk0a7X66lQoYJFW5UqVQC0+V8nT57E19eXYsWKWfSrXr26tv5Wtx/73Vj7+7n9mEuUKAHcPDZ3d3eOHTuGXq+/Y6FnzeNHiMeJFFlCCMxmM3BzXo2Pj0+O9fb2//+von379mzfvp0hQ4ZQt25d3NzcMJvNhIaGauPcye1zgrJlZWXluc2tZ2ey49XpdGzYsCHXdwm6ubndNY7c5PWOw7za1W0T1W3h9mO/G2t/P/lxbNY8foR4nMgjXwhBxYoVAfD29iY4ODjPfpcuXWLz5s1ER0czZswYrT37TMat8iqmss+U3H6T0tvP4NwtXqUUgYGB2pmiwsBsNvP3339bxPTnn38CaBO//f39+emnn7hy5YrF2awjR45o6+8mr9xa8/u5VxUrVsRsNnPo0CHq1q2bZx+4++NHiMeNzMkSQhASEoK7uzsffvghJpMpx/rsdwRmn/W4/SzHzJkzc2yTfS+r24spd3d3SpYsyS+//GLR/vHHH99zvG3btsXOzo7o6OgcsSilctyu4GGaO3euRSxz587FwcGB5s2bAxAWFkZWVpZFP4AZM2ag0+l48cUX77oPFxcXIGdurfn93Ks2bdqg1+sZN25cjjNh2fu518ePEI8bOZMlhMDd3Z358+fTqVMnnnzySTp27EipUqU4deoU69evp0mTJsydOxd3d3eee+45pkyZgslkomzZsmzatInjx4/nGPOpp54CYOTIkXTs2BEHBwdatWqFq6srPXr0YNKkSfTo0YP69evzyy+/aGd87kXFihWZMGECI0aM4MSJE7Rp04ZixYpx/Phx1q5dS69evRg8eHC+5edeOTk5sXHjRrp06ULDhg3ZsGED69ev5/3339fubdWqVSuef/55Ro4cyYkTJ6hTpw6bNm3iu+++Y+DAgdpZoTtxdnamRo0afP3111SpUgVPT09q1qxJzZo17/n3c68qVarEyJEjGT9+PM8++yxt27bFYDCQkJCAr68vEydOvOfHjxCPnQJ6V6MQ4iHKvmVBQkLCHftt3bpVhYSEqOLFiysnJydVsWJFFRkZqXbt2qX1+eeff9Qrr7yiPDw8VPHixdVrr72mkpKScr2lwPjx41XZsmWVXq+3uGVCenq66t69uypevLgqVqyYat++vTp79myet3DIvv3B7VavXq2CgoKUq6urcnV1VdWqVVP9+/dXiYmJ95SP22/hEB4enqMvoPr372/Rln0biqlTp2ptXbp0Ua6ururYsWOqZcuWysXFRZUuXVqNHTs2x60Prly5ot59913l6+urHBwcVOXKldXUqVO1WyLcad/Ztm/frp566inl6Ohokbd7/f3kldvccqOUUl988YWqV6+eMhgMqkSJEqpp06YqLi7Oos+9PH6EeJzolHoIMzeFEKKIi4yM5Ntvv+Xq1asFHYoQopCQOVlCCCGEEDYgRZYQQgghhA1IkSWEEEIIYQMyJ0sIIYQQwgbkTJYQQgghhA1IkSWEEEIIYQNyM9J8YjabSUpKolixYnl+5IUQQgghChelFFeuXMHX1xe9Pn/PPUmRlU+SkpLw8/Mr6DCEEEIIcR9Onz5NuXLl8nVMKbLySfYHvR4/fhxPT88CjqbwM5lMbNq0iZYtW+Lg4FDQ4RR6ki/rSL6sJzmzjuTLOoU5X2lpafj5+Vl8YHt+kSIrn2RfIixWrBju7u4FHE3hZzKZcHFxwd3dvdD9wRVGki/rSL6sJzmzjuTLOo9Cvmwx1UcmvgshhBBC2IAUWUIIIYQQNiBFlhBCCCGEDUiRJYQQQghhA1JkCSGEEELYgBRZQgghhBA2IEWWEEIIIYQNSJElhBBCCGEDUmQJIYQQQtiAFFlCCCGEEDYgRZYQQgghhA1IkSWEEEIIYQNSZAkhhBBC2IAUWUIIIYQQNiBFlhBCCCGEDUiRJYQQQghhA1JkCSGEECJf/fLLL7Rq1QpfX190Oh3fffedxfo1a9bQsmVLvLy80Ol07N27N8cYKSkpdOrUCR8fH1xdXXnyySdZvXq1tv7EiRN0796dwMBAnJ2dqVixImPHjiUjI8NinFWrVlG3bl1cXFzw9/dn6tSpd43/4sWLRERE4O7ujoeHB927d+fq1atW50GKrNucOHEiz1+4EEIIIe7u2rVr1KlTh3nz5uW5PigoiMmTJ+c5RufOnUlMTOT7779n//79tG3blvbt27Nnzx4Ajhw5gtls5pNPPuHgwYPMmDGDBQsW8P7772tjbNiwgYiICPr06cOBAwf4+OOPmTFjBnPnzr1j/BERERw8eJC4uDjWrVvHL7/8Qq9evazOg73VWzyiMjIycHR0LOgwhBBCiCLvxRdf5MUXX8xzfadOnYCbJzbysn37dubPn0+DBg0AGDVqFDNmzGD37t3Uq1eP0NBQQkNDtf4VKlQgMTGR+fPnM23aNAC+/PJL2rRpQ58+fbQ+I0aMYPLkyfTv3x+dTpdjv4cPH2bjxo0kJCRQv359AObMmUNYWBjTpk3D19f3nvNQqIsss9nMtGnT+PTTTzl9+jSlS5emd+/ejBw5kmHDhrF27Vr++ecffHx8iIiIYMyYMTg4OAAQFRVFTEwMAwYM4IMPPuDkyZOYzWY2btzIhAkTOHDgAHZ2djRq1IhZs2ZRsWJFAAIDAwGoV68eAE2bNmXbtm33HHPDiZvJtHfN30QUQQY7xZQGUDPqR4xZOR/kwpLkyzqSL+tJzqwj+crbiUnh+TJO48aN+frrrwkPD8fDw4NVq1Zx48YNmjVrluc2qampeHp6astGoxEXFxeLPs7Ozvzzzz+cPHmSgICAHGPEx8fj4eGhFVgAwcHB6PV6duzYwSuvvHLPx1CoLxeOGDGCSZMmMXr0aA4dOsSKFSsoXbo0AMWKFWPx4sUcOnSIWbNmsXDhQmbMmGGx/dGjR1m9ejVr1qzRLv9du3aNQYMGsWvXLjZv3oxer+eVV17BbDYDsHPnTgB++uknkpOTWbNmzcM7YCGEEEIAN+dSmUwmvLy8MBgM9O7dm7Vr11KpUqVc+x89epQ5c+bQu3dvrS0kJIQ1a9awefNmzGYzf/75Jx999BEAycnJuY6TkpKCt7e3RZu9vT2enp6kpKRYdQyF9kzWlStXmDVrFnPnzqVLly4AVKxYkaCgIODmacNsAQEBDB48mJUrVzJ06FCtPSMjg6VLl1KqVCmtrV27dhb7+eKLLyhVqhSHDh2iZs2aWl8vLy98fHzyjM9oNGI0GrXltLQ0AAx6hZ2dut/DfmwY9Mriu7gzyZd1JF/Wk5xZR/KVN5PJlKMtKysLBweHHOuyl00mU451I0eO5NKlS2zcuBEvLy++//572rdvz5YtW6hVq5ZF3zNnzhAaGkq7du2IjIzUxoqMjOTPP//kpZdewmQy4e7uzoABAxg/fjxmsznX/eanQltkHT58GKPRSPPmzXNd//XXXzN79myOHTvG1atXyczMxN3d3aKPv7+/RYEF8NdffzFmzBh27NjB+fPntTNYp06dombNmvcc38SJE4mOjs7RPqqeGReXrHse53E3vr65oEN4pEi+rCP5sp7kzDqSr5xiY2NztO3du5dnnnmGuLg4i/Z///0XgF9//ZWkpCStPTk5mY8//pjZs2dz48YNzpw5w1NPPYW/vz/vv/8+ffv21fpevHiRUaNGUaVKFVq1apVj/88++yyNGzfm8uXLuLu788cffwBw7Ngxzp8/T3p6ukV/Hx8fzp49a9GWmZnJxYsX73jyJTeFtshydnbOc118fDwRERFER0cTEhJC8eLFWblypXYKMJura865Ua1atcLf35+FCxfi6+uL2WymZs2aOd7yeTcjRoxg0KBB2nJaWhp+fn5M2KMn08HOqrEeRwa9Ynx9M6N36TGaZT7D3Ui+rCP5sp7kzDqSr7wdiArJ0Va3bl0AWrRooc2dhv+f+B4UFKT1Adi/fz9wc1509erVtfZ58+ZRrlw5wsLCgJtnsFq0aEFQUBBLlizBzu7uz78xMTE888wzvP7668D/X4nK1qhRIy5fvszu3bt56qmnANiyZQtms5mGDRvedfxbFdoiq3Llyjg7O7N582Z69OhhsW779u34+/szcuRIre3kyZN3HfPChQskJiaycOFCnn32WeBm9Xyr7HcgZmXd+WyUwWDAYDDkaP9lWDBeXl53jeVxZzKZiI2NZfeYUIs/OJE7yZd1JF/Wk5xZR/J1Z1evXuXo0aPa8unTp7GzsyM5OZmKFSty8eJFTp06pZ29+vvvv3FwcMDHxwcfHx9q1apFpUqVGDBgANOmTcPLy4uYmBh++ukn1q1bh4ODg1Zg+fv7M336dC5fvqztL/uM0/nz5/n2229p1qwZN27cYNGiRaxevZqff/5Z+71ln9lKSkrC3d2d6tWrExoaSs+ePVmwYAEmk4kBAwbQsWNHq95ZCIW4yHJycmLYsGEMHToUR0dHmjRpwrlz5zh48CCVK1fm1KlTrFy5kqeffpr169ezdu3au45ZokQJvLy8+PTTTylTpgynTp1i+PDhFn28vb1xdnZm48aNlCtXDicnJ4oXL26rwxRCCCGKnF27dvH8889ry0OGDAFgz549LF26lO+//56uXbtq6zt27AjA2LFjiYqKwsHBgdjYWIYPH06rVq24evUqlSpVYsmSJdpZrLi4OI4ePcrRo0cpV66cxf6V+v+5ckuWLGHw4MEopWjUqBHbtm3TbgsBaJcLb52btXz5cgYMGEDz5s3R6/W0a9eO2bNnW58IVYhlZWWpCRMmKH9/f+Xg4KDKly+vPvzwQ6WUUkOGDFFeXl7Kzc1NdejQQc2YMUMVL15c23bs2LGqTp06OcaMi4tT1atXVwaDQdWuXVtt27ZNAWrt2rVan4ULFyo/Pz+l1+tV06ZN7ynW1NRUBajz588/wBE/PjIyMlRMTIzKyMgo6FAeCZIv60i+rCc5s47kyzqFOV/Zz9+pqan5PrZOKSVvjcgHaWlpFC9enPPnz8vlwnuQfao9LCxMTrXfA8mXdSRf1pOcWUfyZZ3CnK/s5+/U1NQcb6B7UIX6PllCCCGEEI8qKbKEEEIIIWxAiiwhhBBCCBuQIksIIYQQwgakyBJCCCGEsAEpsoQQQgghbECKLCGEEEIIG5AiSwghhBDCBqTIEkIIIYSwASmyhBBCCCFsQIosIYQQQggbkCJLCCGEEMIGpMgSQgghhLABKbKEEEKIB/TLL7/QqlUrfH190el0xMTEWKxXSjFmzBjKlCmDs7MzwcHB/PXXXxZ9Ll68SEREBO7u7nh4eNC9e3euXr2qrd+2bRutW7emTJkyuLq6UrduXZYvX24xRrNmzdDpdDm+wsPD7xj/tm3bePLJJzEYDFSqVInFixc/UD7ETY9tkbVkyRKCgoIKOgwhhBBFwLVr16hTpw7z5s3Ldf2UKVOYPXs2CxYsYMeOHbi6uhISEsKNGze0PhERERw8eJC4uDjWrVvHL7/8Qq9evbT127dvp3bt2qxevZo//viDrl270rlzZ9atW6f1WbNmDcnJydrXgQMHsLOz47XXXssz9uPHjxMeHs7zzz/P3r17GThwID169ODHH3/Mh8w83uwLOoCC8t133/Hyyy8XdBhCCCGKgBdffJEXX3wx13VKKWbOnMmoUaNo3bo1AEuXLqV06dLExMTQsWNHDh8+zMaNG0lISKB+/foAzJkzh7CwMKZNm4avry/vv/++xbjvvPMOmzZtYs2aNbz00ksAeHp6WvRZuXIlLi4udyyyFixYQGBgIB999BEA1atX59dff2XGjBmEhITcX0IEUASLrHPnzlGrVi3efvtt7QG5fft2mjVrxoYNG2jevDk3btxg06ZNfPjhh4wbN45Vq1Zx4MABi3Hq1q1Lq1atGD9+vFX7bzhxM5n2rvl2PEWVwU4xpQHUjPoRY5auoMMp9CRf1pF8WU9yZp3sfN2L48ePk5KSQnBwsNZWvHhxGjZsSHx8PB07diQ+Ph4PDw+twAIIDg5Gr9ezY8cOXnnllVzHTk1NpXr16nnu+/PPP6djx464uub9vBQfH28RG0BISAgDBw68twMUeSpyRVapUqX44osvaNOmDS1btqRq1ap06tSJAQMG0Lx5cwA2b95M2bJlqVatGt26dSM6OpqEhASefvppAPbs2cMff/zBmjVr8tyP0WjEaDRqy2lpaQAY9Ao7O2XDIywaDHpl8V3cmeTLOpIv60nOrJOdJ5PJlOv6zMxMbd0///wD3DzLdGv/UqVKkZSUhMlk4syZM5QqVSrHeJ6enpw5cybX/XzzzTckJCQwd+7cXNcnJCRw4MABPvnkkzzjBEhOTqZkyZIWfby8vEhLSyMtLQ1nZ+c8t71X2WPfKY6CYsuYilyRBRAWFkbPnj2JiIigfv36uLq6MnHiRG39rZcKy5UrR0hICIsWLdKKrEWLFtG0aVMqVKiQ5z4mTpxIdHR0jvZR9cy4uGTl8xEVXePrmws6hEeK5Ms6ki/rSc6sExcXl2v77t27cXBwAODIkSPAzRf4t17OS05ORqfTERsbS2JiIteuXSM2NtZinIyMDA4cOJCjff/+/UyYMIG+ffty8uRJTp48mSOGjz/+GH9/f86dO5dj+1ulp6eTmJho0WfXrl0AbNy4EYPBcKcUWCWvfBWk9PR0m42tU0oVyZct169fp2bNmpw+fZrdu3dTq1Yt4Oa1cV9fX1atWsWzzz4LwNq1a+nWrRvJycno9Xp8fX2ZMWMGnTp1ynP83M5k+fn5UWPISjId5HLh3Rj0ivH1zYzepcdolksTdyP5so7ky3qSM+tk56tFixZaMZXN0dGRb775Rpt/9ffff1OtWjV27txJ3bp1tX7NmzenTp06TJ8+ncWLFzN06FDOnj2rrc/MzKRYsWJ89dVXtGnTRmv/5ZdfaN26NVOnTqVHjx65xnft2jX8/f0ZO3Ysb7311h2P5YUXXqBevXranCy4+eaw9957j/Pnz99rSu7IZDIRFxeXa74KWlpaGiVLliQ1NRV3d/d8HbtInskCOHbsGElJSZjNZk6cOKEVWTt37iQzM5PGjRtrfVu1aoXBYGDt2rU4OjpiMpl49dVX7zi+wWDItbo3mnVkynyGe2Y062T+hxUkX9aRfFlPcmYdBweHXIsGe3t7rb1KlSr4+Pjwyy+/aFdM0tLS2LlzJ/369cPBwYGgoCAuX77MH3/8wVNPPQXA1q1bMZvNNGnSRBsr+zYOkydPpm/fvnnGFRMTg9FopEuXLnctaho3bkxsbKxFvy1bttCoUaN8L4jyyldBsmk8qggyGo2qTp06qkuXLurDDz9U3t7e6t9//1VKKTVixAjVpUuXHNsMHTpUtWjRQoWHh6tevXpZvc/U1FQFqPPnzz9o+I+FjIwMFRMTozIyMgo6lEeC5Ms6ki/rSc6sc3u+rly5ovbs2aP27NmjADV9+nS1Z88edfLkSaWUUpMmTVIeHh7qu+++U3/88Ydq3bq1CgwMVNevX9fGDA0NVfXq1VM7duxQv/76q6pcubJ6/fXXtfVbtmxRLi4uasSIESo5OVn7unDhQo74goKCVIcOHXKNffjw4apTp07a8t9//61cXFzUkCFD1OHDh9W8efOUnZ2d2rhxY77kSqnC/fjKfv5OTU3N97GLZJE1ePBgFRAQoFJTU1VWVpYKCgpS4eHhSimlnnjiCbV69eoc2/z555/Kzs5O2dnZqf/+979W71OKLOsU5j+4wkjyZR3Jl/UkZ9a5PV9bt25VQI6v7Bf1ZrNZjR49WpUuXVoZDAbVvHlzlZiYaDHmhQsX1Ouvv67c3NyUu7u76tq1q7py5Yq2vkuXLrnuo2nTphbjHDlyRAFq06ZNucbepUuXHNts3bpV1a1bVzk6OqoKFSqoRYsWPVB+bleYH1+2LLKK3OXCbdu2MXPmTLZu3apdW/3yyy+1m8QdPXo01/t+VK5cmcaNG3Px4kUaNmz4sMMWQgjxCGvWrBnqDlOcdTod48aNY9y4cXn28fT0ZMWKFXmuX7x48T3dib1q1ap3jCW3MZo1a8aePXvuOrawTpG743uzZs0wmUwWd3MPCAggNTUVo9HICy+8kOv9QpRSJCUl0a1bt4cZrhBCCCGKqCJ3JutOypUrx4gRI3K0nzt3jpUrV5KSkkLXrl0LIDIhhBBCFDWPVZHVvn37XNu9vb0pWbIkn376KSVKlHjIUQkhhBCiKHqsiqy83OnatRBCCCHE/Shyc7KEEEIIIQoDKbKEEEIIIWxAiiwhhBBCCBuQIksIIYQQwgakyBJCCCGEsAEpsoQQQgghbECKLCGEEEIIG5AiSwghhBDCBqTIEkIIIYSwASmyhBBCPPauXLnCwIED8ff3x9nZmcaNG5OQkGDR5/Dhw7z88ssUL14cDw8PBg8ezKlTp7T1n376Kc2aNcPd3R2dTsfly5dz7OfixYtERETg7u6Oh4cH3bt35+rVq3eM7caNG/Tv3x8vLy/c3Nxo164d//77b74ct7CtQl1kNWvWjIEDB9p8PzqdjpiYGJvvRwghROHUo0cP4uLi+PLLL9m/fz8tW7YkODiYM2fOAHDs2DGCgoKoVq0a27ZtY/fu3bRv3x4nJydtjPT0dEJDQ3n//ffz3E9ERAQHDx4kLi6OdevW8csvv9CrV687xvbuu+/yww8/8M033/Dzzz+TlJRE27Zt8+fAhU09Vp9dGBUVRUxMDHv37i3oUIQQQhQS169fZ/Xq1Xz33Xc899xzwM3nix9++IH58+czYcIERo4cSVhYGFOmTAHAZDLRoEEDvL29tXGyTwps27Yt1/0cPnyYjRs3kpCQQP369QGYM2cOYWFhTJs2DV9f3xzbpKam8vnnn7NixQpeeOEFABYtWkT16tX573//yzPPPJNfaRA2UKjPZAkhhBC2lpmZSVZWlsVZKQBnZ2d+/fVXzGYz69evp0qVKoSEhODt7U2TJk3473//a9V+4uPj8fDw0AosgODgYPR6PTt27Mh1m927d2MymQgODtbaqlWrRvny5YmPj7dq/+LhKzRnsq5du0bfvn1Zs2YNxYoVY/DgwRbrjUYjI0eO5KuvvuLy5cvUrFmTyZMn06xZMwAWL17MwIEDWbx4MUOGDOH06dM0bdqUzz77DD8/PxYvXkx0dDRw8/Ig3Hw1EBkZCcD58+d55ZVX+PHHHylbtiwfffQRL7/8stXH0XDiZjLtXe8/EY8Jg51iSgOoGfUjxixdQYdT6Em+rCP5st7jmrMTk8IpVqwYjRo1Yvz48VSvXp3SpUvz1VdfER8fT6VKlTh79ixXr15l0qRJTJgwgcmTJ7N+/XpGjx5NcHAwzZs3v6d9paSkWJz5ArC3t8fT05OUlJQ8t3F0dMTDw8OivXTp0nluIwqPQlNkDRkyhJ9//pnvvvsOb29v3n//fX7//Xfq1q0LwIABAzh06BArV67E19eXtWvXEhoayv79+6lcuTJw83r4Bx98wNKlS3F0dKRfv3507NiR3377jQ4dOnDgwAE2btzITz/9BEDx4sW1/UdHRzNlyhSmTp3KnDlziIiI4OTJk3h6euYar9FoxGg0astpaWkAGPQKOztlixQVKQa9svgu7kzyZR3Jl/Ue15yZTCYAvvjiC3r16kXZsmWxs7OjXr16dOjQgd9//137X9+qVSsGDBgAQJUqVfjuu+9YsGCBdokxW2ZmpjZ29vgAWVlZKKUs2m5dl1v7rWPdSimV5zaFUXachTFeW8ZUKIqsq1ev8vnnn7Ns2TLtFcGSJUsoV64cAKdOnWLRokWcOnVKu2Y9ePBgNm7cyKJFi/jwww+Bm4maO3cuDRs21MaoXr06O3fupEGDBri5uWFvb4+Pj0+OGCIjI3n99dcB+PDDD5k9ezY7d+4kNDQ015gnTpyonRm71ah6Zlxcsh4wI4+P8fXNBR3CI0XyZR3Jl/Uet5zFxsZqP7/33nv079+f9PR0PD09mTp1Km5ubiQkJGBnZ4ednZ1F/3LlynHgwAGLNoD9+/cDsGnTJtzc3LT2s2fPkpSUZNE/KyuLCxcucObMmRzjAJw8eZKMjAxWrVplMdbJkye5dOlSrtsUZnFxcQUdQg7p6ek2G7tQFFnHjh0jIyNDK44APD09qVq1KnDzAZuVlUWVKlUstjMajXh5eWnL9vb2PP3009pytWrV8PDw4PDhwzRo0OCOMdSuXVv72dXVFXd3d86ePZtn/xEjRjBo0CBtOS0tDT8/Pybs0ZPpYHeXIxYGvWJ8fTOjd+kxmh+fSxP3S/JlHcmX9R7XnB2ICsm1/dKlSxw4cICJEyfSunVr7bklLCwMuPmifuLEidSqVUtry+bqenPKSMuWLS0u8wUGBjJ37lx8fHx48skngZtFh1KKPn365DrxvUmTJowfPx57e3ttP4mJiZw7d46uXbtaPG8WZiaTibi4OFq0aIGDg0NBh2Mh+0qULRSKIuturl69ip2dHbt378bOzrKAubWyfxC3/9J1Oh1mc96v6AwGAwaDIUe70awj8zGaz/CgjGbdYzX/40FJvqwj+bLe45az7P/9P/74I0opqlatytGjRxkyZAjVqlWjR48eODg4MHToUDp06ECzZs14/vnnWb9+PQkJCUyaNEkbIyUlhZSUFE6cOAHAkSNHKFasGOXLl8fT05PatWsTGhpK3759WbBgASaTiYEDB9KxY0f8/f0BOHPmDM2bN2fp0qU0aNCAkiVL0r17d4YOHYq3tzfu7u689dZbNGrUiKCgoALJ2YNwcHAodEWWTeNRhcCVK1eUg4ODWrVqldZ28eJF5eLiot555x2VmJioAPXLL7/kOcaiRYsUoHbs2KG1HTlyxKLtgw8+UDVr1syxLaDWrl1r0Va8eHG1aNGiez6G1NRUBajz58/f8zaPs4yMDBUTE6MyMjIKOpRHguTLOpIv6z3uOfv6669VhQoVlKOjo/Lx8VH9+/dXly9ftujz+eefq0qVKiknJydVu3ZtNWLECIt8jR07VgE5vm59Lrlw4YJ6/fXXlZubm3J3d1ddu3ZVV65c0dYfP35cAWrr1q1a2/Xr11W/fv1UiRIllIuLi3rllVdUcnKyzXJhC4X58ZX9/J2amprvYxeKM1lubm50796dIUOG4OXlhbe3NyNHjkSvv3mHiSpVqhAREUHnzp356KOPqFevHufOnWPz5s3Url2b8PBw4GY1+tZbbzF79mzs7e0ZMGAAzzzzjHapMCAggOPHj7N3717KlStHsWLFcj0bJYQQ4vHSvn172rdvf8c+3bp1o1u3bsDNy1+3z4eKiooiKirqjmN4enqyYsWKPNcHBASglOWbD5ycnJg3bx7z5s2749ii8Ck098maOnUqzz77LK1atSI4OJigoCCeeuopbf2iRYvo3Lkz7733HlWrVqVNmzYkJCRQvnx5rY+LiwvDhg3jjTfeoEmTJri5ufH1119r69u1a0doaCjPP/88pUqV4quvvnqoxyiEEEKIx0ehOJMFN89mffnll3z55Zda25AhQ7SfHRwciI6OzvUdfbdq27Ztnh83YDAY+Pbbb3O03/6qAcj1M6eEEEIIIe5VoTmTJYQQQghRlEiRJYQQQghhA0WmyIqMjJRLfEIIIYQoNIpMkSWEEEIIUZhIkSWEEEIIYQNSZAkhhBBC2IAUWUIIIYQQNiBFlhBCCCGEDUiRJYQQQghhA1JkCSGEEELYgBRZQgghhBA2IEWWEEIIIYQNSJElhBCiyLpy5QoDBw7E398fZ2dnGjduTEJCgrY+KiqKatWq4erqSokSJQgODmbHjh25jmU0Gqlbty46nY69e/dq7du2baN169aUKVMGV1dX6taty/Lly+8a26lTpwgPD8fFxQVvb2+GDBlCZmbmAx+zKDykyAJefvllypcvj5OTE2XKlKFTp04kJSUVdFhCCCEeUI8ePYiLi+PLL79k//79tGzZkuDgYM6cOQNAlSpVmDt3Lvv37+fXX38lICCAli1bcu7cuRxjDR06FF9f3xzt27dvp3bt2qxevZo//viDrl270rlzZ9atW5dnXFlZWYSHh5ORkcH27dtZsmQJixcvZsyYMfl38KLgKaGmT5+u4uPj1YkTJ9Rvv/2mGjVqpBo1amTVGKmpqQpQ58+ft1GURUtGRoaKiYlRGRkZBR3KI0HyZR3Jl/WKYs7S09OVnZ2dWrdunUX7k08+qUaOHJnrNtn/y3/66SeL9tjYWFWtWjV18OBBBaidO3feMV9hYWGqa9euecYWGxur9Hq9SklJ0drmz5+v3N3dldFovNdDfGQU5sdX9u88NTU138e2L9gS7+Exm81MmzaNTz/9lNOnT1O6dGl69+7NyJEjeffdd7V+/v7+DB8+nDZt2mAymXBwcLBqPw0nbibT3jW/wy9yDHaKKQ2gZtSPGLN0BR1OoSf5so7ky3pFLWcnJoWTmZlJVlYWTk5OFuucnZ359ddfc2yTkZHBp59+SvHixalTp47W/u+//9KzZ09iYmJwcXG5p/2npqZSvXr1PNfHx8dTq1YtSpcurbWFhITQt29fDh48SL169e5pP6Jwe2wuF44YMYJJkyYxevRoDh06xIoVKywe3NkuXrzI8uXLady4sdUFlhBCiMKjWLFiNGrUiPHjx5OUlERWVhbLli0jPj6e5ORkrd+6detwc3PDycmJGTNmEBcXR8mSJQFQShEZGUmfPn2oX7/+Pe131apVJCQk0LVr1zz7pKSk5HgOyl5OSUmx9lBFIfVYnMm6cuUKs2bNYu7cuXTp0gWAihUrEhQUpPUZNmwYc+fOJT09nWeeeeaO19Lh5gRIo9GoLaelpQFg0Cvs7JQNjqJoMeiVxXdxZ5Iv60i+rFfUcmYymQD44osv6NWrF2XLlsXOzo569erRoUMHfv/9d61PUFAQCQkJXLhwgc8//5z27dvz66+/4u3tzdy5c0lLS2Pw4MGYTCZtm+wJ6tnL2bZt20bXrl2ZP38+VapUybE+m9lsRillsf7WsfPa7lGVfTyF8bhsGZNOKVU0/qLuYOfOnTRs2JC///6bwMDAXPucP3+eixcvcvLkSaKjoylevDjr1q1Dp8v9tHlUVBTR0dE52lesWHHPp5OFEEI8HDdu3CA9PR1PT0+mTp3KjRs3GD16dK59+/btS/PmzXn11Vf58MMP2bVrl8V6s9mMXq+nadOmvPPOO1r7gQMHmDBhAl27diUkJOSO8axYsYKdO3cyc+ZMre3ff/+ld+/eTJ8+nQoVKtz/wQqrpKen88Ybb5Camoq7u3u+jv1YnMlydna+a5+SJUtSsmRJqlSpQvXq1fHz8+O///0vjRo1yrX/iBEjGDRokLaclpaGn58fE/boyXSwy7fYiyqDXjG+vpnRu/QYzY/+/A9bk3xZR/JlvaKWswNRuRc5ly5d4sCBA0ycOJGwsLBc+zg7OxMQEEBYWBg1a9bUrlQAJCcnEx4ezpdffsn169dp0aIFDg4O/Pzzz0ycOJHJkyfTt2/fu8an1+v59ttvqV+/Pt7e3gB89tlnuLu707NnTwwGw30cdeFlMpmIi4vT8lWY3Pr7zXf5PpW+ELp+/bpydnZWCxcuvKf+J0+eVIDaunXrPe9D3l1oncL8TpPCSPJlHcmX9YpqzjZu3Kg2bNig/v77b7Vp0yZVp04d1bBhQ5WRkaGuXr2qRowYob27fNeuXapr167KYDCoAwcO5Dre8ePHc7y7cMuWLcrFxUWNGDFCJScna18XLlzQtluzZo2qWrWqtpyZmalq1qypWrZsqfbu3as2btyoSpUqpUaMGGHznBSEwvz4kncXPiAnJyeGDRvG0KFDcXR0pEmTJpw7d46DBw9Ss2ZNEhISCAoKokSJEhw7dozRo0dTsWLFPM9iCSGEeDSkpqYyYsQI/vnnHzw9PWnXrh0ffPABDg4OZGVlceTIEZYsWcL58+fx8vLi6aef5j//+Q9PPPHEPe9jyZIlpKenM3HiRCZOnKi1N23alG3btmlxJCYmauvs7OxYt24dffv2pVGjRri6utKlSxfGjRuXb8cuCt5jUWQBjB49Gnt7e8aMGUNSUhJlypShT58+uLi4sGbNGsaOHcu1a9coU6YMoaGhjBo1qsidrhVCiMdN+/btad++fa7rnJycWLNmjVXjBQQEaBPWs29avXjxYhYvXnzH7SIjI4mMjLRo8/f3JzY21qr9i0fLY1Nk6fV6Ro4cyciRI3Os27JlSwFEJIQQQoii7LG5T5YQQgghxMMkRZYQQgghhA1IkSWEEEIIYQNSZAkhhBBC2IAUWUIIIYQQNiBFlhBCCCGEDUiRJYQQQghhA1JkCSGEEELYgBRZQgghhBA2IEWWEEIIIYQNSJElhBBCCGEDUmQJIYQQQtiAFFlCCCGEEDYgRVYuTpw4gU6nY+/evQUdihBCPJaysrIYPXo0gYGBODs7U7FiRcaPH49SSutz9epVBgwYQLly5XB2dqZGjRosWLDAYpyUlBQ6deqEj48Prq6uPPnkk6xevdqiz++//06LFi3w8PDAy8uLXr16cfXq1TvGp5RixYoVlC9fHmdnZ4KDg/nrr7/yLwGiSJAiSwghRKEzefJk5s+fz9y5czl8+DCTJ09mypQpzJkzR+szaNAgNm7cyLJlyzh8+DADBw5kwIABfP/991qfzp07k5iYyPfff8/+/ftp27Yt7du3Z8+ePQAkJSURHBxMpUqV2LFjBxs3buTgwYNERkbeMb5p06axbt065s6dy44dO3B1dSUkJIQbN27YJB/i0SRFlhBCiEJn+/bttG7dmvDwcAICAnj11Vdp2bIlO3futOjTpUsXmjVrRkBAAL169aJOnTo5+rz11ls0aNCAChUqMGrUKDw8PNi9ezcA69atw8HBgXnz5lG1alWefvppFixYwOrVqzl69GiusSmlmDNnDu3bt+fll1+mdu3aLF26lKSkJGJiYmyaF/FosS/oAB6GjRs3MmHCBA4cOICdnR2NGjVi1qxZVKxYEYCdO3fSu3dvDh8+TM2aNRk5cuR976vhxM1k2rvmV+hFlsFOMaUB1Iz6EWOWrqDDKfQkX9aRfFmvMOXsxKRwGjduzKeffsqff/5JlSpV2LdvH7/++ivTp0/X+jVu3Jjvv/+ebt264evry7Zt2/jzzz+ZMWOGRZ+vv/6a8PBwPDw8WLVqFTdu3KBZs2YAGI1GHB0d0ev//5yDs7MzAL/++iuVKlXKEd/x48dJSUmhdu3aWlvx4sVp2LAh8fHxdOzYMb9TIh5Rj0WRde3aNQYNGkTt2rW5evUqY8aM4ZVXXmHv3r2kp6fz0ksv0aJFC5YtW8bx48d555137jqm0WjEaDRqy2lpaQAY9Ao7O5XXZuJ/DHpl8V3cmeTLOpIv6xWmnJlMJt577z0uXbpEtWrVsLOzIysri3HjxtG+fXtMJhMA06dPp2/fvpQrVw57e3v0ej3z58+nUaNGWp/ly5cTERGBl5cX9vb2uLi48M033+Dv74/JZOLZZ59l0KBBTJo0ibfeeotr164xdOhQAP755x9tnFv9888/AHh4eFisL1WqFElJSblu87jLzklhzI0tY3osiqx27dpZLH/xxReUKlWKQ4cOsX37dsxmM59//jlOTk488cQT/PPPP/Tt2/eOY06cOJHo6Ogc7aPqmXFxycrX+Iuy8fXNBR3CI0XyZR3Jl/UKQ85iY2P5z3/+w+LFixk0aBB+fn4cP36cKVOmcO7cOV544QUAYmJi2LJlC++//z7e3t4cPHiQ/v37888//1CnTh0APv30U06cOEF0dDTu7u7s2LGD1157jQ8//JCAgAAA3nrrLSZPnszIkSPR6/W89NJLeHh48NdffxEbG5sjviNHjmg/x8XFaT8nJyej0+ly3UbcdGu+Cov09HSbja1Tt75Vo4j666+/GDNmDDt27OD8+fOYzWauXbvG+vXriYuLY9++fWzZskXrv2/fPurWrcuePXuoW7durmPmdibLz8+PGkNWkukglwvvxqBXjK9vZvQuPUazXM65G8mXdSRf1itMOTsQFUKFChUYMmSIxQveDz/8kBUrVnDgwAGuX79OyZIl+eabbwgLC9P69O7dmzNnzrBu3TqOHTtG9erV2bNnD0888YTWJzQ0lIoVKzJv3jyL/f7777+4urqi0+nw8vJi2bJlvPrqqzni+/vvv6lWrRrTp0+nd+/eODg4ANC8eXPq1KljcUlT3GQymYiLi6NFixZavgqLtLQ0SpYsSWpqKu7u7vk69mNxJqtVq1b4+/uzcOFCfH19MZvN1KxZk4yMjPse02AwYDAYcrQbzToyZQ7IPTOadQU+/+NRIvmyjuTLeoUhZw4ODqSnp+Pg4GDxhOzo6IhSCgcHB65fv47JZMLR0dGij4ODg9Yn+zKQwWCw6GNvb6/1vVW5cuWAm1c7nJycePHFF3MtCKpUqYKPjw9//PGHFmNaWho7d+6kX79+ha6IKExu/50WBjaNRxVx58+fV4D65ZdftLb//Oc/ClBr165Vn3zyifLy8lLXr1/X1i9YsEABas+ePfe8n9TUVAWo8+fP52f4RVZGRoaKiYlRGRkZBR3KI0HyZR3Jl/UKW866dOmiypYtq9atW6eOHz+u1qxZo0qWLKmGDh2q9WnatKl64okn1NatW9Xff/+tFi1apJycnNTHH3+slLp5TJUqVVLPPvus2rFjhzp69KiaNm2a0ul0av369do4c+bMUbt371aJiYlq7ty5ytnZWc2aNcsinqpVq6o1a9Zoyx988IFydXVVq1evVn/88Ydq3bq1CgwMtHguEf+vsD2+bpX9/J2amprvYxf5IisrK0t5eXmpN998U/31119q8+bN6umnn9aKrCtXrqiSJUuqN998Ux08eFCtX79eVapUSYosGyvMf3CFkeTLOpIv6xW2nKWlpal33nlHlS9fXjk5OakKFSqokSNHKqPRqPVJTk5WkZGRytfXVzk5OamqVauqjz76SJnNZq3Pn3/+qdq2bau8vb2Vi4uLql27tlq6dKnFvjp16qQ8PT2Vo6NjruuVUgpQixYt0paNRqNq3769Kl26tDIYDKp58+YqMTEx/xNRRBS2x9etbFlkFfnLhXq9npUrV/L2229Ts2ZNqlatyuzZs7W377q5ufHDDz/Qp08f6tWrR40aNZg8eXKOyfJCCCEenmLFijFz5kxmzpyZZx8fHx8WLVp0x3EqV66c4w7vt1u6dOld41G3TV/W6XS88cYbLFu2rNBd/hKFR5EvsgCCg4M5dOiQRdutfzDPPPNMjo/Quf0PSgghhBDCGnLHdyGEEEIIG5AiSwghhBDCBqTIEkIIIYSwASmyhBBCCCFsQIosIYQQQggbkCJLCCGEEMIGpMgSQgghhLABKbKEEEIIIWxAiiwhhBBCCBuQIksIIYQQwgakyBJCCCGEsAEpsoQQQgghbECKLCGEEPclKyuL0aNHExgYiLOzMxUrVmT8+PEopQAwmUwMGzaMWrVq4erqiq+vL507dyYpKclinD///JPWrVtTsmRJ3N3dCQoKYuvWrRZ9EhISaN68OR4eHpQoUYKQkBD27dt3x/hu3LhB//798fLyws3NjXbt2vHvv//mbxKEuAMpsoQQQtyXyZMnM3/+fObOncvhw4eZPHkyU6ZMYc6cOQCkp6fz+++/M3r0aH7//XfWrFlDYmIiL7/8ssU4L730EpmZmWzZsoXdu3dTp04dXnrpJVJSUgC4evUqoaGhlC9fnh07dvDrr79SrFgxQkJCMJlMecb37rvv8sMPP/DNN9/w888/k5SURNu2bW2XECFuY1/QAQghhHg0bd++ndatWxMeHg5AQEAAX331FTt37gSgePHixMXFWWwzd+5cGjRowKlTpyhfvjznz5/nr7/+4vPPP6d27doATJo0iY8//pgDBw7g4+PDkSNHuHjxIuPGjcPPzw+AsWPHUrt2bU6ePEmlSpVyxJaamsrnn3/OihUreOGFFwBYtGgR1atX57///S/PPPOMzfIiRDYpsvJZw4mbybR3LegwCj2DnWJKA6gZ9SPGLF1Bh1PoSb6sI/mynrU5OzEpnMaNG/Ppp5/y559/UqVKFfbt28evv/7K9OnT89wuNTUVnU6Hh4cHAF5eXlStWpWlS5fy5JNPYjAY+OSTT/D29uapp54CoGrVqnh5efH555/z/vvvk5WVxeeff0716tUJCAjIdT+7d+/GZDIRHBystVWrVo3y5csTHx8vRZZ4KKTI+p8TJ04QGBiYo71p06Zs27bt4QckhBCF3PDhw0lLS6NatWrY2dmRlZXFBx98QERERK79b9y4wbBhw3j99ddxd3cHQKfT8dNPP9GmTRuKFSuGXq/H29ubjRs3UqJECQCKFSvGtm3baNOmDePHjwegcuXK/Pjjj9jb5/40lpKSgqOjo1bMZStdurR2GVIIW5Mi63/8/PxITk7WllNSUggODua5557Ltb/RaMRoNGrLaWlpABj0Cjs7ZdtgiwCDXll8F3cm+bKO5Mt61ubMZDLx9ddfs3z5cpYuXUqNGjXYt28fgwcPxtvbm86dO+fo3759e8xmM7Nnz9bmUiml6Nu3L6VKlWLr1q04OzvzxRdf0KpVK7Zv306ZMmW4fv063bp1o1GjRnz55ZdkZWUxffp0wsLCiI+Px9nZOUd8mZmZ2n5vpZQiKyvrjnO57vX4cxtf5K4w58uWMelU9ttAhObGjRs0a9aMUqVK8d1336HX53x/QFRUFNHR0TnaV6xYgYuLy8MIUwghClT37t1p164dYWFhWtuqVav4+eefmTdvntaWmZnJ1KlT+ffffxk3bpx2Fgtg3759REdHs2zZMov/nX379iU4OJh27doRFxfHsmXLWLRokfb/2GQy8eabbzJgwACeffbZHLH98ccfjBkzhmXLluHm5qa19+zZk1atWuWYfC8eX+np6bzxxhukpqZaPDbzg5zJykW3bt24cuUKcXFxuRZYACNGjGDQoEHaclpaGn5+fkzYoyfTwe5hhfrIMugV4+ubGb1Lj9Esc2buRvJlHcmX9azN2YGoEJRS1KpVy6LI2r9/Pzt37tTaTCYTr7/+OleuXOG3336jVKlSFuOYzWYAQkNDLYohNzc3KleuTFhYGMePH8fZ2Znw8HB0upuxZWZmYm9vT+3atS32n61JkyaMHz8ee3t7bX1iYiLnzp2ja9euNGzY0MoMWTKZTMTFxdGiRQscHBweaKzHQWHOV/aVKJtQwsL48eOVp6enOnr0qFXbpaamKkCdP3/eRpEVLRkZGSomJkZlZGQUdCiPBMmXdSRf1rufnHXp0kWVLVtWrVu3Th0/flytWbNGlSxZUg0dOlQb8+WXX1blypVTe/fuVcnJydqX0WhUSil17tw55eXlpdq2bav27t2rEhMT1eDBg5WDg4Pau3evUkqpw4cPK4PBoPr27asOHTqkDhw4oN58801VvHhxlZSUpJRS6p9//lFVq1ZVO3bs0OLr06ePKl++vNqyZYvatWuXatSokWrUqFGB5etxVpjzlf38nZqamu9jy5msW6xevZpx48axYcMGKlasWNDhCCFEoTZnzhxGjx5Nv379OHv2LL6+vvTu3ZsxY8YAcObMGb7//nsA6tata7Ht1q1badasGSVLlmTjxo2MHDmSF154AZPJxBNPPMF3331HnTp1gJvvCvzhhx+Ijo6mUaNG6PV66tWrx8aNGylTpgxw80xJYmIi6enp2j5mzJiBXq+nXbt2GI1GQkJC+Pjjjx9CZoS4SYqs/zlw4ACdO3dm2LBhPPHEE9q7TxwdHfH09Czg6IQQovApVqwYM2fOZObMmbmuDwgI0O7+fif169fnxx9/vGOfFi1a0KJFizzX57YvJycn5s2bZzE/TIiHSe74/j+7du0iPT2dCRMmUKZMGe1L7g4shBBCiPshRdb/REZGopTK8SX3yBJCCCHE/ZAiSwghhBDCBqTIEkIIIYSwASmyhBBCCCFsIN+KrMuXL+fXUEIIIYQQj7z7KrImT57M119/rS23b98eLy8vypYty759+/ItOCGEEEKIR9V9FVkLFizAz88PgLi4OOLi4tiwYQMvvvgiQ4YMydcAhRBCCCEeRfd1M9KUlBStyFq3bh3t27enZcuWBAQEPPDnQQkhhBBCFAX3dSarRIkSnD59GoCNGzcSHBwMgFKKrKys/ItOCCGEEOIRdV9nstq2bcsbb7xB5cqVuXDhAi+++CIAe/bsoVKlSvkaoBBCCCHEo+i+iqwZM2YQEBDA6dOnmTJlCm5ubgAkJyfTr1+/fA1QCCGEEOJRdF9FloODA4MHD87R/u677z5wQEIIIYQQRcF93yfryy+/JCgoCF9fX06ePAnAzJkz+e677/ItOCGEEEKIR9V9FVnz589n0KBBvPjii1y+fFmb7O7h4cHMmTPzMz4hhBAFICsri9GjRxMYGIizszMVK1Zk/PjxKKW0PkopxowZQ5kyZXB2diY4OJi//vor1/GMRiN169ZFp9Oxd+9ei3VKKaZNm0aVKlUwGAyULVuWDz744I7xXbx4kYiICNzd3fHw8KB79+5cvXr1gY9biPx0X0XWnDlzWLhwISNHjsTOzk5rr1+/Pvv378+34IQQQhSMyZMnM3/+fObOncvhw4eZPHkyU6ZMYc6cOVqfKVOmMHv2bBYsWMCOHTtwdXUlJCSEGzdu5Bhv6NCh+Pr65rqvd955h88++4xp06Zx5MgRvv/+exo0aHDH+CIiIjh48CBxcXGsW7eOX375hV69ej3YQQuRz+5rTtbx48epV69ejnaDwcC1a9ceOCghhBAFa/v27bRu3Zrw8HAAAgIC+Oqrr9i5cydw8+zTzJkzGTVqFK1btwZg6dKllC5dmpiYGDp27KiNtWHDBjZt2sTq1avZsGGDxX4OHz7M/PnzOXDgAFWrVgUgMDDwjrEdPnyYjRs3kpCQQP369YGbL/7DwsKYNm1ansWcEA/bfRVZgYGB7N27F39/f4v2jRs3Ur169XwJ7GE6d+4ctWrV4u233+b9998Hbv6DadasGRs2bKB58+b3PFbDiZvJtHe1VahFhsFOMaUB1Iz6EWOWrqDDKfQkX9aRfFkvO2fZGjduzKeffsqff/5JlSpV2LdvH7/++ivTp08Hbr7YTklJ0e6TCFC8eHEaNmxIfHy8VmT9+++/9OzZk5iYGFxcXHLs94cffqBChQqsW7eO0NBQlFIEBwczZcoUPD09c401Pj4eDw8PrcACCA4ORq/Xs2PHDl555ZX8SIkQD+y+iqxBgwbRv39/bty4gVKKnTt38tVXXzFx4kQ+++yz/I7R5kqVKsUXX3xBmzZtaNmyJVWrVqVTp04MGDDAqgJLCCGKiuHDh5OWlka1atWws7MjKyuLDz74gIiICODmJ38AlC5d2mK70qVLa+uUUkRGRtKnTx/q16/PiRMncuzn77//5uTJk3zzzTcsXbqUrKws3n33XV599VW2bNmSa2wpKSl4e3tbtNnb2+Pp6antW4jC4L6KrB49euDs7MyoUaNIT0/njTfewNfXl1mzZlmcIn6UhIWF0bNnTyIiIqhfvz6urq5MnDgxz/5GoxGj0agtp6WlAWDQK+zsVF6bif8x6JXFd3Fnki/rSL6sl50rk8kEwNdff83y5ctZunQpNWrUYN++fQwePBhvb286d+5MZmam1j97GwCz2YxOp8NkMjF37lzS0tIYPHiwRb9bf87MzMRoNPL5559TpUoVAD755BMaNmxocQnxVllZWSilLPZ767rc2vPbrcci7q4w58uWMVldZGVmZrJixQpCQkKIiIggPT2dq1ev5nhV8SiaNm0aNWvW5JtvvmH37t0YDIY8+06cOJHo6Ogc7aPqmXFxkY8Wulfj65sLOoRHiuTLOpIv68XFxQEwcOBA2rVrR7FixTh9+jSenp6EhoYyduxYSpYsqZ0xWr16NRUqVNC2P3LkCIGBgcTGxrJy5Up27dqFq6vlFIpnnnmGpk2b8s4773D16lXs7Ow4evQoR48eBdBewK5evZq6devmiPHs2bMkJSURGxurtWVlZXHhwgXOnDlj0W5r2fkS96Yw5is9Pd1mY1tdZNnb29OnTx8OHz4MgIuLS67X2R9Fx44dIykpCbPZzIkTJ6hVq1aefUeMGMGgQYO05bS0NPz8/JiwR0+mg12e24mbDHrF+PpmRu/SYzTLnJm7kXxZR/JlveyctWjRAgcHB5RS1KpVi7CwMK3P/v372blzJ2FhYSiliIqKwmQyaX3S0tI4evQow4cPJywsjJo1a2pn+eHmp4KEh4ezYsUKGjRoQLly5XBwcODrr7+matWqVKxYEYB9+/YB8Oqrr2pnt24VGBjI3Llz8fHx4cknnwRuPnkrpejTp89DmfhuMpmIi4vT8iXurDDn69bHaL5T96Fp06Zq7dq197NpoWU0GlWdOnVUly5d1Icffqi8vb3Vv//+e8/bp6amKkCdP3/ehlEWHRkZGSomJkZlZGQUdCiPBMmXdSRf1rs9Z126dFFly5ZV69atU8ePH1dr1qxRJUuWVEOHDtW2mTRpkvLw8FDfffed+uOPP1Tr1q1VYGCgun79eq77OH78uALUnj17tLasrCz15JNPqueee079/vvvateuXaphw4aqRYsWWp8dO3aoqlWrqn/++UdrCw0NVfXq1VM7duxQv/76q6pcubJ6/fXX8zkreZPHmHUKc76yn79TU1Pzfez7mpPVr18/3nvvPf755x+eeuqpHKeCa9eu/eDV30M2cuRIUlNTmT17Nm5ubsTGxtKtWzfWrVtX0KEJIcRDN2fOHEaPHk2/fv04e/Ysvr6+9O7dmzFjxmh9hg4dyrVr1+jVqxeXL18mKCiIjRs34uTkdM/70ev1/PDDD7z11ls899xzuLq68uKLL/LRRx9pfdLT00lMTLSYO7N8+XLtzUl6vZ527doxe/bs/Dl4IfLJfRVZ2ZPb3377ba1Np9OhlEKn02l3gH9UbNu2jZkzZ7J161bc3d2Bmx8bVKdOHebPn0/fvn0LOEIhhHi4ihUrxsyZM+/4KR46nY5x48Yxbty4exozICDA4o7x2Xx9fVm9enWe2zVr1izHdp6enqxYseKe9itEQbnvm5EWJc2aNcvx7oKAgABSU1MLKCIhhBBCPOruq8i6/SakQgghhBDC0n0VWUuXLr3j+s6dO99XMEIIIYQQRcV9FVnvvPOOxbLJZCI9PR1HR0dcXFykyBJCCCHEY09/PxtdunTJ4uvq1askJiYSFBTEV199ld8xCiGEEEI8cu6ryMpN5cqVmTRpUo6zXEIIIYQQj6N8K7Lg5t3gk5KS8nNIIYQQQohH0n3Nyfr+++8tlpVSJCcnM3fuXJo0aZIvgQkhhBBCPMruq8hq06aNxbJOp6NUqVK88MILFnfpFUIIIYR4XN1XkWU2yyfbCyGEEELcyX3NyRo3bhzp6ek52q9fv37PH68ghBBCCFGU3VeRFR0dzdWrV3O0p6enEx0d/cBBCSGEEEI86u6ryMr+IOjb7du3D09PzwcOSgghhBDiUWdVkVWiRAk8PT3R6XRUqVIFT09P7at48eK0aNGC9u3b2ypWIYQQNpaVlcXo0aMJDAzE2dmZihUrMn78eJRSWh+lFGPGjKFMmTI4OzsTHBzMX3/9ZTHOBx98QOPGjXFxccHDwyPHfvbt28frr7+On58fzs7OVK9enVmzZt01vosXLxIREYG7uzseHh5079491ysrQhQGVk18nzlzJkopunXrRnR0NMWLF9fWOTo6EhAQQKNGjfI9yIdt27ZtPP/881y6dCnXfw5CCFFUTZ06lfnz57NkyRKeeOIJdu3aRdeuXSlevDhvv/02AFOmTGH27NksWbKEwMBARo8eTUhICIcOHcLJyQmAjIwMXnvtNRo1asTnn3+eYz+7d+/G29ubZcuW4efnx/bt2+nVqxd2dnYMGDAgz/giIiJITk4mLi4Ok8lE165d6dWrFytWrLBNQoR4AFYVWV26dAEgMDCQxo0b4+DgYJOgbKlZs2bUrVuXmTNnFnQoQghR6Pz3v/+ldevWhIeHAxAQEMBXX33Fzp07gZtnsWbOnMmoUaNo3bo1AEuXLqV06dLExMTQsWNHAG1+7uLFi3PdT7du3SyWK1SoQHx8PGvWrMmzyDp8+DAbN24kISGB+vXrAzBnzhzCwsKYNm0avr6+D3bwQuSz+5qT1bRpU63AunHjBmlpaRZfQgghHk3PPPMMmzdv5s8//wRuXtb79ddfefHFFwE4fvw4KSkpBAcHa9sUL16chg0bEh8f/0D7Tk1NveO83vj4eDw8PLQCCyA4OBi9Xs+OHTseaN9C2MJ93ScrPT2doUOHsmrVKi5cuJBjfVZW1gMHZguRkZH8/PPP/Pzzz9q1/+PHj3Po0CEGDhzI6dOneeaZZ7Qzdvej4cTNZNq75lfIRZbBTjGlAdSM+hFjVs43UQhLki/rSL6sl52zoUOHcu3aNapVq4adnR1ZWVl88MEHREREAJCSkgJA6dKlLbYvXbq0tu5+bN++na+//pr169fn2SclJQVvb2+LNnt7ezw9PR9o30LYyn0VWUOGDGHr1q3Mnz+fTp06MW/ePM6cOcMnn3zCpEmT8jvGfDNr1iz+/PNPatasqd3Py2g00rZtW/r370+vXr3YtWsX77333l3HMhqNGI1GbTn7DJ5Br7CzU3ltJv7HoFcW38WdSb6sI/myXnauVq5cyfLly1m6dCk1atRg3759DB48GG9vbzp37kxmZiYAJpMJk8mkbW82m9HpdBZt8P8vum9vv9WBAwdo3bo1o0aN4vnnn8+zb1ZWFkqpXNdnZWXdcR/5LXtfD3Ofj7LCnC9bxnRfRdYPP/zA0qVLadasGV27duXZZ5+lUqVK+Pv7s3z5cu0VT2FTvHhxHB0dcXFxwcfHB4D333+fihUrah8HVLVqVfbv38/kyZPvONbEiRNzvSfYqHpmXFwK55m8wmh8ffn0AGtIvqwj+bLee++9R7t27ShWrBinT5/G09OT0NBQxo4dS8mSJbUzRqtXr6ZChQradkeOHCEwMJDY2FiL8fbt24fJZMrRnu306dOMGjWKFi1aULdu3Tz7AZw9e5akpCSLPllZWVy4cIEzZ87ccVtbiYuLe+j7fJQVxnzldnP1/HJfRdbFixe1Py53d3cuXrwIQFBQEH379s2/6B6Cw4cP07BhQ4u2e3mH5IgRIxg0aJC2nJaWhp+fHxP26Ml0sMv3OIsag14xvr6Z0bv0GM1yOeduJF/WkXxZLztnSilq1apFWFiYtm7//v3s3LmTsLAwlFJERUVhMpm0PmlpaRw9epThw4dbbAdw/vx5HBwccrQDHDx4kF69etG9e/d7ugoSGBjI3Llz8fHx4cknnwRuPmkrpejTp89DnfhuMpmIi4ujRYsWj+SbwB62wpwvW84lv68iq0KFChw/fpzy5ctTrVo1Vq1aRYMGDfjhhx8em1seGAwGDAZDjnajWUemzAG5Z0azTubMWEHyZR3Jl/XCw8OZNGkSgYGBPPHEE+zZs4dZs2bRrVs37clx4MCBTJw4kWrVqmm3cPD19eXVV1/V+pw6dYqLFy9y5swZsrKyOHjwIACVKlXCzc2NAwcO0LJlS0JCQhgyZIg2v9fOzo5SpUoBsHPnTjp37szmzZspW7YstWvXJjQ0lL59+7JgwQJMJhMDBw6kY8eO+Pv7F0C2wMHBodAVDYVZYcyXTeNR92H69Olq1qxZSiml4uLilJOTkzIYDEqv16uZM2fez5APTYsWLdSAAQO05REjRqgnnnjCos/w4cMVoC5dunTP46ampipAnT9/Pr9CLdIyMjJUTEyMysjIKOhQHgmSL+tIvqyXnbMLFy6od955R5UvX145OTmpChUqqJEjRyqj0aj1NZvNavTo0ap06dLKYDCo5s2bq8TERIvxunTpooAcX1u3blVKKTV27Nhc1/v7+2tjbN26VQHq+PHjWtuFCxfU66+/rtzc3JS7u7vq2rWrunLlii1Tkyt5jFmnMOcr+/k7NTU138fWKaUeeGboyZMn2b17N5UqVaJ27doPOpxN9erVi71797Jq1Src3NxIT0+ncuXKvP322/To0YPdu3fz3nvvkZKSYtXNSNPS0ihevDjnz5/Hy8vLtgdRBGTP0QgLCyt0r2oKI8mXdSRf1pOcWUfyZZ3CnK/s5+/U1FTc3d3zdez7uk/WrW7cuIG/vz9t27Yt9AUWwODBg7Gzs6NGjRqUKlUKs9nM6tWriYmJoU6dOixYsIAPP/ywoMMUQgghxCPuvoqsrKwsxo8fT9myZXFzc+Pvv/8GYPTo0bl+fEJhUqVKFeLj40lPT0cpRUBAAC+99BJ//fUXN27c4JdffqFr164opR6b+WVCCCGEyH/3VWR98MEHLF68mClTpuDo6Ki116xZk88++yzfghNCCCGEeFTdV5G1dOlSPv30UyIiIrCz+//bFdSpU4cjR47kW3BCCCGEEI+q+yqyzpw5Q6VKlXK0m83mQnk3VyGEEEKIh+2+iqwaNWrwn//8J0f7t99+S7169R44KCGEEEKIR9193Yx0zJgxdOnShTNnzmA2m1mzZg2JiYksXbqUdevW5XeMQgghhBCPHKvOZP39998opWjdujU//PADP/30E66urowZM4bDhw/zww8/0KJFC1vFKoQQQgjxyLDqTFblypVJTk7G29ubZ599Fk9PT/bv30/p0qVtFZ8QQgghxCPJqjNZt98cfsOGDVy7di1fAxJCCCGEKAoe6I7v+fCJPEIIIYQQRZJVRZZOp0On0+VoE0IIIYQQlqyak6WUIjIyEoPBANz83MI+ffrg6upq0W/NmjX5F6EQQgghxCPIqiKrS5cuFstvvvlmvgYjhBBCCFFUWFVkLVq0yFZxCCGEKCABAQGcPHkyR3u/fv2YN28ex44dY/Dgwfz6668YjUZCQ0OZM2eOxTvLX375Zfbu3cvZs2cpUaIEwcHBTJ48GV9f3xzjHj16lHr16mFnZ8fly5fvGNupU6fo27cvW7duxc3NjS5dujBx4kTs7e/rNo9CPFQPNPFdCCHEoy8hIYFTp06xaNEiTp06RVxcHACvvfYa165do2XLluh0OrZs2cJvv/1GRkYGrVq1wmw2a2M8//zzrFq1isTERFavXs2xY8d49dVXc+zLZDLx+uuv8+yzz941rqysLMLDw8nIyGD79u0sWbKExYsXM2bMmPw7eCFsSF4KCCHEY65UqVKYTCZKlCiBj48PH330ERUrVqRp06bExcVx4sQJ9uzZg7u7OwBLliyhRIkSbNmyheDgYADeffddbTx/f3+GDx9OmzZtMJlMODg4aOtGjRpFtWrVaN68Odu3b79jXJs2beLQoUP89NNPlC5dmrp16zJ+/HiGDRtGVFQUjo6ONsiGEPlHiqx81nDiZjLtXe/e8TFnsFNMaQA1o37EmCXvUL0byZd1JF/37sSkcIvljIwMli1bxqBBg9DpdBiNRnQ6nfaGJwAnJyf0ej2//vqrVmTd6uLFiyxfvpzGjRtbFFhbtmzhm2++Ye/evff0Bqn4+Hhq1aplcVkyJCSEvn37cvDgQfmsXFHoyeVCYOnSpXh5eWE0Gi3a27RpQ6dOnQooKiGEePi+++47Ll++TGRkJADPPPMMrq6uDBs2jPT0dK5du8bgwYPJysoiOTnZYtthw4bh6uqKl5cXp06d4rvvvtPWXbhwgcjISBYvXqydEbublJSUHJ8okr2ckpLyAEcpxMMhZ7K4Oe/g7bff5vvvv+e1114D4OzZs6xfv55Nmzbluo3RaLQoytLS0gAw6BV2dnKT1rsx6JXFd3Fnki/rSL7unclksvj+xRdfEBISol1C9PDw4KuvvuKtt95i9uzZ6PV6OnTooJ1Fyt4OYODAgXTu3JlTp04xYcIEOnXqRExMDDqdju7du9OhQwcaNWqEyWQiKysrx/a3M5vNKKUs+mT/nJmZecdtbe32vIk7K8z5smVMOiW3bQduvovmxIkTxMbGAjB9+nTmzZvH0aNHc73halRUFNHR0TnaV6xYgYuLi83jFUKI/Hb27Fn69OnDsGHDaNiwYY71aWlp6PV63NzciIyMpHXr1rzyyiu5jnX+/Hl69OjBpEmTqFatGm+88QY3btyw6GM2m9Hr9fTr1y/Xy44rVqxg586dzJw5U2v7999/6d27N9OnT6dChQoPdsBCAOnp6bzxxhukpqbe81nWeyVF1v/s2bOHp59+mpMnT1K2bFlq167Na6+9xujRo3Ptn9uZLD8/P2oMWUmmg8zJuhuDXjG+vpnRu/QYzTJn5m4kX9aRfN27A1EhwM1X8926dWPbtm0cP378jrdI2Lp1K6Ghofzxxx9UrVo11z6nTp2iUqVKxMXF0bRpUw4fPqydvQL44YcfmDZtGj///DNly5alRIkSOcbYuHEjbdq04dSpU3h7ewPw2WefMXz4cM6cOWMxT+xhM5lMxMXF0aJFC4t5ZyJ3hTlfaWlplCxZ0iZFllwu/J969epRp04dli5dSsuWLTl48CDr16/Ps7/BYMj1D/yXYcF4eXnZMtQiwWQyERsby+4xoYXuD64wknxZR/JlPbPZzJYtW+jSpQvOzs4W6xYtWkT16tUpVaoU8fHxvPPOO7z77rvUrFkTgB07dpCQkEBQUBAlSpTg2LFjjB49mooVK/Lss8/i4OBA7dq1Lcbct28fer3eYvL62rVrGTFiBEeOHAEgLCyMGjVq0K1bN6ZMmUJKSgpjx46lf//+uLm52Tgj98bBwUEeY1YojPmyZTxSZN2iR48ezJw5kzNnzhAcHIyfn19BhySEEA/F5s2bOXfunDbh/VaJiYmMGDGCixcvEhAQwMiRIy1u2eDi4sKaNWsYO3Ys165do0yZMoSGhjJq1CirzjalpqaSmJioLdvZ2bFu3Tr69u1Lo0aNcHV1pUuXLowbN+6BjlWIh0UuF94iNTUVX19fMjMzWbp0KR06dLjnbdPS0ihevDjnz5+XM1n3IPtMQ1hYWKF7VVMYSb6sI/mynuTMOpIv6xTmfGU/f9vicqHcwuEWxYsXp127dri5udGmTZuCDkcIIYQQjzApsm5z5swZIiIiCnRCpRBCCCEefTIn638uXbrEtm3b2LZtGx9//HFBhyOEEEKIR5wUWf9Tr149Ll26xOTJk/N8S7IQQgghxL2SIut/Tpw4UdAhCCGEEKIIkTlZQgghhBA2IEWWEEIIIYQNSJElhBBCCGEDUmQJIYQQQtiAFFlCCCGEEDYgRZYQQgghhA1IkSWEEEIIYQNSZAkhhBBC2IAUWUIIIYQQNlAoi6wTJ06g0+nYu3fvA48VEBDAzJkzH3gcIYQoSgICAtDpdNqXo6Mjbdq04e233wYgJSWFTp064ePjg6urK08++SSrV6/OdSyj0UjdunVz/N++ceMGkZGR1KpVC3t7e9q0aXNPsV28eJGIiAjc3d3x8PCge/fuXL169UEPWYiHrlAWWfkpISGBXr16acs6nY6YmJiCC0gIIQqBhIQEkpOTta8NGzYA0K5dOwA6d+5MYmIi33//Pfv376dt27a0b9+ePXv25Bhr6NCh+Pr65mjPysrC2dmZt99+m+Dg4HuOLSIigoMHDxIXF8e6dev45ZdfLP6PC/GoKLJFVkZGBgClSpXCxcWlgKMRQojCpVSpUvj4+GhfsbGx+Pj48NxzzwGwfft23nrrLRo0aECFChUYNWoUHh4e7N6922KcDRs2sGnTJqZNm5ZjH66ursyfP5+ePXvi4+NzT3EdPnyYjRs38tlnn9GwYUOCgoKYM2cOK1euJCkp6cEPXIiHqEA/INpsNjNt2jQ+/fRTTp8+TenSpenduzcREREW/bKysujVqxdbtmwhJSWF8uXL069fP9555x2tT2RkJJcvX+bpp59m3rx5GAwGjh8/TkBAAAMHDmTgwIEEBAQA8MorrwDg7+/Ptm3bqFChAjt37qR+/fraeDNnzmTGjBkcP34cvf7ea9GGEzeTae/6AFl5PBjsFFMaQM2oHzFm6Qo6nEJP8mUdydednZgUbrGckZHBihUrCA0NRae7ma/GjRvz9ddfEx4ejoeHB6tWreLGjRs0a9ZM2+7ff/+lZ8+exMTE5NuL2fj4eDw8PCz+HwcHB6PX69mxY4f2/1uIR0GBFlkjRoxg4cKFzJgxg6CgIJKTkzly5EiOfmazmXLlyvHNN9/g5eXF9u3b6dWrF2XKlKF9+/Zav82bN+Pu7k5cXFyu+0tISMDb25tFixYRGhqKnZ0dpUqVIjg4mEWLFln8US9atIjIyEirCiwhhHgUxcTEcPnyZZo3b661rVq1ig4dOuDl5YW9vT0uLi6sXbuWSpUqAaCUIjIykj59+lC/fn1OnDiRL7GkpKTg7e1t0WZvb4+npycpKSn5sg8hHpYCK7KuXLnCrFmzmDt3Ll26dAGgYsWKBAUF5fhjdXBwIDo6WlsODAwkPj6eVatWWRRZrq6ufPbZZzg6Oua6z1KlSgHg4eFhceq6R48e9OnTh+nTp2MwGPj999/Zv38/3333XZ7xG41GjEajtpyWlgaAQa+ws1P3mIXHl0GvLL6LO5N8WUfydWcmk8li+bPPPqNly5Z4enpq60aOHMmlS5fYuHEjXl5efP/997Rv354tW7ZQq1Yt5s6dS1paGoMHD8ZkMmnb3frzrcxmM2azOdd1t8rKykIplWu/rKysu27/sNx6vOLuCnO+bBlTgRVZhw8fxmg0WrxyupN58+bxxRdfcOrUKa5fv05GRgZ169a16FOrVq08C6w7adOmDf3792ft2rV07NiRxYsX8/zzz2uXF3MzceJEi8Iv26h6ZlxcsqyO4XE1vr65oEN4pEi+rCP5yl1sbKz289mzZ9m8eTPDhg0DIC4ujuTkZD7++GNmz57NjRs3OHPmDE899RT+/v68//779O3bl5UrV7Jr1y5cXS2nRzzzzDM0bdrUYjoHwD///MO1a9cs9p2bs2fPkpSUZNEvKyuLCxcucObMmbtu/7DldeVE5K4w5is9Pd1mYxdYkeXs7HzPfVeuXMngwYP56KOPaNSoEcWKFWPq1Kns2LHDot/tf+z3ytHRkc6dO7No0SLatm3LihUrmDVr1h23GTFiBIMGDdKW09LS8PPzY8IePZkOdvcVx+PEoFeMr29m9C49RrPMmbkbyZd1JF93diAqRPt53LhxeHt7M3z4cLZu3UqLFi20aRtNmzalevXqWt958+ZRrlw5wsLCqFmzpnYGHyA5OZnw8HBWrFhBgwYNKFeunMU+V69ezeXLlwkLC7tjbIGBgcydOxcfHx+efPJJ4OYTs1KKPn365PouxoJgMpmIi4ujRYsWODg4FHQ4hV5hztetj+P8VmBFVuXKlXF2dmbz5s306NHjjn1/++03GjduTL9+/bS2Y8eO3dd+HRwcyMrKeaapR48e1KxZk48//pjMzEzatm17x3EMBgMGgyFH+y/DgvHy8rqv2B4nJpOJ2NhYdo8JLXR/cIWR5Ms6kq97YzabWbp0KV26dNFe+Do4OFCrVi0qVarEgAEDmDZtGl5eXsTExPDTTz+xbt06HBwcqFixosVYJUqUAKBq1aoEBgZq7YcOHSIjI4PLly9z5coVDh48CKBdidi5cyedO3dm8+bNlC1bltq1axMaGkrfvn1ZsGABJpOJgQMH0rFjR/z9/R9CVqzj4OAgjzErFMZ82TKeAiuynJycGDZsGEOHDsXR0ZEmTZpw7tw5Dh48mOMSYuXKlVm6dCk//vgjgYGBfPnllyQkJFj8Id+rgIAANm/eTJMmTTAYDNo/hurVq/PMM88wbNgwunXrZtWZNiGEeBT99NNPnDp1im7dulm0Ozg4EBsby/Dhw2nVqhVXr16lUqVKLFmy5K5nom4XFhbGyZMnteV69eoBNyfOw81LNYmJiRbzYpYvX86AAQNo3rw5er2edu3aMXv27Ps9TCEKTIG+u3D06NHY29szZswYkpKSKFOmDH369MnRr3fv3uzZs4cOHTqg0+l4/fXX6devn3bzPGt89NFHDBo0iIULF1K2bFmLSfbdu3dn+/btOf7hCCFEUdSyZUut2Ll98m/lypXzvMN7bgICArSxbnW3dx02a9Ysx3aenp6sWLHinvctRGFVoEWWXq9n5MiRjBw5Mse6W//oDAYDixYtYtGiRRZ9Jk6cqP28ePHiXPdx+x94q1ataNWqVa59z5w5Q61atXj66afv8QiEEEIIIXInN4ECrl69yoEDB5g7dy5vvfVWQYcjhBBCiCJAiixgwIABPPXUUzRr1kwuFQohhBAiXxTo5cLCYvHixXlebhRCCCGEuB9yJksIIYQQwgakyBJCCCGEsAEpsoQQQgghbECKLCGEEEIIG5AiSwghhBDCBqTIEkIIIYSwASmyhBBCCCFsQIosIYQQQggbkCJLCCGEEMIGpMgSQohCKiAgAJ1Ol+Orf//+XLx4kbfeeouqVavi7OxM+fLlefvtt0lNTdW2v3DhAqGhofj6+mIwGPDz82PAgAGkpaVZ7Gfbtm00aNCAV199lerVq9/TJ2D88ccfPPvsszg5OeHn58eUKVPy+/CFeOQV+Y/ViYyM5PLly8TExBR0KEIIYZWEhASysrK05QMHDtCiRQtee+01kpKSSEpKYtq0adSoUYOTJ0/Sp08fkpKS+PbbbwHQ6/W0bt2aCRMmUKpUKY4ePaoVaCtWrADg+PHjhIeH06tXL7p3705WVhY9evSgTJkyhISE5BpXWloaLVu2JDg4mAULFrB//366deuGh4cHvXr1sn1ihHhEFPkiSwghHlWlSpWyWJ40aRIVK1akadOm6HQ6Vq9era2rWLEiH3zwAW+++SaZmZnY29tTokQJ+vbtq/Xx9/enX79+TJ06VWtbsGABgYGBTJkyhdjYWMLCwoiPj2fGjBl5FlnLly8nIyODL774AkdHR5544gn27t3L9OnTpcgS4hZyufAulFJkZmYWdBhCiMdcRkYGy5Yto1u3buh0ulz7pKam4u7ujr197q+fk5KSWLNmDU2bNtXa4uPjCQ4OtugXEhJCfHx8nrHEx8fz3HPP4ejoaLFNYmIily5dsuawhCjSHokzWWazmWnTpvHpp59y+vRpSpcuTe/evRk5ciT79+/nnXfeIT4+HhcXF9q1a8f06dNxc3PLdSyj0ciQIUNYuXIlaWlp1K9fnxkzZvD0008DN+cmPP/888TGxjJq1Cj279/Ppk2baNas2T3F2nDiZjLtXfPr0Issg51iSgOoGfUjxqzcnzDE/5N8WedRz9eJSeE52mJiYrh8+TKRkZG5bnP+/HnGjx+f65mk119/ne+++47r16/TqlUrPvvsM21dSkoKpUuXtuhfunRp0tLSuH79Os7OzjnGS0lJITAwMMc22etKlChx12MU4nHwSBRZI0aMYOHChcyYMYOgoCCSk5M5cuQI165dIyQkhEaNGpGQkMDZs2fp0aMHAwYMyHPi5tChQ1m9ejVLlizB39+fKVOmEBISwtGjR/H09NT6DR8+nGnTplGhQoVc/2EYjUaMRqO2nD2R1KBX2Nmp/E1AEWTQK4vv4s4kX9Z51PNlMplytH322WeEhIRQqlSpHOvT0tIICwujevXqjBw5Msf6KVOm8P777/PXX38xatQoBg4cyJw5c4CbZ+uzsrK0bUwmk3b23mQy5XpWTCmF2Wy22M+t2+cWf1Fz6/GKuyvM+bJlTIW+yLpy5QqzZs1i7ty5dOnSBbg59yAoKIiFCxdy48YNli5diqvrzbNHc+fOpVWrVkyePDnHq7Nr164xf/58Fi9ezIsvvgjAwoULiYuL4/PPP2fIkCFa33HjxtGiRYs845o4cSLR0dE52kfVM+PikpXLFiI34+ubCzqER4rkyzqPar5iY2Mtls+ePcvmzZsZNmxYjnXXr18nKioKg8FA9+7diYuLy3NcOzs7OnXqxPvvv0/Dhg3x9PTE0dGRHTt2aNvFxcWxefNmXFxc2Lp1a67jZGZm8scff1jEsn//fu378ePH7+u4H0V3yrfIqTDmKz093WZjF/oi6/DhwxiNRpo3b57rujp16mgFFkCTJk0wm80kJibmKLKOHTuGyWSiSZMmWpuDgwMNGjTg8OHDFn3r169/x7hGjBjBoEGDtOW0tDT8/PyYsEdPpoOdVcf4ODLoFePrmxm9S4/R/OhdznnYJF/WedTzdSDKcsL5uHHj8Pb2ZvTo0RZnltLS0ggPD6d06dJ8//33uLi43HXsYsWKARAUFERAQAD/+c9/2LhxIy1atCAuLo4WLVrw1VdfERQURFhYWK5jnD59mjFjxtCiRQscHBwA2L59O1WqVKF9+/b3e9iPFJPJpOUrOwcib4U5X7ff0iQ/FfoiK7f5AA/DrYVbbgwGAwaDIUe70awj8xGcA1JQjGbdIzlnpqBIvqzzqObr1ichs9nM0qVL6dKli8X/w+wCKz09neXLl3P9+nWuX78O3HxXop2dHbGxsfz77788/fTTuLm5cfDgQYYMGUKTJk2oXLkyAP3792f+/PmMHj2aChUq8Pnnn/Ptt9+yfv16LY65c+eydu1aNm/eDECnTp2YMGECffr0YdiwYRw4cIC5c+cyY8aMQvcEamsODg6P3TE/iMKYL1vGU+iLrMqVK+Ps7MzmzZvp0aOHxbrsm+Zdu3ZNK4p+++039Ho9VatWzTFWxYoVcXR05LfffsPf3x+4WV0nJCQwcODAfIl3x4jmeHl55ctYRZnJZCI2NpYDUSGF7g+uMJJ8Waco5eunn37i1KlTdOvWzaL9999/Z8eOHQBUqlTJYt3x48cJCAjA2dmZhQsX8u6772I0GvHz86Nt27YMHz5c6xsYGMj69esZOHAgs2fPpnz58tr8r2znz5/n2LFj2nLx4sXZtGkT/fv356mnnqJkyZKMGTNGbt8gxG0KfZHl5OTEsGHDGDp0KI6OjjRp0oRz585x8OBBIiIiGDt2LF26dCEqKopz587x1ltv0alTpxyXCuHm2am+ffsyZMgQPD09KV++PFOmTCE9PZ3u3bsXwNEJIcSdtWzZEqVyTuBv1qxZru23ev7559m+fftd99GsWTMSEhK0+2TdXphGRUURFRVl0Va7dm3+85//3P0AhHiMFfoiC9DmIYwZM4akpCTKlClDnz59cHFx4ccff+Sdd97h6aeftriFQ14mTZqE2WymU6dOXLlyhfr16/Pjjz/KW46FEEIIka8eiSJLr9czcuRIRo4cmWNdrVq12LJlS57b3n4rBycnJ2bPns3s2bNz7X8vrw6FEEIIIe5G7vguhBBCCGEDUmQJIYQQQtiAFFlCCCGEEDYgRZYQQgghhA1IkSWEEEIIYQNSZAkhhBBC2IAUWUIIIYQQNiBFlhBCCCGEDUiRJYQQQghhA1JkCSGEEELYgBRZQgghhBA2IEWWEEIIIYQNSJElhLgvkyZNQqfTMXDgQK0tJSWFTp064ePjg6urK08++SSrV6/W1p84cYLu3bsTGBiIs7MzFStWZOzYsWRkZGh9EhMTef755yldujROTk5UqFCBUaNGYTKZ7hjPqVOnCA8Px8XFhbJly7J48WIyMzPz/biFEOJe2Rd0APktMjKSy5cvExMTk2efZs2aUbduXWbOnPnQ4hKiKElISOCTTz6hdu3aFu2dO3fm8uXLfP/995QsWZIVK1bQvn17du3aRb169Thy5Ahms5lPPvmESpUqceDAAXr27Mm1a9eYNm0aAA4ODnTu3Jknn3wSDw8P9u3bR8+ePTGbzXz44Ye5xpOVlUV4eDg+Pj5s376d06dP8+abbxIVFcXkyZNtng8hhMhNoS6ypBgSovC5evUqERERLFy4kAkTJlis2759O/Pnz6dBgwYAjBo1ihkzZrB7927q1atHaGgooaGhWv8KFSqQmJjI/PnztSKrQoUKVKhQQevj7+/Ptm3b+M9//pNnTJs2beLQoUP89NNPlC5dmieeeII33niDBQsWMH78eBwdHfMzBUIIcU8KdZH1KGo4cTOZ9q4FHUahZ7BTTGkANaN+xJilK+hwCr3CkK8Tk8IB6N+/P+Hh4QQHB+cosho3bszXX39NeHg4Hh4erFq1ihs3btCsWbM8x01NTcXT0zPP9UePHmXjxo20bds2zz7x8fHUqlWL0qVLa2316tVjwYIFHDx4kHr16t3jUQohRP4ptHOyIiMj+fnnn5k1axY6nQ6dTsexY8cs5nNUrVqVWbNm5bp9dHQ0pUqVwt3dnT59+ljM+bid0Whk8ODBlC1bFldXVxo2bMi2bdtsdGRCPLpWrlzJ77//zsSJE3Ndv2rVKkwmE15eXhgMBnr37s3atWupVKlSrv2PHj3KnDlz6N27d451jRs3xsnJicqVK/Pss88ybty4PONKSUmxKLAAPDw8tHVCCFEQCu2ZrFmzZvHnn39Ss2ZN7Z9riRIlKFeuHN988w1eXl5s376dXr16UaZMGdq3b69tu3nzZpycnNi2bRsnTpyga9eueHl58cEHH+S6rwEDBnDo0CFWrlyJr68va9euJTQ0lP3791O5cuVctzEajRiNRm05LS0NAINeYWen8isNRZZBryy+izsrDPn6+++/eeedd4iNjcXOzg6TyYRSCrPZrE1KHzlyJJcuXWLjxo14eXnx/fff0759e7Zs2UKtWrUsxjtz5gyhoaG0a9eOyMjIHBPbly1bxpUrV/jjjz8YMWIEkydPZvDgwbnGZjabUUppY9w6VmZm5l0nzQtyzZ3Im+TLOoU5X7aMSaeUKrTPcvcyJ2vAgAGkpKTw7bffAjfPgP3www+cPn0aFxcXABYsWMCQIUNITU1Fr9dbjHvq1CkqVKjAqVOn8PX11cYNDg6mQYMGeU60jYqKIjo6Okf7ihUrtP0KUZT897//ZdKkSej1/38C3Gw2a2ea582bR9++fZk9ezbly5fX+owZM4YyZcrQt29fre3ixYuMGjWKKlWq8Pbbb1uMmZtt27bx8ccf89VXX2FnZ5dj/YoVK9i5c6fF/4p///2X3r17M336dIs5XkIIcav09HTeeOMNUlNTcXd3z9exC+2ZrLzMmzePL774glOnTnH9+nUyMjKoW7euRZ86depYFDqNGjXi6tWrnD59Gn9/f4u++/fvJysriypVqli0G41GvLy88oxjxIgRDBo0SFtOS0vDz8+PCXv0ZDrkfBIQlgx6xfj6Zkbv0mM0y5ysuykM+YofMsTijDFAz549qVq1KoMHDyb79VrTpk2pXr261mfevHmUK1eOsLAw4OYZrBYtWhAUFMSSJUtyLZpud+HCBcxmM6GhoTg4OORYr9fr+fbbb6lfvz7e3t6YTCYGDx6Mu7s7PXv2xGAwPMihPxZMJhNxcXG0aNEi1xwLS5Iv6xTmfGVfibKFR6rIWrlyJYMHD+ajjz6iUaNGFCtWjKlTp7Jjx477HvPq1avY2dmxe/fuHP/s3dzc8tzOYDDk+o/7l2HBdyzOxE0mk4nY2Fh2j8n9SVNYKiz5un2CupubG6VKlaJevXqYTCYqVarEgAEDmDZtGl5eXsTExPDTTz+xbt06HBwctALL39+f6dOnc/nyZW0sHx8fAJYvX46DgwO1atXCYDCwa9cuRo8eTYcOHbQXT2vXrmXEiBEcOXIEgLCwMGrUqEG3bt2YMmUK//zzDytWrKBPnz53/DsWOTk4OMjfpBUkX9YpjPmyZTyFushydHQkKytLW/7tt99o3Lgx/fr109qOHTuWY7t9+/Zx/fp1nJ2dgZuXOdzc3PDz88vRt169emRlZXH27FmeffZZGxyFEI8HBwcHYmNjGT58OK1ateLq1atUqlSJJUuWaGex4uLiOHr0KEePHqVcuXIW22efCbO3t2fy5Mn8+eefKKXw9/dnwIABvPvuu1rf1NRUEhMTtWU7OzvWrVtH3759adSoEa6urjRr1oyoqCjbH7gQQuShUBdZAQEB7NixgxMnTuDm5kblypVZunQpP/74I4GBgXz55ZckJCQQGBhosV1GRgbdu3dn1KhRnDhxgrFjxzJgwIBc531UqVKFiIgIOnfuzEcffUS9evU4d+4cmzdvpnbt2oSHhz+swxXikXP7u3ArV65scYf320VGRhIZGXnHMTt06ECHDh3u2Ce3cfz9/YmNjQX+/8yfvX2h/hcnhCjiCu0tHAAGDx6MnZ0dNWrUoFSpUoSEhNC2bVs6dOhAw4YNuXDhgsVZrWzNmzencuXKPPfcc3To0IGXX375jq9oFy1aROfOnXnvvfeoWrUqbdq0ISEhwWLyrhBCCCGENQr1y7wqVaoQHx9v0bZo0SIWLVpk0XbrPXsWL16s/Zzbu/8g56tvBwcHoqOj8+wvhBBCCGGtQn0mSwghhBDiUSVFlhBCCCGEDUiRJYQQQghhA1JkCSGEEELYgBRZQgghhBA2IEWWEEIIIYQNSJElhBBCCGEDUmQJIYQQQtiAFFlCCCGEEDYgRZYQQgghhA1IkSWEEEIIYQNSZAkhhBBC2ECRL7JOnDiBTqdj7969BR2KEI+kSZMmodPpGDhwoEV7fHw8L7zwAq6urri7u/Pcc89x/fp1iz7r16+nYcOGODs7U6JECdq0aaOtW7x4MTqdLtevs2fP5hnPxYsXiYiIwN3dHQ8PD7p3787Vq1fz85CFECJf2Bd0ALbm5+dHcnIyJUuWBGDbtm08//zzXLp0CQ8Pj4INTohCLiEhgU8++YTatWtbtMfHxxMaGsqIESOYM2cO9vb27Nu3D73+/1+3rV69mp49e/Lhhx/ywgsvkJmZyYEDB7T1HTp0IDQ01GLcyMhIbty4gbe3d54xRUREkJycTFxcHCaTia5du9KrVy9WrFiRT0cthBD5o8gXWXZ2dvj4+BR0GEI8cq5evUpERAQLFy5kwoQJFuveffdd3n77bYYPH661Va1aVfs5MzOTd955h6lTp9K9e3etvUaNGtrPzs7OODs7a8vnzp1jy5YtfP7553nGdPjwYTZu3EhCQgL169cHYM6cOYSFhTFt2jR8fX3v/4CFECKfFZkiy2w2M23aND799FNOnz5N6dKl6d27NxEREQQGBrJnzx48PDx4/vnnAShRogQAXbp04YUXXuDdd98lKSkJg8GgjdmmTRuKFSvGl19+ec9xNJy4mUx71/w9uCLIYKeY0gBqRv2IMUtX0OEUeg8zXycmhQPQv39/wsPDCQ4Otiiyzp49y44dO4iIiKBx48YcO3aMatWq8cEHHxAUFATA77//zpkzZ9Dr9dSrV4+UlBTq1q3L1KlTqVmzZq77Xbp0KS4uLrz66qt5xhYfH4+Hh4dWYAEEBwej1+vZsWMHr7zySn6kQAgh8kWRKbJGjBjBwoULmTFjBkFBQSQnJ3PkyBGLPn5+fqxevZp27dqRmJiIu7s7zs7OODo68vbbb/P999/z2muvATefSNavX8+mTZty3Z/RaMRoNGrLaWlpABj0Cjs7ZaOjLDoMemXxXdzZw8yXyWTi66+/Zvfu3cTHx2MymVBKYTabMZlM/PnnnwBERUUxefJkateuzfLly2nevDl79uyhcuXKFn2mTJlCQEAAM2bMoFmzZhw8eBBPT88c+/3ss8/o2LEj9vb2mEymXGM7c+YMpUqVyrHe09OTM2fOaO23fxd3JzmzjuTLOoU5X7aMqUgUWVeuXGHWrFnMnTuXLl26AFCxYkWCgoI4ceKE1s/Ozk775+7t7W0xJ+uNN95g0aJFWpG1bNkyypcvT7NmzXLd58SJE4mOjs7RPqqeGReXrPw5sMfA+Prmgg7hkfIw8rVkyRIGDx5MdHQ0W7ZsAeDChQscP36c2NhY7cXL888/T6lSpUhOTuaFF17gu+++Y8yYMXTq1Inff/8dgPDwcJycnEhJSeHVV19lw4YNREdHExISYrHPI0eOcOTIEXr06EFsbGyesSUmJnLt2rUcfTIyMjhw4ECO9ri4uAfOx+NGcmYdyZd1CmO+0tPTbTZ2kSiyDh8+jNFopHnz5vc9Rs+ePXn66ac5c+YMZcuWZfHixURGRqLT5X5pZsSIEQwaNEhbTktLw8/Pjwl79GQ62N13HI8Lg14xvr6Z0bv0GM1yufBuHma+PqjnQWpqKu+9957WlpWVxaFDh9iwYQMHDhxg+PDhvPTSS4SFhWl9li1bhr29PWFhYbi4uDBjxgzat29PkyZNtD5TpkzB3d3dYjuAmJgY6tSpw9tvv33H2LLPMN+6fWZmJlevXqV58+Zau8lkIi4ujhYtWuDg4PBA+XhcSM6sI/myTmHOV/aVKFsoEkXWrZNn71e9evWoU6cOS5cupWXLlhw8eJD169fn2d9gMFjM38pmNOvIlDlG98xo1smcLCs8jHyFhISwf/9+i7auXbtSrVo1hg0bRtWqVfH19eXYsWMW/yyPHj3Kiy++iIODAw0bNsRgMHDs2DHtbLDJZOLkyZNUqFDBYrurV6/y7bffMnHixLv+8w0KCuLy5cv88ccfPPXUUwBs3boVs9lMkyZNcmzv4OBQ6P6hF3aSM+tIvqxTGPNly3iKRJFVuXJlnJ2d2bx5Mz169LhjX0dHR+DmK/Pb9ejRg5kzZ3LmzBmCg4Px8/OzOpYdI5rj5eVl9XaPG5PJRGxsLAeiQgrdH1xh9LDzdfvkdFdXV7y8vLT2IUOGMHbsWOrUqUPdunVZsmQJR44c4dtvvwXA3d2dPn36MHbsWPz8/PD392fq1KkA2iX5bF9//TWZmZm8+eabOeLYuXMnnTt3ZvPmzZQtW5bq1asTGhpKz549WbBgASaTiQEDBtCxY0d5Z6EQotApEkWWk5MTw4YNY+jQoTg6OtKkSRPOnTvHwYMHc1xC9Pf3R6fTsW7dOsLCwnB2dsbNzQ24OS9r8ODBLFy4kKVLlxbEoQjxSBg4cCA3btzg3Xff5eLFi9SpU4e4uDgqVqyo9Zk6dSr29vZ06tSJ69ev07BhQ7Zs2aK9szfb559/Ttu2bXO9b116ejqJiYkWE1OXL1/OgAEDaN68OXq9nnbt2jF79mybHasQQtyvIlFkAYwePRp7e3vGjBlDUlISZcqUoU+fPjn6lS1blujoaIYPH07Xrl3p3LkzixcvBqB48eK0a9eO9evXW9yZWojH3bZt23K0DR8+3OI+WbdzcHBg2rRpTJs27Y5jb9++Pc91zZo1QynLd1R6enrKjUeFEI+EIlNk6fV6Ro4cyciRI3Osu/2f9OjRoxk9enSu45w5c4aIiIhc51sJIYQQQtyrIlNkPahLly6xbds2tm3bxscff1zQ4QghhBDiESdF1v/Uq1ePS5cuMXnyZIuPBxFCCCGEuB9SZP3PrTctFUIIIYR4UPqCDkAIIYQQoiiSIksIIYQQwgakyBJCCCGEsAEpsoQQQgghbECKLCGEEEIIG5AiSwghhBDCBqTIEkIIIYSwASmyhBBCCCFsQIosIYQQQggbkCJLiAI2f/58ateujbu7O+7u7jRq1IgNGzYANz+JQKfT4ejoSJs2bXB0dESn06HT6fjmm2+0MU6dOkV4eDguLi54e3szZMgQMjMzLfYzb948qlevjrOzM1WrVmXp0qV3je1exhVCCJE7+VgdIQpYuXLlmDRpEpUrV0YpxZIlS2jdujV79uyhWrVqJCcnYzKZ2Lx5M82bN2fRokVMnTqVF198EYCsrCzCw8Px8fFh+/btJCcn07lzZxwcHPjwww+Bm4XciBEjWLhwIU8//TQ7d+6kZ8+elChRglatWuUa172MK4QQ4g6UsLBo0SJVvHhxq7dLTU1VgDp//nz+B1UEZWRkqJiYGJWRkVHQoRRKJUqUUJ999pm2fGu+6tatq7p166ati42NVXq9XqWkpGht8+fPV+7u7spoNCqllGrUqJEaPHiwxT4GDRqkmjRpkmcM9zJuYSWPL+tJzqwj+bJOYc5X9vN3ampqvo8tlwuFKESysrJYuXIl165do1GjRjnW//777+zdu5fu3btrbfHx8dSqVYvSpUtrbSEhIaSlpXHw4EEAjEYjTk5OFmM5Ozuzc+dOTCZTrrHcy7hCCCHyViQvF5rNZqZNm8ann37K6dOnKV26NL1796ZJkyY8//zzXLp0CQ8PDwD27t1LvXr1OH78OCdOnKBr164A6HQ6AMaOHUtUVNQ977vhxM1k2rvm9yEVOQY7xZQGUDPqR4xZuoIOp8CcmBQOwP79+2nUqBE3btzAzc2NtWvXUqNGjRz9Fy1aRPXq1WncuLHWlpKSYlEIAdpySkoKcLM4+uyzz2jTpg1PPvkku3fv5rPPPsNkMnH+/HnKlCmTY1/3Mq4QQoi8FckiK3vuyYwZMwgKCiI5OZkjR47cdbvGjRszc+ZMxowZQ2JiIgBubm659jUajRiNRm05LS0NAINeYWen8uEoijaDXll8f1xln0WqUKECCQkJpKWlsXr1arp06cJPP/2kFVomkwmj0cjKlSt5//33Lc4+mc1mlFIWbdk/Z2ZmYjKZGD58OElJSTzzzDMopShdujRvvvkmH330EVlZWbmezbqXcQur7NgKc4yFjeTMOpIv6xTmfNkypiJXZF25coVZs2Yxd+5cunTpAkDFihUJCgpi27Ztd9zW0dGR4sWLo9Pp8PHxuWPfiRMnEh0dnaN9VD0zLi5Z9x3/42Z8fXNBh1CgYmNjc7Q1adKEH3/8kaFDh9KvXz+tffv27Vy7dg0fHx+L7a5cucJff/1l0fbvv/8CcPToUa39lVdeoVWrVly+fJkSJUqwadMmnJ2dSUhIQK/POXPgXsctzOLi4go6hEeO5Mw6ki/rFMZ8paen22zsIldkHT58GKPRSPPmzW26nxEj/q+9u4+Kqk7jAP6FYWYYxmYgFIgEJSVBhSRJFsncjhS+5W6v5qHELd3VMGX1oHFYXzZ1JYverNjWStuzvpQdrdZYjYA0WYXFBRUw1DQtE9lNYXA1GZhn//Bw8wZYk3MZXr6fc+Ycub9n7vx+X70zj3fuDBmYN2+e8rPNZkNISAiWl3miSa/T9LG7A6OnYFmsA4tKPXHJ0XPfLqxYmtTm9hdffBGBgYEYP348gMv/08rMzMTEiRMxZcoUVa2npyfee+89xMbGIiAgAADwxhtvwGKxYMaMGTAaje0+xqRJkzBx4sQ2x3/ufjsDu92OvLw83HXXXdDr9e6eTpfAzJzDvJzTmfNqeSdKC92uyTKZTO2OtfxvXeT7t6h+7mlCo9HY5ovMJYcHmnrwNUbOuuTw6NHXZOn1emRkZGDcuHEIDQ1FQ0MDNmzYgJ07d2LHjh3Kk9HRo0dRVVWFrKysVk9Q48ePx+DBg/HYY49h1apVqKmpwZIlS5Camqq83X348GGUlJQgLi4O586dw/PPP4/Kykr89a9/Vfa3detWZGRkKG+t/5T9dnZ6vb7TPaF3dszMOczLOZ0xLy3n0+2arPDwcJhMJuTn52P69OmqsT59+gAATp8+DT8/PwCXL3y/ksFgQHPzz3+7rzhjDPz9/X/2/XsKu92O3NxcVCxN6nQHXEerra3F1KlTcfr0aVitVkRHR2PHjh246667lJp169bB399fta2FTqfDtm3bMGvWLMTHx8NsNiMlJQVPP/20UtPc3Izs7GxUV1dDr9fjzjvvxD//+U/0799fqamvr1euRfyp+yUiovZ1uybL29sbCxcuxIIFC2AwGJCQkID//Oc/qKysxNSpUxESEoKlS5dixYoVOHz4MLKzs1X379+/P86fP4/8/Hzccsst8PHxgY+Pj5tWQz3Bm2+++aM1y5cvx8iRI9u8dgoA+vXrd9VrpCIjI1FWVnbVx5g2bRqmTZvm1H6JiKh93fJ7shYtWoT58+dj8eLFiIyMxOTJk1FbWwu9Xo+NGzfi888/R3R0NJ555hksX75cdd+RI0di5syZmDx5Mvr06YNVq1a5aRVERETUlXW7M1nA5WuvMjMzkZmZ2WosISEBBw4cUG278hot4PKvIMnJydF0jkRERNS9dcszWURERETuxiaLiIiISANssoiIiIg0wCaLiIiISANssoiIiIg0wCaLiIiISANssoiIiIg0wCaLiIiISANssoiIiIg0wCaLiIiISANssoiIiIg0wCaLiIiISANssoiIiIg0wCaLiIiISANssoiIiIg0wCaLiIiISANssoiIiIg04OXuCXQXIgIAaGhogF6vd/NsOj+73Y4LFy7AZrMxr5+AeTmHeTmPmTmHeTmnM+dls9kAfP867kpsslzk22+/BQCEhYW5eSZERETkrIaGBlitVpfuk02Wi1x//fUAgJMnT7r8L6k7stlsCAkJwVdffQWLxeLu6XR6zMs5zMt5zMw5zMs5nTkvEUFDQwOCg4Ndvm82WS7i6Xn58jar1drp/gF1ZhaLhXk5gXk5h3k5j5k5h3k5p7PmpdXJEV74TkRERKQBNllEREREGmCT5SJGoxFLliyB0Wh091S6BOblHOblHOblPGbmHOblnJ6al4do8ZlFIiIioh6OZ7KIiIiINMAmi4iIiEgDbLKIiIiINMAmi4iIiEgDbLJc4NVXX0X//v3h7e2NuLg4lJSUuHtKHWLlypW47bbbcN111yEgIAC//vWvUV1drar57rvvkJqaCn9/f/Tq1Qv3338/zpw5o6o5efIkJkyYAB8fHwQEBCA9PR1NTU2qmk8//RS33norjEYjBg4ciHXr1mm9PE1lZWXBw8MDaWlpyjZm1dqpU6fwyCOPwN/fHyaTCVFRUSgtLVXGRQSLFy/GDTfcAJPJhMTERBw5ckS1j7NnzyI5ORkWiwW+vr54/PHHcf78eVXNgQMHMGrUKHh7eyMkJASrVq3qkPW5UnNzMxYtWoSwsDCYTCYMGDAAy5YtU/0+tp6e165du3DPPfcgODgYHh4eeP/991XjHZnP5s2bERERAW9vb0RFRSE3N9fl671WV8vLbrdj4cKFiIqKgtlsRnBwMKZOnYpvvvlGtY+elFebhK7Jpk2bxGAwyFtvvSWVlZUyY8YM8fX1lTNnzrh7appLSkqStWvXSkVFhZSXl8v48eMlNDRUzp8/r9TMnDlTQkJCJD8/X0pLS+UXv/iFjBw5UhlvamqSoUOHSmJiopSVlUlubq707t1bMjIylJpjx46Jj4+PzJs3T6qqqmT16tWi0+lk+/btHbpeVykpKZH+/ftLdHS0zJ07V9nOrNTOnj0r/fr1k2nTpklxcbEcO3ZMduzYIUePHlVqsrKyxGq1yvvvvy/79++XSZMmSVhYmFy8eFGpGTt2rNxyyy2yd+9e+eyzz2TgwIEyZcoUZby+vl4CAwMlOTlZKioqZOPGjWIymeT111/v0PVeqxUrVoi/v79s27ZNjh8/Lps3b5ZevXrJSy+9pNT09Lxyc3MlMzNTtmzZIgBk69atqvGOyqeoqEh0Op2sWrVKqqqq5A9/+IPo9Xo5ePCg5hk442p51dXVSWJiorzzzjvy+eefy549e2TEiBEyfPhw1T56Ul5tYZN1jUaMGCGpqanKz83NzRIcHCwrV65046zco7a2VgDIzp07ReTyQajX62Xz5s1KzaFDhwSA7NmzR0QuH8Senp5SU1Oj1OTk5IjFYpFLly6JiMiCBQtkyJAhqseaPHmyJCUlab0kl2toaJDw8HDJy8uT0aNHK00Ws2pt4cKFcvvtt7c77nA4JCgoSJ599lllW11dnRiNRtm4caOIiFRVVQkA+de//qXU/OMf/xAPDw85deqUiIi89tpr4ufnp2TY8tiDBg1y9ZI0NWHCBHnsscdU2+677z5JTk4WEeb1Qz9sGjoyn4ceekgmTJigmk9cXJz87ne/c+kaXamtpvSHSkpKBICcOHFCRHp2Xi34duE1aGxsxL59+5CYmKhs8/T0RGJiIvbs2ePGmblHfX09gO9/Wfa+fftgt9tV+URERCA0NFTJZ8+ePYiKikJgYKBSk5SUBJvNhsrKSqXmyn201HTFjFNTUzFhwoRW62FWrX344YeIjY3Fgw8+iICAAMTExGDNmjXK+PHjx1FTU6Nar9VqRVxcnCozX19fxMbGKjWJiYnw9PREcXGxUnPHHXfAYDAoNUlJSaiursa5c+e0XqbLjBw5Evn5+Th8+DAAYP/+/di9ezfGjRsHgHn9mI7Mpzsdp1eqr6+Hh4cHfH19ATAvgNdkXZP//ve/aG5uVr3oAUBgYCBqamrcNCv3cDgcSEtLQ0JCAoYOHQoAqKmpgcFgUA64FlfmU1NT02Z+LWNXq7HZbLh48aIWy9HEpk2b8O9//xsrV65sNcasWjt27BhycnIQHh6OHTt2YNasWZgzZw7efvttAN+v+WrHX01NDQICAlTjXl5euP76653KtSt46qmn8PDDDyMiIgJ6vR4xMTFIS0tDcnIyAOb1Yzoyn/ZqunJ+3333HRYuXIgpU6YovwCaeQFe7p4AdQ+pqamoqKjA7t273T2VTumrr77C3LlzkZeXB29vb3dPp0twOByIjY3Fn/70JwBATEwMKioq8Oc//xkpKSlunl3n8+6772L9+vXYsGEDhgwZgvLycqSlpSE4OJh5kabsdjseeughiAhycnLcPZ1OhWeyrkHv3r2h0+lafQLszJkzCAoKctOsOt7s2bOxbds2FBYWom/fvsr2oKAgNDY2oq6uTlV/ZT5BQUFt5tcydrUai8UCk8nk6uVoYt++faitrcWtt94KLy8veHl5YefOnXj55Zfh5eWFwMBAZvUDN9xwAwYPHqzaFhkZiZMnTwL4fs1XO/6CgoJQW1urGm9qasLZs2edyrUrSE9PV85mRUVF4dFHH8Xvf/975cwp87q6jsynvZqumF9Lg3XixAnk5eUpZ7EA5gWwybomBoMBw4cPR35+vrLN4XAgPz8f8fHxbpxZxxARzJ49G1u3bkVBQQHCwsJU48OHD4der1flU11djZMnTyr5xMfH4+DBg6oDseVAbXmBjY+PV+2jpaYrZTxmzBgcPHgQ5eXlyi02NhbJycnKn5mVWkJCQquvBDl8+DD69esHAAgLC0NQUJBqvTabDcXFxarM6urqsG/fPqWmoKAADocDcXFxSs2uXbtgt9uVmry8PAwaNAh+fn6arc/VLly4AE9P9VO6TqeDw+EAwLx+TEfm012O05YG68iRI/jkk0/g7++vGmde4Fc4XKtNmzaJ0WiUdevWSVVVlfz2t78VX19f1SfAuqtZs2aJ1WqVTz/9VE6fPq3cLly4oNTMnDlTQkNDpaCgQEpLSyU+Pl7i4+OV8ZavJbj77rulvLxctm/fLn369GnzawnS09Pl0KFD8uqrr3bZryW40pWfLhRhVj9UUlIiXl5esmLFCjly5IisX79efHx85G9/+5tSk5WVJb6+vvLBBx/IgQMH5Fe/+lWbH7mPiYmR4uJi2b17t4SHh6s+Ql5XVyeBgYHy6KOPSkVFhWzatEl8fHy6xFcSXCklJUVuvPFG5SsctmzZIr1795YFCxYoNT09r4aGBikrK5OysjIBIM8//7yUlZUpn4brqHyKiorEy8tLnnvuOTl06JAsWbKkU34lwdXyamxslEmTJknfvn2lvLxc9Rpw5ScFe1JebWGT5QKrV6+W0NBQMRgMMmLECNm7d6+7p9QhALR5W7t2rVJz8eJFeeKJJ8TPz098fHzk3nvvldOnT6v28+WXX8q4cePEZDJJ7969Zf78+WK321U1hYWFMmzYMDEYDHLTTTepHqOr+mGTxaxa+/vf/y5Dhw4Vo9EoERER8pe//EU17nA4ZNGiRRIYGChGo1HGjBkj1dXVqppvv/1WpkyZIr169RKLxSK/+c1vpKGhQVWzf/9+uf3228VoNMqNN94oWVlZmq/N1Ww2m8ydO1dCQ0PF29tbbrrpJsnMzFS94PX0vAoLC9t8zkpJSRGRjs3n3XfflZtvvlkMBoMMGTJEPvroI83W/XNdLa/jx4+3+xpQWFio7KMn5dUWD5Ervg6YiIiIiFyC12QRERERaYBNFhEREZEG2GQRERERaYBNFhEREZEG2GQRERERaYBNFhEREZEG2GQRERERaYBNFhEREZEG2GQRUbcwbdo0eHh4tLodPXrU3VMjoh7Ky90TICJylbFjx2Lt2rWqbX369HHTbNTsdjv0er27p0FEHYhnsoio2zAajQgKClLddDpdm7UnTpzAPffcAz8/P5jNZgwZMgS5ubnKeGVlJSZOnAiLxYLrrrsOo0aNwhdffAEAcDgcePrpp9G3b18YjUYMGzYM27dvV+775ZdfwsPDA++88w5Gjx4Nb29vrF+/HgDwxhtvIDIyEt7e3oiIiMBrr72mYSJE5E48k0VEPVJqaioaGxuxa9cumM1mVFVVoVevXgCAU6dO4Y477sAvf/lLFBQUwGKxoKioCE1NTQCAl156CdnZ2Xj99dcRExODt956C5MmTUJlZSXCw8OVx3jqqaeQnZ2NmJgYpdFavHgxXnnlFcTExKCsrAwzZsyA2WxGSkqKW3IgIg25+zdUExG5QkpKiuh0OjGbzcrtgQceaLc+KipKli5d2uZYRkaGhIWFSWNjY5vjwcHBsmLFCtW22267TZ544gkRETl+/LgAkBdffFFVM2DAANmwYYNq27JlyyQ+Pv5H10dEXQ/PZBFRt3HnnXciJydH+dlsNrdbO2fOHMyaNQsff/wxEhMTcf/99yM6OhoAUF5ejlGjRrV5DZXNZsM333yDhIQE1faEhATs379ftS02Nlb58//+9z988cUXePzxxzFjxgxle1NTE6xWq3MLJaIugU0WEXUbZrMZAwcO/Em106dPR1JSEj766CN8/PHHWLlyJbKzs/Hkk0/CZDK5bD4tzp8/DwBYs2YN4uLiVHXtXTdGRF0bL3wnoh4rJCQEM2fOxJYtWzB//nysWbMGABAdHY3PPvsMdru91X0sFguCg4NRVFSk2l5UVITBgwe3+1iBgYEIDg7GsWPHMHDgQNUtLCzMtQsjok6BZ7KIqEdKS0vDuHHjcPPNN+PcuXMoLCxEZGQkAGD27NlYvXo1Hn74YWRkZMBqtWLv3r0YMWIEBg0ahPT0dCxZsgQDBgzAsGHDsHbtWpSXlyufIGzPH//4R8yZMwdWqxVjx47FpUuXUFpainPnzmHevHkdsWwi6kBssoioR2pubkZqaiq+/vprWCwWjB07Fi+88AIAwN/fHwUFBUhPT8fo0aOh0+kwbNgw5TqsOXPmoL6+HvPnz0dtbS0GDx6MDz/8UPXJwrZMnz4dPj4+ePbZZ5Geng6z2YyoqCikpaVpvVwicgMPERF3T4KIiIiou+E1WUREREQaYJNFREREpAE2WUREREQaYJNFREREpAE2WUREREQaYJNFREREpAE2WUREREQaYJNFREREpAE2WUREREQaYJNFREREpAE2WUREREQaYJNFREREpIH/A6DbTmE2iD7QAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "ax = plot_importance(best_model, max_num_features=len(X.columns)+1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[240], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m X_nan \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mnan_to_num(X\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32))\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Fit the GridSearchCV instance to the training data\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m \u001b[43mgrid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_nan\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Get the best parameters and the best score\u001b[39;00m\n\u001b[1;32m     18\u001b[0m best_params \u001b[38;5;241m=\u001b[39m grid_search\u001b[38;5;241m.\u001b[39mbest_params_\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/base.py:1351\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1344\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1346\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1347\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1348\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1349\u001b[0m     )\n\u001b[1;32m   1350\u001b[0m ):\n\u001b[0;32m-> 1351\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/model_selection/_search.py:970\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m    964\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    965\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    966\u001b[0m     )\n\u001b[1;32m    968\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 970\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    973\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    974\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1527\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1525\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1526\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1527\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/model_selection/_search.py:916\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    909\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    910\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    911\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    912\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    913\u001b[0m         )\n\u001b[1;32m    914\u001b[0m     )\n\u001b[0;32m--> 916\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    917\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    918\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    920\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    922\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    924\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    925\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    926\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    927\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    928\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    929\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    930\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    931\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    932\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    934\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    935\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    936\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    937\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    938\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    939\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     66\u001b[0m )\n\u001b[0;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/parallel.py:1952\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1946\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   1947\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   1948\u001b[0m \u001b[38;5;66;03m# reach the first `yield` statement. This starts the aynchronous\u001b[39;00m\n\u001b[1;32m   1949\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   1950\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1952\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/parallel.py:1595\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1592\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1594\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1595\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1597\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1598\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1599\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1600\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1601\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/parallel.py:1707\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1702\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1703\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[1;32m   1704\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1705\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[1;32m   1706\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[0;32m-> 1707\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1708\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1710\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[1;32m   1711\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[1;32m   1712\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "rf_regressor = RandomForestRegressor()\n",
    "\n",
    "# Define the parameter grid to search through\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [300, 400, 500],\n",
    "    'max_depth': [None],\n",
    "    'min_samples_split': [2, 3],\n",
    "    'min_samples_leaf': [2,3]\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=rf_regressor, param_grid=param_grid_rf, cv=3, n_jobs=-1, verbose=2, scoring='neg_root_mean_squared_error')\n",
    "X_nan = np.nan_to_num(X.astype(np.float32))\n",
    "# Fit the GridSearchCV instance to the training data\n",
    "grid_search.fit(X_nan, y)\n",
    "\n",
    "# Get the best parameters and the best score\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "print(\"Best parameters found: \", best_params)\n",
    "print(\"Best score found: \", best_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rjcol\\.conda\\envs\\streamlit_env\\lib\\site-packages\\sklearn\\model_selection\\_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..................................C=0.1, penalty=l1; total time=   0.0s\n",
      "[CV] END ..................................C=0.1, penalty=l1; total time=   0.0s\n",
      "[CV] END ..................................C=0.1, penalty=l1; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rjcol\\.conda\\envs\\streamlit_env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..................................C=0.1, penalty=l2; total time= 2.3min\n",
      "[CV] END ..................................C=0.1, penalty=l2; total time= 5.5min\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[543], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(estimator\u001b[38;5;241m=\u001b[39mlogistic, param_grid\u001b[38;5;241m=\u001b[39mparam_grid_lr, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneg_root_mean_squared_error\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Fit the GridSearchCV instance to the training data\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m \u001b[43mgrid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_nan\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Get the best parameters and the best score\u001b[39;00m\n\u001b[0;32m     12\u001b[0m best_params \u001b[38;5;241m=\u001b[39m grid_search\u001b[38;5;241m.\u001b[39mbest_params_\n",
      "File \u001b[1;32mc:\\Users\\rjcol\\.conda\\envs\\streamlit_env\\lib\\site-packages\\sklearn\\base.py:1351\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1344\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1346\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1347\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1348\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1349\u001b[0m     )\n\u001b[0;32m   1350\u001b[0m ):\n\u001b[1;32m-> 1351\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\rjcol\\.conda\\envs\\streamlit_env\\lib\\site-packages\\sklearn\\model_selection\\_search.py:970\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m    964\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    965\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    966\u001b[0m     )\n\u001b[0;32m    968\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 970\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    972\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    973\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    974\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\rjcol\\.conda\\envs\\streamlit_env\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1527\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1525\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1526\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1527\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\rjcol\\.conda\\envs\\streamlit_env\\lib\\site-packages\\sklearn\\model_selection\\_search.py:916\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    908\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    909\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    910\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    911\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    912\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    913\u001b[0m         )\n\u001b[0;32m    914\u001b[0m     )\n\u001b[1;32m--> 916\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    917\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    918\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    920\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    922\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    924\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    925\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    926\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    927\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    928\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    929\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    930\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    931\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    932\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    934\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    935\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    936\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    937\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    938\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    939\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\rjcol\\.conda\\envs\\streamlit_env\\lib\\site-packages\\sklearn\\utils\\parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     66\u001b[0m )\n\u001b[1;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\rjcol\\.conda\\envs\\streamlit_env\\lib\\site-packages\\joblib\\parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1861\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1862\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1863\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1865\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1866\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1867\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1868\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1869\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1870\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[1;32mc:\\Users\\rjcol\\.conda\\envs\\streamlit_env\\lib\\site-packages\\joblib\\parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1790\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1791\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1792\u001b[0m res \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1793\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1794\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32mc:\\Users\\rjcol\\.conda\\envs\\streamlit_env\\lib\\site-packages\\sklearn\\utils\\parallel.py:129\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    127\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\rjcol\\.conda\\envs\\streamlit_env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:890\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    888\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    889\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 890\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    892\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m    893\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[0;32m    894\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[1;32mc:\\Users\\rjcol\\.conda\\envs\\streamlit_env\\lib\\site-packages\\sklearn\\base.py:1351\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1344\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1346\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1347\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1348\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1349\u001b[0m     )\n\u001b[0;32m   1350\u001b[0m ):\n\u001b[1;32m-> 1351\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\rjcol\\.conda\\envs\\streamlit_env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1296\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1293\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1294\u001b[0m     n_threads \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1296\u001b[0m fold_coefs_ \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprefer\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1297\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1298\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1299\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1300\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpos_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1301\u001b[0m \u001b[43m        \u001b[49m\u001b[43mCs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mC_\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1302\u001b[0m \u001b[43m        \u001b[49m\u001b[43ml1_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43ml1_ratio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1303\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_intercept\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_intercept\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1304\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1305\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1306\u001b[0m \u001b[43m        \u001b[49m\u001b[43msolver\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msolver\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1307\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmulti_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmulti_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1308\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1309\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1310\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1311\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1312\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcoef\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwarm_start_coef_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1313\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpenalty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpenalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1314\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_squared_sum\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_squared_sum\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1315\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_threads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_threads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1317\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1318\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mclass_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwarm_start_coef_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mclasses_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwarm_start_coef\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1319\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1321\u001b[0m fold_coefs_, _, n_iter_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mfold_coefs_)\n\u001b[0;32m   1322\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_iter_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(n_iter_, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mint32)[:, \u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\rjcol\\.conda\\envs\\streamlit_env\\lib\\site-packages\\sklearn\\utils\\parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     66\u001b[0m )\n\u001b[1;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\rjcol\\.conda\\envs\\streamlit_env\\lib\\site-packages\\joblib\\parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1861\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1862\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1863\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1865\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1866\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1867\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1868\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1869\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1870\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[1;32mc:\\Users\\rjcol\\.conda\\envs\\streamlit_env\\lib\\site-packages\\joblib\\parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1790\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1791\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1792\u001b[0m res \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1793\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1794\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32mc:\\Users\\rjcol\\.conda\\envs\\streamlit_env\\lib\\site-packages\\sklearn\\utils\\parallel.py:129\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    127\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\rjcol\\.conda\\envs\\streamlit_env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:455\u001b[0m, in \u001b[0;36m_logistic_regression_path\u001b[1;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio, n_threads)\u001b[0m\n\u001b[0;32m    451\u001b[0m l2_reg_strength \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m/\u001b[39m (C \u001b[38;5;241m*\u001b[39m sw_sum)\n\u001b[0;32m    452\u001b[0m iprint \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m101\u001b[39m][\n\u001b[0;32m    453\u001b[0m     np\u001b[38;5;241m.\u001b[39msearchsorted(np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m]), verbose)\n\u001b[0;32m    454\u001b[0m ]\n\u001b[1;32m--> 455\u001b[0m opt_res \u001b[38;5;241m=\u001b[39m \u001b[43moptimize\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mminimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    456\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[43m    \u001b[49m\u001b[43mw0\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    458\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mL-BFGS-B\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    459\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjac\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    460\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ml2_reg_strength\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_threads\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    461\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[0;32m    462\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaxiter\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    463\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaxls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# default is 20\u001b[39;49;00m\n\u001b[0;32m    464\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43miprint\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43miprint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    465\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgtol\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    466\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mftol\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfinfo\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    467\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    468\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    469\u001b[0m n_iter_i \u001b[38;5;241m=\u001b[39m _check_optimize_result(\n\u001b[0;32m    470\u001b[0m     solver,\n\u001b[0;32m    471\u001b[0m     opt_res,\n\u001b[0;32m    472\u001b[0m     max_iter,\n\u001b[0;32m    473\u001b[0m     extra_warning_msg\u001b[38;5;241m=\u001b[39m_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n\u001b[0;32m    474\u001b[0m )\n\u001b[0;32m    475\u001b[0m w0, loss \u001b[38;5;241m=\u001b[39m opt_res\u001b[38;5;241m.\u001b[39mx, opt_res\u001b[38;5;241m.\u001b[39mfun\n",
      "File \u001b[1;32mc:\\Users\\rjcol\\.conda\\envs\\streamlit_env\\lib\\site-packages\\scipy\\optimize\\_minimize.py:713\u001b[0m, in \u001b[0;36mminimize\u001b[1;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[0;32m    710\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_newtoncg(fun, x0, args, jac, hess, hessp, callback,\n\u001b[0;32m    711\u001b[0m                              \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[0;32m    712\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml-bfgs-b\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m--> 713\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001b[0;32m    714\u001b[0m                            callback\u001b[38;5;241m=\u001b[39mcallback, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[0;32m    715\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtnc\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    716\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_tnc(fun, x0, args, jac, bounds, callback\u001b[38;5;241m=\u001b[39mcallback,\n\u001b[0;32m    717\u001b[0m                         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n",
      "File \u001b[1;32mc:\\Users\\rjcol\\.conda\\envs\\streamlit_env\\lib\\site-packages\\scipy\\optimize\\_lbfgsb_py.py:369\u001b[0m, in \u001b[0;36m_minimize_lbfgsb\u001b[1;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[0;32m    363\u001b[0m task_str \u001b[38;5;241m=\u001b[39m task\u001b[38;5;241m.\u001b[39mtobytes()\n\u001b[0;32m    364\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m task_str\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFG\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    365\u001b[0m     \u001b[38;5;66;03m# The minimization routine wants f and g at the current x.\u001b[39;00m\n\u001b[0;32m    366\u001b[0m     \u001b[38;5;66;03m# Note that interruptions due to maxfun are postponed\u001b[39;00m\n\u001b[0;32m    367\u001b[0m     \u001b[38;5;66;03m# until the completion of the current minimization iteration.\u001b[39;00m\n\u001b[0;32m    368\u001b[0m     \u001b[38;5;66;03m# Overwrite f and g:\u001b[39;00m\n\u001b[1;32m--> 369\u001b[0m     f, g \u001b[38;5;241m=\u001b[39m \u001b[43mfunc_and_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    370\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m task_str\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNEW_X\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    371\u001b[0m     \u001b[38;5;66;03m# new iteration\u001b[39;00m\n\u001b[0;32m    372\u001b[0m     n_iterations \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\rjcol\\.conda\\envs\\streamlit_env\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:296\u001b[0m, in \u001b[0;36mScalarFunction.fun_and_grad\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray_equal(x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx):\n\u001b[0;32m    295\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_x_impl(x)\n\u001b[1;32m--> 296\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    297\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_grad()\n\u001b[0;32m    298\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mg\n",
      "File \u001b[1;32mc:\\Users\\rjcol\\.conda\\envs\\streamlit_env\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:262\u001b[0m, in \u001b[0;36mScalarFunction._update_fun\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    260\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_update_fun\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_updated:\n\u001b[1;32m--> 262\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_fun_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    263\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_updated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\rjcol\\.conda\\envs\\streamlit_env\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:163\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.update_fun\u001b[1;34m()\u001b[0m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate_fun\u001b[39m():\n\u001b[1;32m--> 163\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf \u001b[38;5;241m=\u001b[39m \u001b[43mfun_wrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\rjcol\\.conda\\envs\\streamlit_env\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:145\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.fun_wrapped\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnfev \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;66;03m# Send a copy because the user may overwrite it.\u001b[39;00m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;66;03m# Overwriting results in undefined behaviour because\u001b[39;00m\n\u001b[0;32m    144\u001b[0m \u001b[38;5;66;03m# fun(self.x) will change self.x, with the two no longer linked.\u001b[39;00m\n\u001b[1;32m--> 145\u001b[0m fx \u001b[38;5;241m=\u001b[39m \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    146\u001b[0m \u001b[38;5;66;03m# Make sure the function returns a true scalar\u001b[39;00m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misscalar(fx):\n",
      "File \u001b[1;32mc:\\Users\\rjcol\\.conda\\envs\\streamlit_env\\lib\\site-packages\\scipy\\optimize\\_optimize.py:78\u001b[0m, in \u001b[0;36mMemoizeJac.__call__\u001b[1;34m(self, x, *args)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, \u001b[38;5;241m*\u001b[39margs):\n\u001b[0;32m     77\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\" returns the function value \"\"\"\u001b[39;00m\n\u001b[1;32m---> 78\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compute_if_needed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     79\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n",
      "File \u001b[1;32mc:\\Users\\rjcol\\.conda\\envs\\streamlit_env\\lib\\site-packages\\scipy\\optimize\\_optimize.py:72\u001b[0m, in \u001b[0;36mMemoizeJac._compute_if_needed\u001b[1;34m(self, x, *args)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39mall(x \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjac \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     71\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(x)\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m---> 72\u001b[0m     fg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     73\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjac \u001b[38;5;241m=\u001b[39m fg[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value \u001b[38;5;241m=\u001b[39m fg[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\rjcol\\.conda\\envs\\streamlit_env\\lib\\site-packages\\sklearn\\linear_model\\_linear_loss.py:280\u001b[0m, in \u001b[0;36mLinearModelLoss.loss_gradient\u001b[1;34m(self, coef, X, y, sample_weight, l2_reg_strength, n_threads, raw_prediction)\u001b[0m\n\u001b[0;32m    277\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    278\u001b[0m     weights, intercept \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight_intercept(coef)\n\u001b[1;32m--> 280\u001b[0m loss, grad_pointwise \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_loss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss_gradient\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    281\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_true\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    282\u001b[0m \u001b[43m    \u001b[49m\u001b[43mraw_prediction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mraw_prediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    283\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    284\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_threads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_threads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    285\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    286\u001b[0m sw_sum \u001b[38;5;241m=\u001b[39m n_samples \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m np\u001b[38;5;241m.\u001b[39msum(sample_weight)\n\u001b[0;32m    287\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39msum() \u001b[38;5;241m/\u001b[39m sw_sum\n",
      "File \u001b[1;32mc:\\Users\\rjcol\\.conda\\envs\\streamlit_env\\lib\\site-packages\\sklearn\\_loss\\loss.py:254\u001b[0m, in \u001b[0;36mBaseLoss.loss_gradient\u001b[1;34m(self, y_true, raw_prediction, sample_weight, loss_out, gradient_out, n_threads)\u001b[0m\n\u001b[0;32m    251\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m gradient_out\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m gradient_out\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    252\u001b[0m     gradient_out \u001b[38;5;241m=\u001b[39m gradient_out\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m--> 254\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss_gradient\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_true\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43mraw_prediction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mraw_prediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss_out\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_out\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    259\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgradient_out\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgradient_out\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    260\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_threads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_threads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    261\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    262\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss_out, gradient_out\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "param_grid_lr = {\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'C': [ 0.1, 1, 10,]\n",
    "}\n",
    "logistic = LogisticRegression()\n",
    "grid_search = GridSearchCV(estimator=logistic, param_grid=param_grid_lr, cv=3, n_jobs=None, verbose=2, scoring='neg_root_mean_squared_error')\n",
    "\n",
    "# Fit the GridSearchCV instance to the training data\n",
    "grid_search.fit(X_nan, y)\n",
    "\n",
    "# Get the best parameters and the best score\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "print(\"Best parameters found: \", best_params)\n",
    "print(\"Best score found: \", best_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>cut</th>\n",
       "      <th>color</th>\n",
       "      <th>clarity</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>city</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.79</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>F</td>\n",
       "      <td>SI1</td>\n",
       "      <td>62.7</td>\n",
       "      <td>60.0</td>\n",
       "      <td>5.82</td>\n",
       "      <td>5.89</td>\n",
       "      <td>3.67</td>\n",
       "      <td>Amsterdam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.20</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>J</td>\n",
       "      <td>VS1</td>\n",
       "      <td>61.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>6.81</td>\n",
       "      <td>6.89</td>\n",
       "      <td>4.18</td>\n",
       "      <td>Surat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.57</td>\n",
       "      <td>Premium</td>\n",
       "      <td>H</td>\n",
       "      <td>SI1</td>\n",
       "      <td>62.2</td>\n",
       "      <td>61.0</td>\n",
       "      <td>7.38</td>\n",
       "      <td>7.32</td>\n",
       "      <td>4.57</td>\n",
       "      <td>Kimberly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.90</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>F</td>\n",
       "      <td>SI1</td>\n",
       "      <td>63.8</td>\n",
       "      <td>54.0</td>\n",
       "      <td>6.09</td>\n",
       "      <td>6.13</td>\n",
       "      <td>3.90</td>\n",
       "      <td>Kimberly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.50</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>F</td>\n",
       "      <td>VS1</td>\n",
       "      <td>62.9</td>\n",
       "      <td>58.0</td>\n",
       "      <td>5.05</td>\n",
       "      <td>5.09</td>\n",
       "      <td>3.19</td>\n",
       "      <td>Amsterdam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13480</th>\n",
       "      <td>0.57</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>E</td>\n",
       "      <td>SI1</td>\n",
       "      <td>61.9</td>\n",
       "      <td>56.0</td>\n",
       "      <td>5.35</td>\n",
       "      <td>5.32</td>\n",
       "      <td>3.30</td>\n",
       "      <td>Amsterdam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13481</th>\n",
       "      <td>0.71</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>I</td>\n",
       "      <td>VS2</td>\n",
       "      <td>62.2</td>\n",
       "      <td>55.0</td>\n",
       "      <td>5.71</td>\n",
       "      <td>5.73</td>\n",
       "      <td>3.56</td>\n",
       "      <td>New York City</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13482</th>\n",
       "      <td>0.70</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>F</td>\n",
       "      <td>VS1</td>\n",
       "      <td>61.6</td>\n",
       "      <td>55.0</td>\n",
       "      <td>5.75</td>\n",
       "      <td>5.71</td>\n",
       "      <td>3.53</td>\n",
       "      <td>Tel Aviv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13483</th>\n",
       "      <td>0.70</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>F</td>\n",
       "      <td>SI2</td>\n",
       "      <td>58.8</td>\n",
       "      <td>57.0</td>\n",
       "      <td>5.85</td>\n",
       "      <td>5.89</td>\n",
       "      <td>3.45</td>\n",
       "      <td>Surat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13484</th>\n",
       "      <td>0.40</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>I</td>\n",
       "      <td>VVS2</td>\n",
       "      <td>62.4</td>\n",
       "      <td>55.0</td>\n",
       "      <td>4.70</td>\n",
       "      <td>4.73</td>\n",
       "      <td>2.94</td>\n",
       "      <td>New York City</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13485 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       carat        cut color clarity  depth  table     x     y     z  \\\n",
       "0       0.79  Very Good     F     SI1   62.7   60.0  5.82  5.89  3.67   \n",
       "1       1.20      Ideal     J     VS1   61.0   57.0  6.81  6.89  4.18   \n",
       "2       1.57    Premium     H     SI1   62.2   61.0  7.38  7.32  4.57   \n",
       "3       0.90  Very Good     F     SI1   63.8   54.0  6.09  6.13  3.90   \n",
       "4       0.50  Very Good     F     VS1   62.9   58.0  5.05  5.09  3.19   \n",
       "...      ...        ...   ...     ...    ...    ...   ...   ...   ...   \n",
       "13480   0.57      Ideal     E     SI1   61.9   56.0  5.35  5.32  3.30   \n",
       "13481   0.71      Ideal     I     VS2   62.2   55.0  5.71  5.73  3.56   \n",
       "13482   0.70      Ideal     F     VS1   61.6   55.0  5.75  5.71  3.53   \n",
       "13483   0.70  Very Good     F     SI2   58.8   57.0  5.85  5.89  3.45   \n",
       "13484   0.40      Ideal     I    VVS2   62.4   55.0  4.70  4.73  2.94   \n",
       "\n",
       "                city  \n",
       "0          Amsterdam  \n",
       "1              Surat  \n",
       "2           Kimberly  \n",
       "3           Kimberly  \n",
       "4          Amsterdam  \n",
       "...              ...  \n",
       "13480      Amsterdam  \n",
       "13481  New York City  \n",
       "13482       Tel Aviv  \n",
       "13483          Surat  \n",
       "13484  New York City  \n",
       "\n",
       "[13485 rows x 10 columns]"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('./data/src/diamonds_test.csv')\n",
    "test['price'] = 0\n",
    "submit_df = test[['id', 'price']]\n",
    "test = test.drop(['id','price'], axis = 1)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>13485.000000</td>\n",
       "      <td>13485.000000</td>\n",
       "      <td>13485.000000</td>\n",
       "      <td>13485.000000</td>\n",
       "      <td>13485.000000</td>\n",
       "      <td>13485.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.798642</td>\n",
       "      <td>61.739095</td>\n",
       "      <td>57.490337</td>\n",
       "      <td>5.736454</td>\n",
       "      <td>5.739648</td>\n",
       "      <td>3.543474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.469399</td>\n",
       "      <td>1.435310</td>\n",
       "      <td>2.237109</td>\n",
       "      <td>1.113671</td>\n",
       "      <td>1.128507</td>\n",
       "      <td>0.731005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>50.800000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.400000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>4.730000</td>\n",
       "      <td>4.730000</td>\n",
       "      <td>2.920000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.700000</td>\n",
       "      <td>61.900000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>5.700000</td>\n",
       "      <td>5.720000</td>\n",
       "      <td>3.530000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.040000</td>\n",
       "      <td>62.500000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>6.530000</td>\n",
       "      <td>6.530000</td>\n",
       "      <td>4.040000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.010000</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>10.740000</td>\n",
       "      <td>31.800000</td>\n",
       "      <td>31.800000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              carat         depth         table             x             y  \\\n",
       "count  13485.000000  13485.000000  13485.000000  13485.000000  13485.000000   \n",
       "mean       0.798642     61.739095     57.490337      5.736454      5.739648   \n",
       "std        0.469399      1.435310      2.237109      1.113671      1.128507   \n",
       "min        0.200000     50.800000     51.000000      0.000000      0.000000   \n",
       "25%        0.400000     61.000000     56.000000      4.730000      4.730000   \n",
       "50%        0.700000     61.900000     57.000000      5.700000      5.720000   \n",
       "75%        1.040000     62.500000     59.000000      6.530000      6.530000   \n",
       "max        5.010000     79.000000     73.000000     10.740000     31.800000   \n",
       "\n",
       "                  z  \n",
       "count  13485.000000  \n",
       "mean       3.543474  \n",
       "std        0.731005  \n",
       "min        0.000000  \n",
       "25%        2.920000  \n",
       "50%        3.530000  \n",
       "75%        4.040000  \n",
       "max       31.800000  "
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>cut</th>\n",
       "      <th>color</th>\n",
       "      <th>clarity</th>\n",
       "      <th>city</th>\n",
       "      <th>x/y</th>\n",
       "      <th>td</th>\n",
       "      <th>ad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>40455.000000</td>\n",
       "      <td>40455.000000</td>\n",
       "      <td>40455.000000</td>\n",
       "      <td>40455.000000</td>\n",
       "      <td>40455.000000</td>\n",
       "      <td>40455.000000</td>\n",
       "      <td>40455.000000</td>\n",
       "      <td>40455.000000</td>\n",
       "      <td>40455.000000</td>\n",
       "      <td>40455.000000</td>\n",
       "      <td>40455.000000</td>\n",
       "      <td>40455.000000</td>\n",
       "      <td>40455.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.795712</td>\n",
       "      <td>61.749087</td>\n",
       "      <td>57.433731</td>\n",
       "      <td>5.729428</td>\n",
       "      <td>5.731641</td>\n",
       "      <td>3.537474</td>\n",
       "      <td>3.904783</td>\n",
       "      <td>4.400766</td>\n",
       "      <td>4.049388</td>\n",
       "      <td>1.036433</td>\n",
       "      <td>0.999352</td>\n",
       "      <td>0.930607</td>\n",
       "      <td>0.006125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.468168</td>\n",
       "      <td>1.361600</td>\n",
       "      <td>2.176820</td>\n",
       "      <td>1.122433</td>\n",
       "      <td>1.114376</td>\n",
       "      <td>0.693746</td>\n",
       "      <td>1.117876</td>\n",
       "      <td>1.701260</td>\n",
       "      <td>1.648181</td>\n",
       "      <td>0.019357</td>\n",
       "      <td>0.008849</td>\n",
       "      <td>0.045753</td>\n",
       "      <td>0.000181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>57.457665</td>\n",
       "      <td>50.745527</td>\n",
       "      <td>2.356034</td>\n",
       "      <td>2.292869</td>\n",
       "      <td>1.445969</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.966818</td>\n",
       "      <td>0.791427</td>\n",
       "      <td>0.002847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.400000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>4.710000</td>\n",
       "      <td>4.720000</td>\n",
       "      <td>2.910000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.031075</td>\n",
       "      <td>0.992593</td>\n",
       "      <td>0.898876</td>\n",
       "      <td>0.006046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.700000</td>\n",
       "      <td>61.800000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>5.690000</td>\n",
       "      <td>5.710000</td>\n",
       "      <td>3.520000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.038843</td>\n",
       "      <td>0.995726</td>\n",
       "      <td>0.923825</td>\n",
       "      <td>0.006115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.040000</td>\n",
       "      <td>62.500000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>6.540000</td>\n",
       "      <td>6.540000</td>\n",
       "      <td>4.035000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.048770</td>\n",
       "      <td>1.006928</td>\n",
       "      <td>0.955519</td>\n",
       "      <td>0.006189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.224338</td>\n",
       "      <td>66.048018</td>\n",
       "      <td>64.146739</td>\n",
       "      <td>9.102750</td>\n",
       "      <td>9.172768</td>\n",
       "      <td>5.628338</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.069918</td>\n",
       "      <td>1.031968</td>\n",
       "      <td>1.070199</td>\n",
       "      <td>0.011228</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              carat         depth         table             x             y  \\\n",
       "count  40455.000000  40455.000000  40455.000000  40455.000000  40455.000000   \n",
       "mean       0.795712     61.749087     57.433731      5.729428      5.731641   \n",
       "std        0.468168      1.361600      2.176820      1.122433      1.114376   \n",
       "min        0.200000     57.457665     50.745527      2.356034      2.292869   \n",
       "25%        0.400000     61.000000     56.000000      4.710000      4.720000   \n",
       "50%        0.700000     61.800000     57.000000      5.690000      5.710000   \n",
       "75%        1.040000     62.500000     59.000000      6.540000      6.540000   \n",
       "max        2.224338     66.048018     64.146739      9.102750      9.172768   \n",
       "\n",
       "                  z           cut         color       clarity          city  \\\n",
       "count  40455.000000  40455.000000  40455.000000  40455.000000  40455.000000   \n",
       "mean       3.537474      3.904783      4.400766      4.049388      1.036433   \n",
       "std        0.693746      1.117876      1.701260      1.648181      0.019357   \n",
       "min        1.445969      1.000000      1.000000      1.000000      1.000000   \n",
       "25%        2.910000      3.000000      3.000000      3.000000      1.031075   \n",
       "50%        3.520000      4.000000      4.000000      4.000000      1.038843   \n",
       "75%        4.035000      5.000000      6.000000      5.000000      1.048770   \n",
       "max        5.628338      5.000000      7.000000      8.000000      1.069918   \n",
       "\n",
       "                x/y            td            ad  \n",
       "count  40455.000000  40455.000000  40455.000000  \n",
       "mean       0.999352      0.930607      0.006125  \n",
       "std        0.008849      0.045753      0.000181  \n",
       "min        0.966818      0.791427      0.002847  \n",
       "25%        0.992593      0.898876      0.006046  \n",
       "50%        0.995726      0.923825      0.006115  \n",
       "75%        1.006928      0.955519      0.006189  \n",
       "max        1.031968      1.070199      0.011228  "
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_labeling_test(test, ['cut', 'color', 'clarity','city'],dic2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[outlier_columns] = sub_outlyers(test[outlier_columns],3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['x/y'] = test.apply(lambda x : feature_xy(x['x'], x['y']), axis=1)\n",
    "test['td'] = test.apply(lambda x : feature_xy(x['table'], x['depth']), axis=1)\n",
    "test['ad'] = test.apply(lambda x : feature_ad(x['carat'],x['x'], x['y'], x['z']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test = pd.concat([test, pd.get_dummies(test['city'], drop_first=True)], axis = 1).drop('city',axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[['x/y','td', 'ad']] = sub_outlyers(test[['x/y','td', 'ad']],3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"def filter_transform2(df,selected_features,target):\\n    data_df = df[selected_features]\\n    to_dummy = [feature for feature in selected_features if len(df[feature].unique()) < 15]\\n    for feature in to_dummy:\\n        dummies_df = pd.get_dummies(data_df[feature], prefix=feature, drop_first=True)\\n        data_df = pd.concat([data_df, dummies_df],axis=1).drop(feature, axis=1)   \\n    data_df = pd.concat([data_df.select_dtypes(exclude=['object']), df[target]], axis=1)\\n    return data_df\""
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''def filter_transform2(df,selected_features,target):\n",
    "    data_df = df[selected_features]\n",
    "    to_dummy = [feature for feature in selected_features if len(df[feature].unique()) < 15]\n",
    "    for feature in to_dummy:\n",
    "        dummies_df = pd.get_dummies(data_df[feature], prefix=feature, drop_first=True)\n",
    "        data_df = pd.concat([data_df, dummies_df],axis=1).drop(feature, axis=1)   \n",
    "    data_df = pd.concat([data_df.select_dtypes(exclude=['object']), df[target]], axis=1)\n",
    "    return data_df'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test[X.columns]\n",
    "test.to_csv('./data/clean/testdl123fexydatdso3x2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_submit = test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_list = best_model.predict(X_submit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13480</th>\n",
       "      <td>13480</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13481</th>\n",
       "      <td>13481</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13482</th>\n",
       "      <td>13482</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13483</th>\n",
       "      <td>13483</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13484</th>\n",
       "      <td>13484</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13485 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  price\n",
       "0          0      0\n",
       "1          1      0\n",
       "2          2      0\n",
       "3          3      0\n",
       "4          4      0\n",
       "...      ...    ...\n",
       "13480  13480      0\n",
       "13481  13481      0\n",
       "13482  13482      0\n",
       "13483  13483      0\n",
       "13484  13484      0\n",
       "\n",
       "[13485 rows x 2 columns]"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit_df['price'] = 0\n",
    "submit_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        2876.100830\n",
       "1        5621.440430\n",
       "2        9607.622070\n",
       "3        4015.559570\n",
       "4        1618.453613\n",
       "            ...     \n",
       "13480    1702.471558\n",
       "13481    2498.168701\n",
       "13482    3076.998779\n",
       "13483    2097.655029\n",
       "13484     799.293274\n",
       "Name: price, Length: 13485, dtype: float32"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit_df['price'] = price_list\n",
    "submit_df['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_df.set_index('id')['price'].to_csv('./submissions/xgartl123gridtdso3x2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(best_model, open('./models/xgartdl123dlgridtdso3x2.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = pickle.load(open('./models/dl123dlgridtdso3.sav', 'rb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "streamlit_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
